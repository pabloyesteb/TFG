\chapter{Miscellaneous}
%
\label{app:App_E}
%
\section{State Transition Matrices.}
%
%
	\subsection{STM for circular, unperturbed reference orbit.}
	%
	\indent As analyzed in chapter \ref{chap:Chap_2}, out of the four surveyed HCW methods, only two of them provide a true closed-form expression for the STM. Furthermore, as these two are mere different approaches or decompositions of the same matrix, the simplest result will be here shown: that is, the Clohessy-Wiltshire solution STM:
	%
	\begin{equation}
	\bm \Phi (t, t_0) = \left[
	\begin{array}{cccccc}
	1	& \ccg{0}					& 6(\omega\tau - \sin\omega\tau)	& \frac{4}{\omega} \sin\omega\tau - 3\tau	& \ccg{0}						& \frac{2}{\omega} (1 - \cos\omega\tau) \\
	\rowcolor{Gray!20}
	0	& \cos\omega\tau			& 0									& 0 										&\frac{1}{\omega}\sin\omega\tau & 0 \\
	0	& \ccg{0}					& 4 - 3 \cos\omega\tau				& \frac{2}{\omega} (\cos\omega\tau - 1)		& \ccg{0}						& \frac{1}{\omega} \sin\omega\tau\\
	0	& \ccg{0}					& 6\omega (1 - \cos\omega\tau)		& 4\cos\omega\tau - 3						& \ccg{0}						& 2\sin\omega\tau	\\
	\rowcolor{Gray!20}
	0	& -\omega \sin\omega\tau	& 0									& 0											& \cos\omega\tau				& 0\\
	0	& \ccg{0}					& 3\omega\sin\omega\tau 			& -2 \sin\omega\tau							& \ccg{0}						& \cos\omega\tau
	\end{array}\right]
	\label{eqAppE:CW_STM}
	\end{equation}
	%
	\subsection{STM for elliptic, unperturbed reference orbit.}
	%
	\indent The one and only implementation is the state-of-the-art Yamanaka-Ankersen STM, which is computed through:
	%
	\begin{equation}
	\Phi_{\theta_0}^{\theta} = \Phi_{\theta} \left(\Phi_{\theta_0}\right)^{-1}
	\end{equation}
	\noindent where:
	\begin{subequations}
	\begin{alignat}{2}
	&\label{eqCh3:phi_final} \Phi_{\theta} = 
	\left[
	\begin{array}{cccccc}
	1 	&    0 			&  -c  (1 + \rho^{-1})	& s  (1 + \rho^{-1})	&    0			&                  3 \rho^2 J \\
        0	&  \cos\theta 	&                   0	&                 0	&  \sin\theta 	&                              0\\
        0 	&  	0			&                  s	&                 c	&    0			&              2 - 3  e  s  J\\
        0	&    0			&              2  s		&         2  c - e	&    0			&       3  (1  - 2 e  s  J)\\
        0	& -\sin\theta   &                0 		&                 0&  \cos\theta 	&                              0\\
        0	&	0 			&             s^{\prime}	&            c^{\prime}&    0			& -3  e  (s^{\prime}  J + s/\rho^2)
	\end{array}
	\right] \\
	&\nonumber \Phi_{\theta_0}^{-1} = \dfrac{1}{1 - e^2}\times \\ 
	&\label{eqCh3:phi_inv_final}\left[
	\begin{array}{cccccc}
	1 - e^2	&    0 					&  3 e  (s/\rho)  (1 + \rho^{-1})		& -e s  (1 + \rho^{-1})	&    0						&                 2 - e c\\
        0		&  (1 - e^2) \cos\theta	&         0							&                 0		&  -(1 - e^2) \sin\theta 	&              0\\
        0 		&  	0					&     -3  (s/\rho)  (1 + e^2/\rho)	&   s  (1 + \rho^{-1})	&    0						&              c - 2e	\\
        0		&    0					&          -3  (c/\rho + e)			&  c  (1 + \rho^{-1}) + e	&    0						&      -s 		\\
        0		& (1 - e^2) \sin\theta 	&                0 					&                 0		&  (1 - e^2) \cos\theta 	&                              0\\
        0		&	0 					&             3  \rho + e^2 - 1		&           -\rho^2 	&    0						& e s
	\end{array}
	\right]
	\end{alignat}
	\end{subequations}
	%
	\indent It shall be remarked that this matrices operates on the modified LVLH state vector, derived from the original LVLH state vector. If one wishes to have an expression for the STM in which a true LVLH state vector is fed and returned, a slight modification must be performed:
	%
	\begin{equation}
	\Phi(t, t_0) =\left( T_{\theta}(\theta)\right)^{-1} \Phi_{\theta} \left(\Phi_{\theta_0}\right)^{-1} T_{\theta}(\theta_0)
	\end{equation}
	%
	\noindent where $T_{\theta}(\theta)$ is the matrix that converts a regular LVLH state vector into the modified form.
	%
	\subsection{STM for elliptic, J2-perturbed orbit.}
	%
	\indent Outlined in section \ref{secCh5:GA_STM}, the Gim-Alfriend STM components is specified in \cite{GA_STM}, appendices A to E.
	%
\section{Variational equations.}\label{secAppE:Variational}
%
\indent The equations of motion of a spacecraft immersed in a potential field $V$ can be expressed, in an inertial reference frame, as:
%
\[
\ddot{\underline{r}} = \nabla V = \underline{a}
\]
%
\indent These equations can be converted, as usual, to a system of six first-order equations, by treating the velocity components as variables. Accordingly:
%
\begin{equation}
\begin{array}{lc}
\left\{\begin{array}{lll}
\dfrac{d}{dt} x_i = \dot{x}_i \\[1.2em]
\dfrac{d}{dt} \dot{x_i}= \dfrac{\partial V}{\partial x_i} = a_i \\
\end{array}\right. & i = 1, 2, 3
\end{array}
\label{eqAppE:EqsMotion1}
\end{equation}
%
\indent One can expect that these coordinates and velocities change rapidly, requiring a smaller integration timestep. However, it is known that there are some phase spaces in which the state vector does not change so quickly, if it change at all. The obvious example for this is the Keplerian Orbital Elements, which for the two body problem remain constant (except for the mean anomaly, which grows linearly). If the target is to analyze a problem that differs very slightly from the two body problem, an interesting approach would be to use the Keplerian Elements as a parametrization, as they would change slowly. The question now is, how to express the equations of motion in terms of the orbital elements (Keplerian in this case). \\
%
\indent This is where the variational equations appear, as they are (by construction) said equations. There are two approaches, depending on whether it is desirable to work with perturbation potentials ($V$) or perturbation accelerations ($\underline{a}$), which are the so-called Lagrange Planetary Equations (LPEs) and the Gauss Variational Equations (GVEs) respectively.
%
	\subsection{Lagrange Planetary Equations.}\label{secAppE:LPE}
	%
	\indent The procedure followed herewith is derived from Kaula \cite{Kaula}. Firstly, the rates of change of position and velocity are assumed to be functions of the rates of change of the Keplerian OEs $ds_k/dt$, where $s_k$ represents any of $a, e, i, \Omega, \omega, M$. Equation \eqref{eqAppE:EqsMotion1} can be then reformulated as:
	%
	\begin{align}
	\label{eqAppE:EqsMotion2_A} \sum_{k=1}^{6} \frac{\partial x_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}=\frac{\partial x_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}=\dot{x}_{i}, \quad i=1,2,3 \\
	\label{eqAppE:EqsMotion2_B} \sum_{k=1}^{6} \frac{\partial \dot{x}_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}=\frac{\partial \dot{x}_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}=\frac{\partial V}{\partial x_{i}}, \quad i=1,2,3
	\end{align}
	%
	\noindent where the partial derivatives $\frac{\partial x_{i}}{\partial s_{k}}$ and $\frac{\partial \dot{x}_{i}}{\partial s_{k}}$ can be computed through \eqref{eqAppB:PQW2ECI}. Furthermore, if one adds the multiplication of \eqref{eqAppE:EqsMotion2_A} times $- \frac{\partial \dot{x}_{i}}{\partial s_{k}}$ plus the product of \eqref{eqAppE:EqsMotion2_B} times $\frac{\partial x_{i}}{\partial s_{k}}$, it follows that:
	%
	\begin{equation}
	-\frac{\partial \dot{x}_{i}}{\partial s_{l}} \cdot \frac{\partial x_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}+\frac{\partial x_{i}}{\partial s_{l}} \cdot \frac{\partial \dot{x}_{i}}{\partial s_{k}} \cdot \frac{d s_{k}}{d t}=-\frac{\partial \dot{x}_{i}}{\partial s_{l}} \dot{x}_{i}+\frac{\partial x_{i}}{\partial s_{l}} \cdot \frac{\partial V}{\partial x_{i}}
	\label{eqAppE:EqsMotion3}
	\end{equation}
	%
	\noindent which can be more succinctly written as:
	%
	\begin{equation}
	[s_l, s_k] \dfrac{d s_k}{dt} = \dfrac{\partial F}{\partial s_l}
	\label{eqAppE:LPE_compact}
	\end{equation}
	%
	\noindent where two new concepts appear. The first one is the Lagrange brackets, which are defined as:
	%
	\begin{equation}
	\left[s_{l}, s_{k}\right]=\frac{\partial x_{i}}{\partial s_{l}} \cdot \frac{\partial \dot{x}_{i}}{\partial s_{k}}-\frac{\partial \dot{x}_{i}}{\partial s_{l}} \cdot \frac{\partial x_{i}}{\partial s_{k}}
	\end{equation}
	%
	\noindent and the function $F$, which is equal to:
	%
	\[
	F = V - T = V - \frac{1}{2} \dot{x}_i \dot{x}_i
	\]
	%
	\indent Solving for $ds_k/dt$ in \eqref{eqAppE:LPE_compact} leaves exactly what one was looking for: an initial value problem expressed in terms of the Keplerian OEs. Skipping the mathematical specifics of the development (detailed in \cite{Kaula}, eqs. 3.34-3.37), the final form of the equations is:
	%
	\begin{equation}
	\left\{ \begin{array}{llll}
	\dfrac{da}{dt} 		& = \dfrac{2}{na} \dfrac{ \partial F}{\partial M} \\[1.2 em]
	\dfrac{de}{dt} 		& = \dfrac{\eta^2}{na^2 e} \dfrac{ \partial F}{\partial M} - \dfrac{\eta}{na^2e} \dfrac{\partial F}{\partial e} \\[1.2 em]
	\dfrac{di}{dt} 		& = \dfrac{\cos i}{na^2 \eta \sin i} \dfrac{ \partial F}{\partial \omega} - \dfrac{1}{na^2 \eta \sin i} \dfrac{\partial F}{\partial \Omega} \\[1.2 em]
	\dfrac{d\omega}{dt} & = -\dfrac{\cos i}{na^2 \eta \sin i} \dfrac{ \partial F}{\partial i} + \dfrac{\eta}{na^2  e} \dfrac{\partial F}{\partial e}\\[1.2 em]
	\dfrac{d\Omega}{dt} & = \dfrac{1}{na^2 \eta \sin i} \dfrac{ \partial F}{\partial i} \\[1.2 em]
	\dfrac{dM}{dt}		& = - \dfrac{\eta^2}{n a^2 e}\dfrac{\partial F}{\partial e} - \dfrac{2}{na} \dfrac{\partial F}{\partial a}
	\end{array}\right.
	\label{eq:LPE}
	\end{equation} 
	%
	\indent It is common to express the force function $F$ as:
	%
	\[
	F = \dfrac{\mu}{r} + R - T = \dfrac{\mu }{2a} + R
	\]
	%
	\noindent where $R$ is the disturbing function, and comprises all terms except the central body acceleration ($\approx$ the two body part of the problem). Hence, the usual form of Lagrange Planetary Equations is:
	%
	\begin{equation}
	\left\{ \begin{array}{llll}
	\dfrac{da}{dt} 		& = \dfrac{2}{na} \dfrac{ \partial R}{\partial M} \\[1.2 em]
	\dfrac{de}{dt} 		& = \dfrac{\eta^2}{na^2 e} \dfrac{ \partial R}{\partial M} - \dfrac{\eta}{na^2e} \dfrac{\partial R}{\partial e} \\[1.2 em]
	\dfrac{di}{dt} 		& = \dfrac{\cos i}{na^2 \eta \sin i} \dfrac{ \partial R}{\partial \omega} - \dfrac{1}{na^2 \eta \sin i} \dfrac{\partial R}{\partial \Omega} \\[1.2 em]
	\dfrac{d\omega}{dt} & = -\dfrac{\cos i}{na^2 \eta \sin i} \dfrac{ \partial R}{\partial i} + \dfrac{\eta}{na^2  e} \dfrac{\partial R}{\partial e}\\[1.2 em]
	\dfrac{d\Omega}{dt} & = \dfrac{1}{na^2 \eta \sin i} \dfrac{ \partial R}{\partial i} \\[1.2 em]
	\dfrac{dM}{dt}		& = n - \dfrac{\eta^2}{n a^2 e}\dfrac{\partial R}{\partial e} - \dfrac{2}{na} \dfrac{\partial R}{\partial a}
	\end{array}\right.
	\label{eq:LPE_final}
	\end{equation} 
	%
	\indent As a side note, Wiesel \cite{Wiesel} provides yet another approach to obtain these equations in section 3.8.
	%
		\subsubsection{Delaunay elements from the LPEs.}\label{secAppE:Delaunay}
		%
		\indent The structure of equation \eqref{eqAppE:LPE_compact} as well as the symmetry of the Lagrangian brackets suggests that a simpler form of the LPEs may be reached, when using an adequate set of elements. In particular, consider a set of elements $L, G, H$ such that:
		%
		\begin{equation}
		\begin{array}{ccc}
		\left[M, L\right] = 1, 			& \left[M, G\right] = 0,		&  \left[M, H\right] = 0, \\
		\left[\omega, L\right] = 0, 	& \left[\omega, G\right] = 1,	&  \left[\omega, H\right] = 0, \\		
		\left[\Omega, L\right] = 0, 	& \left[\Omega, G\right] = 0,	&  \left[\Omega, H\right] = 1, 				
		\end{array}
		\label{eqAppE:Delaunay_1}
		\end{equation}
		%
		\indent In order to derive the expressions for $L, G$ and $H$, it is necessary to apply the definition of the Lagrangian brackets and the chain rule. For the case of $H$, and considering the already known bracket $[\Omega, i]$:
		%
		\[
		[\Omega, i] = [\Omega, L] \dfrac{\partial L}{\partial i} + [\Omega, G] \dfrac{\partial G}{\partial i} + [\Omega, H] \dfrac{\partial H}{\partial i} = [\Omega, H] \dfrac{\partial H}{\partial i} = \dfrac{\partial H}{\partial i}
		\]
		\[\Rightarrow \dfrac{\partial H}{\partial i} = [\Omega, i] = -na^2 \eta \sin i\]
		\[\Rightarrow H = na^2\eta \cos i\]
		
		%
		\indent As a check, the brackets $[\Omega, e]$ and $[\Omega, a]$ can be computed, while it is also possible to derive $H$ directly from them. Proceeding in an analog manner with $G$ and $L$ lead to:
		%
		\[G = na^2\eta, \qquad L = na^2\]
		%
		\indent The set $L, G, H, l = M, g = \omega, h = \Omega$ is the so-called Delaunay element set, matching the definition provided in appendix \ref{app:App_A}. To conclude, the LPEs for this set of elements become (by design):
		%
		\begin{equation}
		\left\{ \begin{array}{ccc}
		\dfrac{dL}{dt} = \dfrac{\partial F}{\partial l}\; , \qquad \dfrac{dl}{dt} = - \dfrac{\partial F}{\partial L} \\[1.2em]
		\dfrac{dG}{dt} = \dfrac{\partial F}{\partial g}\; , \qquad \dfrac{dg}{dt} = - \dfrac{\partial F}{\partial G} \\[1.2em]
		\dfrac{dH}{dt} = \dfrac{\partial F}{\partial h}\; , \qquad \dfrac{dh}{dt} = - \dfrac{\partial F}{\partial H}
		\end{array}\right. 
		\label{eqAppE:LPE_DOE}
		\end{equation}
		%
	\subsection{Gauss Variational Equations.}\label{secAppE:GVE}
	%
	\indent A possible drawback or limitation of the LPEs is that it assumes the existence of a force potential whose functional form is known. Nonetheless, there are some cases in which either only the force is modelled or it does not come from a potential field, as it happens with aerodynamic drag. Gauss Variational Equations involve only the components of the perturbing acceleration, allowing to model a wider spectrum of forces. Its derivation is also mathematically dense, as it can be seen in Wiesel \cite{Wiesel}, section 3.3. It involves several ``happy thoughts'' to reach the following expression:
	%
	\begin{equation}
	\left\{ \begin{array}{llll}
	\dfrac{d a}{d t}=&\dfrac{2 e \sin \theta}{n \eta} a_{r}+\dfrac{2 a \eta}{n r} a_{\theta} \\[1.2em]
	\dfrac{d e}{d t}=& \dfrac{\eta \sin \theta}{n a} a_{r}+\dfrac{\eta}{n a^{2} e}\left(\dfrac{a^{2}\eta^2}{r}-r\right) a_{\theta} \\[1.2em]
	\dfrac{d i}{d t}=&\dfrac{r \cos (\omega+\theta)}{n a^{2} \eta} a_{N} \\[1.2em]
	\dfrac{d \Omega}{d t}=&\dfrac{r \sin (\omega+\theta)}{n a^{2} \eta \sin i} a_{N} \\[1.2em]
	\dfrac{d \omega}{d t}=& -\dfrac{\eta \cos\theta}{nae}a_r - \dfrac{r\cot i\sin(\omega + \theta)}{na^2 \eta} a_N + \dfrac{\eta}{nae} \left( 1 + \dfrac{1}{1 + e\cos\theta}\right) \sin \theta a_{\theta}\\[1.2em]
	\dfrac{d M}{d t}=& n -\dfrac{1}{na} \left( \dfrac{2r}{a} - \dfrac{\eta^2 }{e}\cos\theta\right) a_r - \dfrac{\eta^2}{nae} \left( 1 + \dfrac{1}{1 + e\cos\theta}\right) \sin \theta a_{\theta}
	\end{array}\right.
	\label{eqAppE:GVE_Wiesel}
	\end{equation}
	%
	\noindent where $a_r, a_{\theta}$ and $a_N$ are the radial, azimuthal and normal (RTN) components of the acceleration on the spacecraft. This equations allow for a very intuitive evaluation of the cuantitative effects of a certain kind of acceleration. For example, it is clear that only an out-of-plane acceleration is able to change the inclination or the ascending node of the orbit. The problem of equation \eqref{eqAppE:GVE_Wiesel} is that, as it involves the use of the true anomaly $\theta$, it requires the solution of Kepler's equation at every timestep. Another option is to substitute the variational equation of the mean anomaly by its true anomaly equivalent, or even integrate the seven of them. \\
	%
	\indent To finalize, it should be remarked that both LPEs and GVEs as here presented become singular for null eccentricity and for equatorial/polar orbits, due to the in some sense poor election of the OEs. There are though several alternatives in the literature, in which LPEs and GVEs are expressed for non-singular elements, such as the Equinoctial elements or the Delaunay elements.
	%
\section{Elliptic anomaly mapping.}
%
\indent The parametrization of the elliptic motion of a spacecraft in its orbit plane may involve the use of three different angles: the true anomaly, the eccentric anomaly and the mean anomaly. Without stopping in its academic definitions, let's remark that the true anomaly is the most physically meaningful one, while the eccentric and the mean are basically mathematical constructs that simplify the motion parametrization.\\
%
\indent That being said, it is usually impossible -- or at least uncomfortable -- to use just one of them. That is why a mapping between them is required, as it is also recurrently used in the software side. 
%
	\subsection{Angles.}
	%
		\subsubsection{Eccentric to mean and viceversa.}
		%
		\indent The relation between mean and eccentric anomalies is more of a definition, as Kepler's equation states:
		%
		\begin{equation}
		M = E - \sin E
		\label{eqAppE:Kepler_equation}
		\end{equation}
		%
		\indent It is quite clear that the direct transformation (\ie $E\to  M$) is trivial. The inverse transformation is a bit more tricky. There is no closed-form solution for $E = E(M)$, so an alternative way must be developed. A common exact solution of said equation consists of an infinite series of Bessel functions, which is not handy or worth the calculation. However, a simple iterative scheme can be obtained, solving for the linear term $E$ and substituting the precedent value in the $\sin$ function. A usually good initial approximation is $E_0 = M$, although for highly eccentric orbit, $E_0 = \pi$ yields better results. In summary, this numeric method can be written as:
		%
		\begin{equation}
		[P] \equiv \left\{ \begin{array}{ll}
		E_{i + 1} = M + e \sin E_i \\[1.2em]
		E_0 = M
		\end{array}\right.
		\label{eqAppE:mean2ecc}
		\end{equation}
		%
		\indent This is called a fixed-point iteration. Of course, several other methods can be implemented (\eg Newton's Method).
		
		\subsubsection{True to eccentric and viceversa.}
		%
		\indent The position of the spacecraft in the perifocal frame can be parametrized by both the true and the eccentric anomaly:
		%
		\begin{equation}
		\left\{ \begin{array}{ll}
		X = r\cos\theta = \dfrac{a\eta^2\cos\theta}{1 + e\cos\theta} = a (\cos E - e)\\[1.2em]
		Y = r\sin\theta = \dfrac{a\eta^2\sin\theta}{1 + e\cos\theta} = b \sin E = a \eta \sin E
		\end{array}\right.
		\end{equation}
		%
		\indent These lead to a handy pair of equations for $\sin E$ and $\cos E$:
		%
		\begin{alignat}{4}[left = \empheqlbrace]
		\label{eqAppE:cosE}\cos E = \dfrac{e + \cos\theta}{1 + e\cos\theta}\\[1.2em]
		\label{eqAppE:sinE}\sin E = \dfrac{\eta \sin\theta}{1 + e\cos\theta}
		\end{alignat}
		%
		\indent In the seeking of a more concise relation between $E$ and $\theta$, they are substituted by their half angles, which after a little manipulation, leads to:
		%
		\begin{alignat}{4}[left = \empheqlbrace]
		\label{eqAppE:cosE_V2} 2 \cos^2 E/2 = 1 + \cos E = \dfrac{(1 + e) (1 + \cos \theta)}{1 + e\cos\theta} = \dfrac{(1 + e) 2\cos^2 \theta/2 }{1 + e\cos\theta}\\[1.2em]
		\label{eqAppE:sinE_V2}\sin E = 2 \sin E/2 \cos E/2 = \dfrac{\eta 2 \sin \theta/2 \cos \theta/2}{1 + e\cos\theta}
		\end{alignat}
		%
		\indent Dividing \eqref{eqAppE:sinE_V2} by \eqref{eqAppE:cosE_V2} and simplifying:
		%
		\begin{equation}
		\tan \dfrac{E}{2}= \dsqrt{\dfrac{1 - e}{1 + e}} \tan \dfrac{\theta}{2}
		\label{eqAppE:true2ecc}
		\end{equation}
		%
		\indent The inverse transformation is again trivial, by just solving for $\tan \theta/2$.
		%
		\subsubsection{True to mean and viceversa.}\label{secAppE:mean2true}
		%
		\indent As simple or absurd as it sounds, and although a closed form exists for the direct transformation (\ie $\theta \to M$), the simplest procedure is to just concatenate the transformations \eqref{eqAppE:true2ecc} and \eqref{eqAppE:Kepler_equation}.
		
	\subsection{Angle rates.}
	%
	\indent The eccentric and true anomaly rates are usually required, although the fact that they vary along any eccentric orbit makes them unpleasant to manipulate or integrate. In order to tackle their conversion to mean anomaly rate (or mean motion, which is constant along any unperturbed eccentric orbit) it is enough to calculate the time derivatives of the already prescribed equations, that is \cite[][appendix E]{Schaub_Junkins}:
	%
	\begin{itemize}
	\item[\GMVred{A.}] \myul[GMVred]{Mean to eccentric rate}: By differentiating in \eqref{eqAppE:Kepler_equation}, the sensitivity is obtained:
	%
	\begin{equation}
	\dfrac{dM}{dE} = 1 - e\cos E = \dfrac{\eta^2}{\rho} = \dfrac{r}{a}
	\label{eqAppE:dMdE}
	\end{equation}
	%
	\noindent where $\rho = 1 + e\cos\theta$ as usual. The relation between the mean and eccentric rates is obtained by simply using the chain rule:
	%
	\begin{equation}
	\dfrac{dM}{dt} = \dot{M} = n = \dfrac{dM}{dE}\dfrac{dE}{dt}\dfrac{\eta^2}{\rho} \dfrac{dE}{dt} \Rightarrow \dot{E} = \dfrac{\rho}{\eta^2} n
	\label{eqAppE:Edot}
	\end{equation}
	\item[\GMVred{B.}] \myul[GMVred]{Mean to true rate}: Differentiating \eqref{eqAppE:cosE} and rearranging terms, the sensitivity of the true anomaly with respect to the eccentric is obtained\cite{Schaub_Junkins}:
	%
	\begin{equation}
	\dfrac{d\theta}{dE} = \dfrac{\eta}{1 - e\cos E} = \dfrac{\rho}{\eta} = \dfrac{b}{r}
	\label{eqAppE:dthetadE}
	\end{equation}
	%
	\indent Combining \eqref{eqAppE:dthetadE} and \eqref{eqAppE:dMdE}, and taking time derivatives, it is pretty much straightaway to get $\dot{\theta}$:
	%
	\begin{equation}
	\dfrac{d\theta}{dt} = \dfrac{d\theta}{dE} \left(\dfrac{dM}{dE}\right)^{-1} \dfrac{dM}{dt} \Rightarrow \dot{\theta} = \dfrac{\rho^2}{\eta^3}n
	\label{eqAppE:thetadot}
	\end{equation}
	\end{itemize}
	
	\subsection{Relative anomalies.}
	%
	\indent Relative motion may be expressed through relative elements, hence relative anomalies. In order to convert them, one must keep in mind that the aforementioned transformations are defined for absolute values. That is, when converting relative anomalies, firstly the absolute values must be computed before they are transformed. For example, consider the transformation from relative eccentric anomaly to relative mean anomaly, assuming as inputs the relative value $\delta E$ and the absolute value of the chief $E_C$. The diagram shown in \ref{tikz:rel_anom_workflow} shows the process of this conversion.
	%
	\input{Appendices/Appendix_E/rel_anom_workflow}
	%
\section{Kaula's functions.}
%
\indent The developments of Kaula's theory, in particular, equations \eqref{eq:F_lmp} and \eqref{eq:G_lpq_Kaula}, as well as its derivatives \eqref{eq:dF_lmp} and \eqref{eq:dG_lpq}, can be computed for a given set of indices $lmpq$. Tables \ref{table:F_lmp}, \ref{table:dF_lmp} and \ref{table:G} include these functions for $l = \left\{2, 3, 4\right\}$, $m = \left\{0, 1, 2, 3, 4\right\}$, $p = \left\{0, 1, 2, 3, 4\right\}$ and $q  = \left\{-4, -3, -2, -1, 0, 1, 2, 3, 4\right\}$.
%
\input{Appendices/Appendix_E/Tables/Table_F_lmp}
\input{Appendices/Appendix_E/Tables/Table_dF_lmp}
\input{Appendices/Appendix_E/Tables/Table_G}
%
\section{Series expansions for $\beta$ and $e/\beta$.}
%
\indent In order to match the convenient formulation from Kaula for $G_{lpq}$ results, the series expansions for $\beta = e/(1 + \eta)$ and $e/\beta$ are now provided, as they appear recurrently in the $P_{lpqk}, G_{lpqk}, P_{k}$ and $Q_k$ functions. \\
%
	\subsection{$\beta$ series expansion.}\label{sec:Beta}
	%
	\indent Brouwer and Clemence \cite[][page 63]{Brouwer} show the series development of $\beta$ up to the seventh power ($\beta^7$) in terms of the eccentricity, retaining terms of up to seventh power ($e^7$). The results are shown next:
	%
	\begin{subequations}
	\label{eq:beta_exp}
	\begin{alignat}{4}[left = \empheqlbrace]
	& \beta = && \dfrac{1}{2} e + \dfrac{1}{8} e^3 + \dfrac{1}{16} e^5 + \dfrac{5}{128} e^7 + \mathcal{O}(e^8) \\
	& \beta^2 = && \dfrac{1}{4} e^2 + \dfrac{1}{8} e^4 + \dfrac{5}{64} e^6 + \mathcal{O}(e^8) \\
	& \beta^3 = && \dfrac{1}{8} e^3 + \dfrac{3}{32} e^5 + \dfrac{9}{128} e^7 + \mathcal{O}(e^8) \\
	& \beta^4 = && \dfrac{1}{16} e^4 + \dfrac{1}{16} e^6 + \mathcal{O}(e^8) \\
	& \beta^5 = &&  \dfrac{1}{32} e^5 + \dfrac{5}{128} e^7 + \mathcal{O}(e^8) \\
	& \beta^6 = && \dfrac{1}{64} e^6  + \mathcal{O}(e^8) \\
	& \beta^7 = && \dfrac{1}{128} e^7 + \mathcal{O}(e^8) 
	\end{alignat}
	\end{subequations}
	%
	\subsection{$e/\beta$ series expansion.}
	%
	\indent This series expansion is not explicitly mentioned, though it is necessary, as it is not directly derived from the $\beta$ expansion (at least in \textsc{Matlab}). Using \eqref{eq:beta_exp}, we arrive to the following result:
	%
	\begin{subequations}
	\label{eq:e_over_beta_exp}
	\begin{alignat}{4}[left = \empheqlbrace]
	& \left(\dfrac{e}{\beta}\right)		&&  = 2 	- \dfrac{1}{2} e^2 - \dfrac{5}{16} e^4 + \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^2  	&& = 4 	- 2 e^2 - \dfrac{9}{8} e^4 + \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^3  	&& = 8 	- 6 e^2 - \dfrac{27}{4} e^4 + \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^4  	&& = 16 	- 16 e^2 - 8 e^4 + \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^5 	&& = 32 	- 40 e^2 - 25 e^4 + \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^6 	&& = 64 	+ \mathcal{O}(e^6) \\
	& \left(\dfrac{e}{\beta}\right)^7  	&& = 128 	+ \mathcal{O}(e^6)
	\end{alignat}
	\end{subequations}
	%
	\indent Alternatively, these expansions can be carried out by using the identity $e/\beta = 1 + \eta = 1 + \sqrt{1 - e^2}$. Please note that terms of order greater than four will be neglected, coherently with Kaula's tables.
	%
%
%\section{Data sources.}
%
%