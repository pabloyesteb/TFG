\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {xchapter}{Resumen.}{iii}{chapter*.2}%
\addvspace {10\p@ }
\contentsline {xchapter}{Abstract.}{v}{chapter*.3}%
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction.}{xv}{chapter*.8}%
\addvspace {10\p@ }
\contentsline {xchapter}{The Validation Loop}{1}{chapter.1}%
\contentsline {table}{\numberline {1.1}{\ignorespaces Output of \autoref {algo:tt-split}.\relax }}{12}{table.caption.15}%
\contentsline {table}{\numberline {1.2}{\ignorespaces Voxel reference table\relax }}{12}{table.caption.16}%
\contentsline {table}{\numberline {1.3}{\ignorespaces Points outside voxel hypercube\relax }}{14}{table.caption.17}%
\contentsline {table}{\numberline {1.4}{\ignorespaces \texttt {reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.\relax }}{14}{table.caption.18}%
\contentsline {table}{\numberline {1.5}{\ignorespaces P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi ^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').\relax }}{16}{table.caption.19}%
\contentsline {table}{\numberline {1.6}{\ignorespaces P-values of the output variables distributions\relax }}{17}{table.caption.22}%
\contentsline {table}{\numberline {1.7}{\ignorespaces p-value results for the 2-sample Kolmogorov-Smirnov test performed on distributions showed in \autoref {fig:yvsydoublehist}. Hypothesis $H0$ is that ground true and predicted values both come from the same (unknown) distribution.\relax }}{25}{table.caption.29}%
\contentsline {table}{\numberline {1.8}{\ignorespaces P-values of the K-S test comparing the empirical sample of $P(e)$ to the theoretical distributions indicated in each column. The null hypothesis $H0$ (the empirical distribution has been sampled from the one figuring in a given column) is rejected when $p-\text {value}<0.05$.\relax }}{27}{table.caption.32}%
\contentsline {table}{\numberline {1.9}{\ignorespaces Outlier detection taking $e\sim JohnsonSU$ as $H0$. N.B. for this table the usual requirements for classifying a point as an outlier ($z\in \sigma \pm 3\mu $ for the z-score and significance $1-a\geq 95\%$ for the gESD) have been softened here for illustration purposes to $z\in \sigma \pm 1.2\mu $ and $a=0.45$ for both tests, respectively.\relax }}{29}{table.caption.35}%
\contentsline {table}{\numberline {1.10}{\ignorespaces Summary of bootstrapped error statistics. For the median, the Wilson-score\blx@tocontentsinit {0}\cite {wilson1927probable} is used for computing the confidence interval.\relax }}{31}{table.caption.37}%
\contentsline {table}{\numberline {1.11}{\ignorespaces Bootstrapped percentiles (\ordinalnum {1}, \ordinalnum {5}, \ordinalnum {10}, \ordinalnum {90}, \ordinalnum {95} and \ordinalnum {99}) of the residue distribution, calculated with a 95\% confidence interval using Wilson-score.\relax }}{32}{table.caption.38}%
\contentsline {table}{\numberline {1.12}{\ignorespaces P-values results from the one-way ANOVA test. The red labelled cells show that bias is found in output variable ''RF Net Tension'' for the input categorical variable ''dp'', as well as in output variable ''RF Forced Crippling'' for the input variable ''Stringer'' and in the output variables ''RF Net Tension'' and ''RF Pure Compression''. For the rest of the table's combinations, p-values greater than 0.05 indicate that $H0$ cannot be rejected with a statistical confidence of at least 95\%.\relax }}{38}{table.caption.41}%
\contentsline {table}{\numberline {1.13}{\ignorespaces Z-score results for biased categorical variables. One table is generated for each pair biased categorical input variable-output variable. Row labelled ''N'' shows the number of test points belonging to the specified input-output variable combination. Clearly, the bias is found for combinations where the number of test points is extremely low ({\it e.g.}\ 1). This suggests performing a revision of the dataset in order to find uncovered regions and isolated points, refilling those regions as needed, and re-training the model.\relax }}{39}{table.caption.42}%
\contentsline {table}{\numberline {1.14}{\ignorespaces Output of \autoref {algo:tt-split}: \texttt {reqs\_results} table\relax }}{46}{table.caption.43}%
\contentsline {table}{\numberline {1.15}{\ignorespaces Voxel reference table. Lorem ipsum dolor sit amet, consectetuer adisciping elit.\relax }}{47}{table.caption.44}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusions and research outlook.}{55}{chapter.2}%
\addvspace {10\p@ }
\contentsline {xchapter}{Absolute and relative orbital element sets.}{57}{appendix.A}%
