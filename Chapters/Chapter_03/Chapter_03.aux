\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The validation pipeline}{11}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{The validation pipeline}{11}{chapter.3}\protected@file@percent }
\@writefile{lot}{\contentsline {xchapter}{The validation pipeline}{11}{chapter.3}\protected@file@percent }
\newlabel{chap:Chap_1}{{3}{11}{The validation pipeline}{chapter.3}{}}
\newlabel{chap:Chap_1@cref}{{[chapter][3][]3}{[1][11][]11}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction2}{11}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Case of study}{11}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Surrogate model pipeline\relax }}{12}{figure.caption.23}\protected@file@percent }
\newlabel{fig:diagrama_cajas}{{3.1}{12}{Surrogate model pipeline\relax }{figure.caption.23}{}}
\newlabel{fig:diagrama_cajas@cref}{{[figure][1][3]3.1}{[1][11][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Overview}{12}{subsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Validation pipeline\relax }}{12}{figure.caption.24}\protected@file@percent }
\newlabel{fig:pipeline}{{3.2}{12}{Validation pipeline\relax }{figure.caption.24}{}}
\newlabel{fig:pipeline@cref}{{[figure][2][3]3.2}{[1][11][]12}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Train-test split}{13}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Preliminaries}{13}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Location of the train-test split assessment in the overall validation pipeline\relax }}{13}{figure.caption.25}\protected@file@percent }
\newlabel{fig:esquemattsplit}{{3.3}{13}{Location of the train-test split assessment in the overall validation pipeline\relax }{figure.caption.25}{}}
\newlabel{fig:esquemattsplit@cref}{{[figure][3][3]3.3}{[1][13][]13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Validation loop for the train-test split}{14}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.1}Geometrical analysis}{14}{subsubsection.3.2.2.1}\protected@file@percent }
\pp@spagectr{FN@totalid}{5}{1}{15}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Train-test split geometrical analysis\relax }}{17}{algocf.1}\protected@file@percent }
\newlabel{algo:tt-split}{{1}{17}{Geometrical analysis}{algocf.1}{}}
\newlabel{algo:tt-split@cref}{{[algorithm][1][]1}{[1][14][]17}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Output of \autoref  {algo:tt-split}.\relax }}{18}{table.caption.27}\protected@file@percent }
\newlabel{tab:geo_out}{{3.1}{18}{Output of \autoref {algo:tt-split}.\relax }{table.caption.27}{}}
\newlabel{tab:geo_out@cref}{{[table][1][3]3.1}{[1][14][]18}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Voxel reference table\relax }}{18}{table.caption.28}\protected@file@percent }
\newlabel{tab:voxref}{{3.2}{18}{Voxel reference table\relax }{table.caption.28}{}}
\newlabel{tab:voxref@cref}{{[table][2][3]3.2}{[1][14][]18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.2}Non-geometrical analysis}{19}{subsubsection.3.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Points outside voxel hypercube\relax }}{20}{table.caption.29}\protected@file@percent }
\newlabel{tab:outhypercube}{{3.3}{20}{Points outside voxel hypercube\relax }{table.caption.29}{}}
\newlabel{tab:outhypercube@cref}{{[table][3][3]3.3}{[1][19][]20}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces \texttt  {reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.\relax }}{20}{table.caption.30}\protected@file@percent }
\newlabel{tab:reqsresults}{{3.4}{20}{\texttt {reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.\relax }{table.caption.30}{}}
\newlabel{tab:reqsresults@cref}{{[table][4][3]3.4}{[1][19][]20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2.3}Train-test split. Conclusions}{21}{subsubsection.3.2.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi ^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').\relax }}{22}{table.caption.31}\protected@file@percent }
\newlabel{tab:pvalin}{{3.5}{22}{P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi ^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').\relax }{table.caption.31}{}}
\newlabel{tab:pvalin@cref}{{[table][5][3]3.5}{[1][21][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.\relax }}{23}{figure.caption.32}\protected@file@percent }
\newlabel{fig:inputsdhist}{{3.4}{23}{Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.\relax }{figure.caption.32}{}}
\newlabel{fig:inputsdhist@cref}{{[figure][4][3]3.4}{[1][21][]23}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces P-values of the output variables distributions\relax }}{23}{table.caption.34}\protected@file@percent }
\newlabel{tab:pvalout}{{3.6}{23}{P-values of the output variables distributions\relax }{table.caption.34}{}}
\newlabel{tab:pvalout@cref}{{[table][6][3]3.6}{[1][21][]23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Input categorical variables distributions double histograms\relax }}{24}{figure.caption.33}\protected@file@percent }
\newlabel{fig:inputscatdhist}{{3.5}{24}{Input categorical variables distributions double histograms\relax }{figure.caption.33}{}}
\newlabel{fig:inputscatdhist@cref}{{[figure][5][3]3.5}{[1][21][]24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Output variables distributions double histograms\relax }}{24}{figure.caption.35}\protected@file@percent }
\newlabel{fig:outputsdhist}{{3.6}{24}{Output variables distributions double histograms\relax }{figure.caption.35}{}}
\newlabel{fig:outputsdhist@cref}{{[figure][6][3]3.6}{[1][21][]24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Requirements of the geometrical analysis\relax }}{25}{figure.caption.36}\protected@file@percent }
\newlabel{fig:coloreqs_table}{{3.7}{25}{Requirements of the geometrical analysis\relax }{figure.caption.36}{}}
\newlabel{fig:coloreqs_table@cref}{{[figure][7][3]3.7}{[1][21][]25}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Global error quantification}{26}{section.3.3}\protected@file@percent }
\newlabel{eq:residue}{{3.1}{26}{Global error quantification}{equation.3.3.1}{}}
\newlabel{eq:residue@cref}{{[equation][1][3]3.1}{[1][26][]26}}
\pp@spagectr{FN@totalid}{6}{1}{26}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Scatter plot of ground true ($x$ axis) against predicted values ($y$ axis) of output variable ''RF Net Tension'', with the correspondent $R^2$ coefficient. In this case, $R^2=1,000$ indicates a perfect fit of predicted to ground true values. Mismatches due to underestimating failure risk are labelled in red, while those due to overestimating failure risk are labelled in blue. Similar graphs can be computed for every pair $\left \{y_j,\hat  {y}_j\right \}$ of features in the output variables $\mathbf  {Y}=\left \{y_1,y_2,\ldots  ,y_m\right \}$. Plots for the rest of the six output variables of MS-S18 show analogous results.\relax }}{27}{figure.caption.38}\protected@file@percent }
\newlabel{fig:truevspredscatter}{{3.8}{27}{Scatter plot of ground true ($x$ axis) against predicted values ($y$ axis) of output variable ''RF Net Tension'', with the correspondent $R^2$ coefficient. In this case, $R^2=1,000$ indicates a perfect fit of predicted to ground true values. Mismatches due to underestimating failure risk are labelled in red, while those due to overestimating failure risk are labelled in blue. Similar graphs can be computed for every pair $\left \{y_j,\hat {y}_j\right \}$ of features in the output variables $\mathbf {Y}=\left \{y_1,y_2,\ldots ,y_m\right \}$. Plots for the rest of the six output variables of MS-S18 show analogous results.\relax }{figure.caption.38}{}}
\newlabel{fig:truevspredscatter@cref}{{[figure][8][3]3.8}{[1][26][]27}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Distributed error quantification.}{28}{section.3.4}\protected@file@percent }
\newlabel{sec:disterr}{{3.4}{28}{Distributed error quantification}{section.3.4}{}}
\newlabel{sec:disterr@cref}{{[section][4][3]3.4}{[1][28][]28}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Location of \autoref  {sec:globalerr} in the validation pipeline.\relax }}{28}{figure.caption.39}\protected@file@percent }
\newlabel{fig:globalerrpipeline}{{3.9}{28}{Location of \autoref {sec:globalerr} in the validation pipeline.\relax }{figure.caption.39}{}}
\newlabel{fig:globalerrpipeline@cref}{{[figure][9][3]3.9}{[1][28][]28}}
\pp@spagectr{FN@totalid}{7}{1}{28}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Non gaussian error distribution}\\}{28}{figure.caption.39}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Outlier detection}\\}{29}{figure.caption.39}\protected@file@percent }
\newlabel{par:outliers}{{3.4}{29}{\GMVred {B.} \myul [GMVred]{Outlier detection}\label {par:outliers}\\}{figure.caption.39}{}}
\newlabel{par:outliers@cref}{{[section][4][3]3.4}{[1][29][]29}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Uncertainty measuring}\\}{29}{figure.caption.39}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Double histogram depicting ground true values and model's predictions for the six output variables of MS-18.\relax }}{30}{figure.caption.40}\protected@file@percent }
\newlabel{fig:yvsydoublehist}{{3.10}{30}{Double histogram depicting ground true values and model's predictions for the six output variables of MS-18.\relax }{figure.caption.40}{}}
\newlabel{fig:yvsydoublehist@cref}{{[figure][10][3]3.10}{[1][29][]30}}
\pp@spagectr{FN@totalid}{8}{1}{30}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Resulting $p$-values from the 2-sample K-S test of goodness of fit between ground true ($\mathbf  {Y}$) and predicted ($\mathbf  {\hat  {Y}}$) distributions. The null hypothesis $H0$ that both distributions conform is rejected if the $p$-value is smaller than $0.05$.\relax }}{31}{table.caption.41}\protected@file@percent }
\newlabel{tab:yvsyKS}{{3.7}{31}{Resulting $p$-values from the 2-sample K-S test of goodness of fit between ground true ($\mathbf {Y}$) and predicted ($\mathbf {\hat {Y}}$) distributions. The null hypothesis $H0$ that both distributions conform is rejected if the $p$-value is smaller than $0.05$.\relax }{table.caption.41}{}}
\newlabel{tab:yvsyKS@cref}{{[table][7][3]3.7}{[1][29][]31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Empirical residue distribution sampled from the test set, for each of the six output variables of MS-S18. $x$-axis limits have been truncated to $\mu \pm 3 \sigma $, where the most part of the error lies. Histograms have been appropriately binned for a correct visualization.\relax }}{32}{figure.caption.42}\protected@file@percent }
\newlabel{fig:pdferror}{{3.11}{32}{Empirical residue distribution sampled from the test set, for each of the six output variables of MS-S18. $x$-axis limits have been truncated to $\mu \pm 3 \sigma $, where the most part of the error lies. Histograms have been appropriately binned for a correct visualization.\relax }{figure.caption.42}{}}
\newlabel{fig:pdferror@cref}{{[figure][11][3]3.11}{[1][29][]32}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Cumulative error distributions corresponding to the PDFs showed (as binned histograms) in \autoref  {fig:pdferror}.\relax }}{32}{figure.caption.43}\protected@file@percent }
\newlabel{fig:errorcumulative}{{3.12}{32}{Cumulative error distributions corresponding to the PDFs showed (as binned histograms) in \autoref {fig:pdferror}.\relax }{figure.caption.43}{}}
\newlabel{fig:errorcumulative@cref}{{[figure][12][3]3.12}{[1][29][]32}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces P-values of the K-S test comparing the empirical sample of $P(e)$ to the theoretical distributions indicated in each column. The null hypothesis $H0$ (the empirical distribution has been sampled from the one figuring in a given column) is rejected when $p-\text  {value}<0.05$.\relax }}{33}{table.caption.44}\protected@file@percent }
\newlabel{tab:KSerror}{{3.8}{33}{P-values of the K-S test comparing the empirical sample of $P(e)$ to the theoretical distributions indicated in each column. The null hypothesis $H0$ (the empirical distribution has been sampled from the one figuring in a given column) is rejected when $p-\text {value}<0.05$.\relax }{table.caption.44}{}}
\newlabel{tab:KSerror@cref}{{[table][8][3]3.8}{[1][31][]33}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces Graphical comparison of the p-values resulting from the K-S test for the MS-18 data.\relax }}{34}{figure.caption.45}\protected@file@percent }
\newlabel{fig:errorpvalues}{{3.13}{34}{Graphical comparison of the p-values resulting from the K-S test for the MS-18 data.\relax }{figure.caption.45}{}}
\newlabel{fig:errorpvalues@cref}{{[figure][13][3]3.13}{[1][31][]34}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces (Binned) histograms depicting the distribution of the variable $z=\gamma +\qopname  \relax o{sinh}{\frac  {e-\xi }{\lambda }}$, where $e\sim JohnsonSU(\gamma ,\delta ,\xi ,\lambda )$ is the sampled residue. It can be shown that $z$ converges to a normal distribution\blx@tocontentsinit {0}\cite {jones2009sinh}.\relax }}{34}{figure.caption.46}\protected@file@percent }
\newlabel{fig:ztransform}{{3.14}{34}{(Binned) histograms depicting the distribution of the variable $z=\gamma +\sinh {\frac {e-\xi }{\lambda }}$, where $e\sim JohnsonSU(\gamma ,\delta ,\xi ,\lambda )$ is the sampled residue. It can be shown that $z$ converges to a normal distribution\cite {jones2009sinh}.\relax }{figure.caption.46}{}}
\newlabel{fig:ztransform@cref}{{[figure][14][3]3.14}{[1][31][]34}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Outlier detection taking $e\sim JohnsonSU$ as $H0$. N.B. for this table the usual requirements for classifying a point as an outlier ($z\in \sigma \pm 3\mu $ for the z-score and significance $1-a\geq 95\%$ for the gESD) have been softened here for illustration purposes to $z\in \sigma \pm 1.2\mu $ and $a=0.45$ for both tests, respectively.\relax }}{35}{table.caption.47}\protected@file@percent }
\newlabel{tab:outliers}{{3.9}{35}{Outlier detection taking $e\sim JohnsonSU$ as $H0$. N.B. for this table the usual requirements for classifying a point as an outlier ($z\in \sigma \pm 3\mu $ for the z-score and significance $1-a\geq 95\%$ for the gESD) have been softened here for illustration purposes to $z\in \sigma \pm 1.2\mu $ and $a=0.45$ for both tests, respectively.\relax }{table.caption.47}{}}
\newlabel{tab:outliers@cref}{{[table][9][3]3.9}{[1][31][]35}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Non-parametric bootstrapping\relax }}{36}{algocf.2}\protected@file@percent }
\newlabel{algo:bootstrapping}{{2}{36}{\GMVred {C.} \myul [GMVred]{Uncertainty measuring}\\}{algocf.2}{}}
\newlabel{algo:bootstrapping@cref}{{[algorithm][2][]2}{[1][36][]36}}
\newlabel{RF1}{38}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Summary of bootstrapped error statistics. For the median, the Wilson-score\blx@tocontentsinit {0}\cite {wilson1927probable} is used for computing the confidence interval.\relax }}{38}{table.caption.49}\protected@file@percent }
\newlabel{tab:errorstats}{{3.10}{38}{Summary of bootstrapped error statistics. For the median, the Wilson-score\cite {wilson1927probable} is used for computing the confidence interval.\relax }{table.caption.49}{}}
\newlabel{tab:errorstats@cref}{{[table][10][3]3.10}{[1][36][]38}}
\newlabel{RF2}{39}
\@writefile{lot}{\contentsline {table}{\numberline {3.11}{\ignorespaces Bootstrapped percentiles (\ordinalnum {1}, \ordinalnum {5}, \ordinalnum {10}, \ordinalnum {90}, \ordinalnum {95} and \ordinalnum {99}) of the residue distribution, calculated with a 95\% confidence interval using Wilson-score.\relax }}{39}{table.caption.50}\protected@file@percent }
\newlabel{tab:basicuncertainty}{{3.11}{39}{Bootstrapped percentiles (\ordinalnum {1}, \ordinalnum {5}, \ordinalnum {10}, \ordinalnum {90}, \ordinalnum {95} and \ordinalnum {99}) of the residue distribution, calculated with a 95\% confidence interval using Wilson-score.\relax }{table.caption.50}{}}
\newlabel{tab:basicuncertainty@cref}{{[table][11][3]3.11}{[1][36][]39}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Distributed error quantification: conditioning the error distribution on the input space}{40}{section.3.5}\protected@file@percent }
\newlabel{sec:biasinput}{{3.5}{40}{Distributed error quantification: conditioning the error distribution on the input space}{section.3.5}{}}
\newlabel{sec:biasinput@cref}{{[section][5][3]3.5}{[1][40][]40}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces Box diagram showing the relative position of \autoref  {sec:biasinput} in the complete validation pipeline.\relax }}{40}{figure.caption.51}\protected@file@percent }
\newlabel{fig:biasinputbox}{{3.15}{40}{Box diagram showing the relative position of \autoref {sec:biasinput} in the complete validation pipeline.\relax }{figure.caption.51}{}}
\newlabel{fig:biasinputbox@cref}{{[figure][15][3]3.15}{[1][40][]40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Visualization of error as a function of categorical (discrete) input variables}{41}{subsection.3.5.1}\protected@file@percent }
\newlabel{fig:boxwhisker1}{{3.16(a)}{42}{Error conditioned to the categorical variable ''Frame''\relax }{figure.caption.52}{}}
\newlabel{fig:boxwhisker1@cref}{{[subfigure][1][3,16]3.16(a)}{[1][41][]42}}
\newlabel{sub@fig:boxwhisker1}{{(a)}{42}{Error conditioned to the categorical variable ''Frame''\relax }{figure.caption.52}{}}
\newlabel{sub@fig:boxwhisker1@cref}{{[subfigure][1][3,16]3.16(a)}{[1][41][]42}}
\newlabel{fig:boxwhisker2}{{3.16(b)}{42}{Error conditioned to the categorical variable ''Stringer''\relax }{figure.caption.52}{}}
\newlabel{fig:boxwhisker2@cref}{{[subfigure][2][3,16]3.16(b)}{[1][41][]42}}
\newlabel{sub@fig:boxwhisker2}{{(b)}{42}{Error conditioned to the categorical variable ''Stringer''\relax }{figure.caption.52}{}}
\newlabel{sub@fig:boxwhisker2@cref}{{[subfigure][2][3,16]3.16(b)}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces Box and whisker plots depicting the residue conditioned to two different categorical variables. \autoref  {fig:boxwhisker1}: ''Frame''. \autoref  {fig:boxwhisker2}: ''Stringer''. Clearly, outliers can be appreciated in both cases (''Fr69-Fr70'' in \autoref  {fig:boxwhisker1}, and various stringers in \autoref  {fig:boxwhisker2}).\relax }}{42}{figure.caption.52}\protected@file@percent }
\newlabel{fig:boxwhisker}{{3.16}{42}{Box and whisker plots depicting the residue conditioned to two different categorical variables. \autoref {fig:boxwhisker1}: ''Frame''. \autoref {fig:boxwhisker2}: ''Stringer''. Clearly, outliers can be appreciated in both cases (''Fr69-Fr70'' in \autoref {fig:boxwhisker1}, and various stringers in \autoref {fig:boxwhisker2}).\relax }{figure.caption.52}{}}
\newlabel{fig:boxwhisker@cref}{{[figure][16][3]3.16}{[1][41][]42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Bias detection and quantification (1D)}{43}{subsection.3.5.2}\protected@file@percent }
\newlabel{subsec:biasinput1d}{{3.5.2}{43}{Bias detection and quantification (1D)}{subsection.3.5.2}{}}
\newlabel{subsec:biasinput1d@cref}{{[subsection][2][3,5]3.5.2}{[1][43][]43}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Detection of error bias in single categories (ANOVA)}\\}{43}{subsection.3.5.2}\protected@file@percent }
\pp@spagectr{FN@totalid}{9}{1}{43}
\@writefile{lot}{\contentsline {table}{\numberline {3.12}{\ignorespaces P-values results from the one-way ANOVA test. The red labelled cells show that variable ''dp'' shows bias for the residual distribution of ''RF Net Tension'', as well as variable ''Frame'' for the residual distribution of ''RF Forced Crippling'' and variable''Stringer'' for the residual distributions of ''RF Net Tension'' and ''RF Pure Compression''. For the rest of the table, p-values greater than 0.05 indicate that $H0$ cannot be rejected with a statistical confidence of at least 95\%.\relax }}{44}{table.caption.53}\protected@file@percent }
\newlabel{tab:1anova}{{3.12}{44}{P-values results from the one-way ANOVA test. The red labelled cells show that variable ''dp'' shows bias for the residual distribution of ''RF Net Tension'', as well as variable ''Frame'' for the residual distribution of ''RF Forced Crippling'' and variable''Stringer'' for the residual distributions of ''RF Net Tension'' and ''RF Pure Compression''. For the rest of the table, p-values greater than 0.05 indicate that $H0$ cannot be rejected with a statistical confidence of at least 95\%.\relax }{table.caption.53}{}}
\newlabel{tab:1anova@cref}{{[table][12][3]3.12}{[1][43][]44}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Quantification of error bias in single categories test no. 1: based on error mean outlier}\\}{44}{table.caption.53}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.13}{\ignorespaces Z-score results for biased categorical variables. One table is generated for each pair biased categorical input variable-output variable.\relax }}{45}{table.caption.54}\protected@file@percent }
\newlabel{tab:zscore}{{3.13}{45}{Z-score results for biased categorical variables. One table is generated for each pair biased categorical input variable-output variable.\relax }{table.caption.54}{}}
\newlabel{tab:zscore@cref}{{[table][13][3]3.13}{[1][45][]45}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Quantification of error bias in single categories test no. 2: based on error variance outlier}\\}{45}{table.caption.54}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}D.} \myul [GMVred]{Quantification of error bias in single categories test no. 3: based on identification of linear trend}\\}{46}{table.caption.54}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces Quantification of linear trend for input categorical variables ''Stringer'' (left) and ''Frame'' (right). Variables have been numerically encoded following a logical order ({\it  e.g.}\ in the right image, six integers in the $x$ axis represent the six possible values of variable Frame). The residue of output variable ''RF Net Tension'' has been plotted against the categorical variable ($y$ axis). In this case, no linear trend is appreciated in neither of the two input variables (no bias present).\relax }}{47}{figure.caption.55}\protected@file@percent }
\newlabel{fig:linearcat}{{3.17}{47}{Quantification of linear trend for input categorical variables ''Stringer'' (left) and ''Frame'' (right). Variables have been numerically encoded following a logical order (\eg in the right image, six integers in the $x$ axis represent the six possible values of variable Frame). The residue of output variable ''RF Net Tension'' has been plotted against the categorical variable ($y$ axis). In this case, no linear trend is appreciated in neither of the two input variables (no bias present).\relax }{figure.caption.55}{}}
\newlabel{fig:linearcat@cref}{{[figure][17][3]3.17}{[1][46][]47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Bias detection and quantification (2D)}{47}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Bias detection (2D)}\\}{47}{subsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Bias quantification (2D)}\\}{48}{subsection.3.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.14}{\ignorespaces 2D bias quantification: Results from mean and variance $z$-score tests on biased Stringer-Frame input pairs (bias detection has been performed through 1-way ANOVA). For the input value combinations showed in the columns, either mean or variance (or both) show bias (weak: $z\text  {-score}<3$. Strong: $z\text  {-score}>3$). For the combination of Frame Fr67-Fr69 and Stringer Str07, there are not enough test points to compute the $z$-score variance test.\relax }}{48}{table.caption.56}\protected@file@percent }
\newlabel{tab:2dbiascat}{{3.14}{48}{2D bias quantification: Results from mean and variance $z$-score tests on biased Stringer-Frame input pairs (bias detection has been performed through 1-way ANOVA). For the input value combinations showed in the columns, either mean or variance (or both) show bias (weak: $z\text {-score}<3$. Strong: $z\text {-score}>3$). For the combination of Frame Fr67-Fr69 and Stringer Str07, there are not enough test points to compute the $z$-score variance test.\relax }{table.caption.56}{}}
\newlabel{tab:2dbiascat@cref}{{[table][14][3]3.14}{[1][48][]48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Visualization of error as a function of numerical (continuous) input variables}{49}{subsection.3.5.4}\protected@file@percent }
\newlabel{fig:imagen1}{{\caption@xref {fig:imagen1}{ on input line 651}}{49}{Visualization of error as a function of numerical (continuous) input variables}{figure.caption.57}{}}
\newlabel{fig:imagen1@cref}{{[subsection][4][3,5]3.5.4}{[1][48][]49}}
\newlabel{fig:imagen2}{{\caption@xref {fig:imagen2}{ on input line 657}}{49}{Visualization of error as a function of numerical (continuous) input variables}{figure.caption.57}{}}
\newlabel{fig:imagen2@cref}{{[subsection][4][3,5]3.5.4}{[1][48][]49}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Scatter plots of residue against a particular numerical input variable. Left: Input var. FU.0420.26. A linear trend is appreciated, suggesting the model makes worse predictions as input load ''FU.0420.26'' is larger. Right: input var. FU.0420.25. No linear trend is appreciated, although severe heteroscedasticity can be observed. Note the vertical bar arrangement, showing particular input loads for which dispersion is unusually large. In view of the former results, the engineer may decide to investigate the underlying causes both for the linear trend in the left and for heteroscedasticity on the right. With the information, model and data boosting may be performed. More training data could be decided to be sampled in the range of $[20000,60000]$ of FU.0420.26, for instance, and some regularization technique could be tried for the loss function in order to penalise inputs triggering high variance observed in the right.\relax }}{49}{figure.caption.57}\protected@file@percent }
\newlabel{fig:binputscatter}{{3.18}{49}{Scatter plots of residue against a particular numerical input variable. Left: Input var. FU.0420.26. A linear trend is appreciated, suggesting the model makes worse predictions as input load ''FU.0420.26'' is larger. Right: input var. FU.0420.25. No linear trend is appreciated, although severe heteroscedasticity can be observed. Note the vertical bar arrangement, showing particular input loads for which dispersion is unusually large. In view of the former results, the engineer may decide to investigate the underlying causes both for the linear trend in the left and for heteroscedasticity on the right. With the information, model and data boosting may be performed. More training data could be decided to be sampled in the range of $[20000,60000]$ of FU.0420.26, for instance, and some regularization technique could be tried for the loss function in order to penalise inputs triggering high variance observed in the right.\relax }{figure.caption.57}{}}
\newlabel{fig:binputscatter@cref}{{[figure][18][3]3.18}{[1][48][]49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.5}Bias detection and quantification}{49}{subsection.3.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Detection of linear trends for individual numerical variables}\\}{50}{subsection.3.5.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.15}{\ignorespaces Bias detection and quantification on numerical input variables (the results for just five input variables are shown here -- in columns--): P-value (statistical significance of the hypothesis that the variable is biased), Pearson coefficient, and slope of the best linear fit are shown in the first three rows. The last row shows the message ''Biased'' in case the $p\text  {-value}>0.05$, ''NO'' otherwise. Data from this table corresponds to residue of the output variable ''RF Column Buckling''. Analogous tables exist for the rest of the output variables.\relax }}{50}{table.caption.58}\protected@file@percent }
\newlabel{tab:lintrend}{{3.15}{50}{Bias detection and quantification on numerical input variables (the results for just five input variables are shown here -- in columns--): P-value (statistical significance of the hypothesis that the variable is biased), Pearson coefficient, and slope of the best linear fit are shown in the first three rows. The last row shows the message ''Biased'' in case the $p\text {-value}>0.05$, ''NO'' otherwise. Data from this table corresponds to residue of the output variable ''RF Column Buckling''. Analogous tables exist for the rest of the output variables.\relax }{table.caption.58}{}}
\newlabel{tab:lintrend@cref}{{[table][15][3]3.15}{[1][50][]50}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Discretizing continuous variables}\\}{50}{table.caption.58}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.16}{\ignorespaces 1-way ANOVA test results (p-values) for binned numerical input variables. For the output variable ''RF Forced Crippling'', bias is found in the input variables ''FU.0420.25'' and ''FU.0430.25''. Similarly, for the output variable ''RF Net Tension'', bias is found in the input variable ''FU.0430.15''. \relax }}{51}{table.caption.59}\protected@file@percent }
\newlabel{tab:anovanum}{{3.16}{51}{1-way ANOVA test results (p-values) for binned numerical input variables. For the output variable ''RF Forced Crippling'', bias is found in the input variables ''FU.0420.25'' and ''FU.0430.25''. Similarly, for the output variable ''RF Net Tension'', bias is found in the input variable ''FU.0430.15''. \relax }{table.caption.59}{}}
\newlabel{tab:anovanum@cref}{{[table][16][3]3.16}{[1][50][]51}}
\@writefile{lot}{\contentsline {table}{\numberline {3.17}{\ignorespaces Bias quantification in binned FU.0430.15 input variable. Columns represents bins showing bias. The same quantification methods employed for categorical variables (z-score for mean and variance outlier detection) have been used.\relax }}{52}{table.caption.60}\protected@file@percent }
\newlabel{tab:anovabins}{{3.17}{52}{Bias quantification in binned FU.0430.15 input variable. Columns represents bins showing bias. The same quantification methods employed for categorical variables (z-score for mean and variance outlier detection) have been used.\relax }{table.caption.60}{}}
\newlabel{tab:anovabins@cref}{{[table][17][3]3.17}{[1][50][]52}}
\@writefile{lot}{\contentsline {table}{\numberline {3.18}{\ignorespaces Summary of binned input variables bias quantification after binning the numerical variables and performing one-way ANOVA and z-score tests to every bin.\relax }}{52}{table.caption.61}\protected@file@percent }
\newlabel{tab:zscorenum1}{{3.18}{52}{Summary of binned input variables bias quantification after binning the numerical variables and performing one-way ANOVA and z-score tests to every bin.\relax }{table.caption.61}{}}
\newlabel{tab:zscorenum1@cref}{{[table][18][3]3.18}{[1][50][]52}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Distributed error quantification: conditioning the error distribution on the output space}{54}{section.3.6}\protected@file@percent }
\newlabel{sec:biasoutput}{{3.6}{54}{Distributed error quantification: conditioning the error distribution on the output space}{section.3.6}{}}
\newlabel{sec:biasoutput@cref}{{[section][6][3]3.6}{[1][54][]54}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Relative position of \autoref  {sec:biasoutput} in the complete validation pipeline.\relax }}{54}{figure.caption.62}\protected@file@percent }
\newlabel{fig:boutpipeline}{{3.19}{54}{Relative position of \autoref {sec:biasoutput} in the complete validation pipeline.\relax }{figure.caption.62}{}}
\newlabel{fig:boutpipeline@cref}{{[figure][19][3]3.19}{[1][54][]54}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Goodness of fit of the error distribution (test set previously filtered) to some parametrised distributions. The test is performed individually for the output variables (Reserve Factors) displayed on top of each image. The goodness of fit is assessed with a 1-variable K-S test. The test set is filtered using the x axis, rejecting every point whose output $\hat  {y}$ is larger than $x$. If the p-value resulting from the K-S test in the filtered test set is greater than $0.05$, the vertical slice at position $x$ is labelled green (red if $p\text  {-value}<0.05$, grey if less than a threshold number of points --namely, 30-- are present in the filtered test set).\relax }}{56}{figure.caption.63}\protected@file@percent }
\newlabel{fig:localfits}{{3.20}{56}{Goodness of fit of the error distribution (test set previously filtered) to some parametrised distributions. The test is performed individually for the output variables (Reserve Factors) displayed on top of each image. The goodness of fit is assessed with a 1-variable K-S test. The test set is filtered using the x axis, rejecting every point whose output $\hat {y}$ is larger than $x$. If the p-value resulting from the K-S test in the filtered test set is greater than $0.05$, the vertical slice at position $x$ is labelled green (red if $p\text {-value}<0.05$, grey if less than a threshold number of points --namely, 30-- are present in the filtered test set).\relax }{figure.caption.63}{}}
\newlabel{fig:localfits@cref}{{[figure][20][3]3.20}{[1][54][]56}}
\@writefile{lot}{\contentsline {table}{\numberline {3.19}{\ignorespaces Binnarization of the test set. The test set has been divided into ten bins according to output values. Extremes of the six intervals --one for each Reserve Factor-- defining the bins are shown below.\relax }}{57}{table.caption.64}\protected@file@percent }
\newlabel{tab:ybins}{{3.19}{57}{Binnarization of the test set. The test set has been divided into ten bins according to output values. Extremes of the six intervals --one for each Reserve Factor-- defining the bins are shown below.\relax }{table.caption.64}{}}
\newlabel{tab:ybins@cref}{{[table][19][3]3.19}{[1][54][]57}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces Line plot of the $p$-value from the true-predicted distributions under a 2 sample K-S test. Distribution similarity is rejected if $p\text  {-value}<0.05$.\relax }}{58}{figure.caption.65}\protected@file@percent }
\newlabel{fig:binpvals}{{3.21}{58}{Line plot of the $p$-value from the true-predicted distributions under a 2 sample K-S test. Distribution similarity is rejected if $p\text {-value}<0.05$.\relax }{figure.caption.65}{}}
\newlabel{fig:binpvals@cref}{{[figure][21][3]3.21}{[1][54][]58}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces Violin plots showing the absolute value residue for every bin.\relax }}{59}{figure.caption.66}\protected@file@percent }
\newlabel{fig:violins}{{3.22}{59}{Violin plots showing the absolute value residue for every bin.\relax }{figure.caption.66}{}}
\newlabel{fig:violins@cref}{{[figure][22][3]3.22}{[1][54][]59}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Sliced-bar with p-values from the binned error under a K-S test to assess the goodness of fit to several parametrised distributions.\relax }}{60}{figure.caption.67}\protected@file@percent }
\newlabel{fig:binfits}{{3.23}{60}{Sliced-bar with p-values from the binned error under a K-S test to assess the goodness of fit to several parametrised distributions.\relax }{figure.caption.67}{}}
\newlabel{fig:binfits@cref}{{[figure][23][3]3.23}{[1][56][]60}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Uncertainty model}{62}{section.3.7}\protected@file@percent }
\newlabel{sec:uncertainty}{{3.7}{62}{Uncertainty model}{section.3.7}{}}
\newlabel{sec:uncertainty@cref}{{[section][7][3]3.7}{[1][62][]62}}
\newlabel{num:disterr}{{1}{62}{Uncertainty model}{Item.5}{}}
\newlabel{num:disterr@cref}{{[enumi][1][]1}{[1][62][]62}}
\newlabel{num:biasoutput}{{2}{62}{Uncertainty model}{Item.6}{}}
\newlabel{num:biasoutput@cref}{{[enumi][2][]2}{[1][62][]62}}
\newlabel{num:biasinput}{{3}{62}{Uncertainty model}{Item.7}{}}
\newlabel{num:biasinput@cref}{{[enumi][3][]3}{[1][62][]62}}
\pp@spagectr{FN@totalid}{10}{1}{62}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Global uncertainty model based on $P(E)$}{63}{subsection.3.7.1}\protected@file@percent }
\newlabel{subsec:GUM}{{3.7.1}{63}{Global uncertainty model based on $P(E)$}{subsection.3.7.1}{}}
\newlabel{subsec:GUM@cref}{{[subsection][1][3,7]3.7.1}{[1][63][]63}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Global Uncertainty Model (GUM) computation}\\}{63}{subsection.3.7.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Bootstrapped uncertainty CI\relax }}{63}{algocf.3}\protected@file@percent }
\newlabel{algo:uncertainty1}{{3}{63}{\GMVred {A.} \myul [GMVred]{Global Uncertainty Model (GUM) computation}\\}{algocf.3}{}}
\newlabel{algo:uncertainty1@cref}{{[algorithm][3][]3}{[1][63][]63}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Global Uncertainty Model (GUM) evaluation}\\}{63}{table.caption.69}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.20}{\ignorespaces Global Uncertainty Model: Confidence Interval (mean and extremes) for output variables ''RF Forced Crippling'' (left) and ''RF Column Buckling'' (right). Header showing $[y_{min},y_{max}]$ in the calibration set.\relax }}{64}{table.caption.69}\protected@file@percent }
\newlabel{fig:gumtab1}{{3.20}{64}{Global Uncertainty Model: Confidence Interval (mean and extremes) for output variables ''RF Forced Crippling'' (left) and ''RF Column Buckling'' (right). Header showing $[y_{min},y_{max}]$ in the calibration set.\relax }{table.caption.69}{}}
\newlabel{fig:gumtab1@cref}{{[table][20][3]3.20}{[1][63][]64}}
\newlabel{fig:gumtab2}{{3.20}{64}{Global Uncertainty Model: Confidence Interval (mean and extremes) for output variables ''RF Forced Crippling'' (left) and ''RF Column Buckling'' (right). Header showing $[y_{min},y_{max}]$ in the calibration set.\relax }{table.caption.69}{}}
\newlabel{fig:gumtab2@cref}{{[table][20][3]3.20}{[1][63][]64}}
\newlabel{tab:gum1}{{3.20}{64}{Global Uncertainty Model: Confidence Interval (mean and extremes) for output variables ''RF Forced Crippling'' (left) and ''RF Column Buckling'' (right). Header showing $[y_{min},y_{max}]$ in the calibration set.\relax }{table.caption.69}{}}
\newlabel{tab:gum1@cref}{{[table][20][3]3.20}{[1][63][]64}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Bootstrapped coverage\relax }}{64}{algocf.4}\protected@file@percent }
\newlabel{algo:coverage}{{4}{64}{\GMVred {B.} \myul [GMVred]{Global Uncertainty Model (GUM) evaluation}\\}{algocf.4}{}}
\newlabel{algo:coverage@cref}{{[algorithm][4][]4}{[1][63][]64}}
\@writefile{lot}{\contentsline {table}{\numberline {3.21}{\ignorespaces Global Uncertainty Model. The six confidence intervals (bootstrapped) defining the GUM alongside their coverage --in the calibration set-- are showed.\relax }}{64}{table.caption.71}\protected@file@percent }
\newlabel{tab:coverage1}{{3.21}{64}{Global Uncertainty Model. The six confidence intervals (bootstrapped) defining the GUM alongside their coverage --in the calibration set-- are showed.\relax }{table.caption.71}{}}
\newlabel{tab:coverage1@cref}{{[table][21][3]3.21}{[1][64][]64}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.24}{\ignorespaces Global Uncertainty Model: error coverage. The coverage is higher than 95\% for both output variables --for convenience just two output variables are depicted-- what means the calibration criteria is successfully met.\relax }}{65}{figure.caption.72}\protected@file@percent }
\newlabel{fig:coverage1}{{3.24}{65}{Global Uncertainty Model: error coverage. The coverage is higher than 95\% for both output variables --for convenience just two output variables are depicted-- what means the calibration criteria is successfully met.\relax }{figure.caption.72}{}}
\newlabel{fig:coverage1@cref}{{[figure][24][3]3.24}{[1][64][]65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Local uncertainty model based on $P(E|\mathbf  {Y})$}{65}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Output variable binning}\\}{65}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Local Output Uncertainty Model (LOUM) computation}\\}{65}{figure.caption.74}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.25}{\ignorespaces Local Uncertainty Model based on $P(E|\mathbf  {Y})$: Scatter plot of the residue as a function of the predicted output $\hat  {y}$, for output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }}{66}{figure.caption.73}\protected@file@percent }
\newlabel{fig:scatter1}{{3.25}{66}{Local Uncertainty Model based on $P(E|\mathbf {Y})$: Scatter plot of the residue as a function of the predicted output $\hat {y}$, for output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }{figure.caption.73}{}}
\newlabel{fig:scatter1@cref}{{[figure][25][3]3.25}{[1][65][]66}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.26}{\ignorespaces Local Uncertainty Model based on $P(E|\mathbf  {Y})$: Violin plots of the residue, for binned output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }}{66}{figure.caption.74}\protected@file@percent }
\newlabel{fig:violins1}{{3.26}{66}{Local Uncertainty Model based on $P(E|\mathbf {Y})$: Violin plots of the residue, for binned output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }{figure.caption.74}{}}
\newlabel{fig:violins1@cref}{{[figure][26][3]3.26}{[1][65][]66}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Local Output Uncertainty Model (LOUM) evaluation}\\}{66}{table.caption.75}\protected@file@percent }
\newlabel{RF3}{67}
\@writefile{lot}{\contentsline {table}{\numberline {3.22}{\ignorespaces Local Output Uncertainty Model: Bootstrapped CIs for each of the ten bins into which the output variable ''RF Forced Crippling'' has been binned. The mean of each CI is also given, as well as the bin extrema $[\hat  {y}_{min},\hat  {y}_{max}]$ for every bin (in the first row).\relax }}{67}{table.caption.75}\protected@file@percent }
\newlabel{tab:loumtab1}{{3.22}{67}{Local Output Uncertainty Model: Bootstrapped CIs for each of the ten bins into which the output variable ''RF Forced Crippling'' has been binned. The mean of each CI is also given, as well as the bin extrema $[\hat {y}_{min},\hat {y}_{max}]$ for every bin (in the first row).\relax }{table.caption.75}{}}
\newlabel{tab:loumtab1@cref}{{[table][22][3]3.22}{[1][65][]67}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.27}{\ignorespaces LOUM coverage in the validation set. For both output variables coverage is above the minimum 95\% threshold.\relax }}{68}{figure.caption.77}\protected@file@percent }
\newlabel{fig:loum1}{{3.27}{68}{LOUM coverage in the validation set. For both output variables coverage is above the minimum 95\% threshold.\relax }{figure.caption.77}{}}
\newlabel{fig:loum1@cref}{{[figure][27][3]3.27}{[1][68][]68}}
\@writefile{lot}{\contentsline {table}{\numberline {3.23}{\ignorespaces LOUM coverage. Coverage in the validation set is displayed in the first row, whereas the coverage bootstrapped CIs are displayed in the second row.\relax }}{68}{table.caption.76}\protected@file@percent }
\newlabel{tab:loumtab2}{{3.23}{68}{LOUM coverage. Coverage in the validation set is displayed in the first row, whereas the coverage bootstrapped CIs are displayed in the second row.\relax }{table.caption.76}{}}
\newlabel{tab:loumtab2@cref}{{[table][23][3]3.23}{[1][68][]68}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Local uncertainty model based on $P(E|\mathbf  {X})$}{68}{subsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Input variable binnarization}\\}{68}{subsection.3.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.28}{\ignorespaces LIUM: Scatter plot of the residue of ''RF Forced Crippling'' as a function of the input $x$ (left: $x$ is ''FU.0410.16''. Right: $x$ is ''FU.0410.24'').\relax }}{69}{figure.caption.78}\protected@file@percent }
\newlabel{fig:scatter2}{{3.28}{69}{LIUM: Scatter plot of the residue of ''RF Forced Crippling'' as a function of the input $x$ (left: $x$ is ''FU.0410.16''. Right: $x$ is ''FU.0410.24'').\relax }{figure.caption.78}{}}
\newlabel{fig:scatter2@cref}{{[figure][28][3]3.28}{[1][68][]69}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Local Input Uncertainty Model (LIUM) computation}\\}{69}{figure.caption.79}\protected@file@percent }
\newlabel{fig:subviolins1}{{3.29(a)}{70}{Input variables: ''FU.0410.16'' (left), ''FU.0410.24'' (right)\relax }{figure.caption.79}{}}
\newlabel{fig:subviolins1@cref}{{[subfigure][1][3,29]3.29(a)}{[1][69][]70}}
\newlabel{sub@fig:subviolins1}{{(a)}{70}{Input variables: ''FU.0410.16'' (left), ''FU.0410.24'' (right)\relax }{figure.caption.79}{}}
\newlabel{sub@fig:subviolins1@cref}{{[subfigure][1][3,29]3.29(a)}{[1][69][]70}}
\newlabel{fig:subviolins2}{{3.29(b)}{70}{Input variable: ''Frame''\relax }{figure.caption.79}{}}
\newlabel{fig:subviolins2@cref}{{[subfigure][2][3,29]3.29(b)}{[1][69][]70}}
\newlabel{sub@fig:subviolins2}{{(b)}{70}{Input variable: ''Frame''\relax }{figure.caption.79}{}}
\newlabel{sub@fig:subviolins2@cref}{{[subfigure][2][3,29]3.29(b)}{[1][69][]70}}
\newlabel{fig:subviolins3}{{3.29(c)}{70}{Input variable: ''dp''\relax }{figure.caption.79}{}}
\newlabel{fig:subviolins3@cref}{{[subfigure][3][3,29]3.29(c)}{[1][69][]70}}
\newlabel{sub@fig:subviolins3}{{(c)}{70}{Input variable: ''dp''\relax }{figure.caption.79}{}}
\newlabel{sub@fig:subviolins3@cref}{{[subfigure][3][3,29]3.29(c)}{[1][69][]70}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.29}{\ignorespaces Violin plots showing the residue of output variable ''RF Forced Crippling''. (a): Numerical inputs (binned). (b) and (c): categorical inputs.\relax }}{70}{figure.caption.79}\protected@file@percent }
\newlabel{fig:violins3}{{3.29}{70}{Violin plots showing the residue of output variable ''RF Forced Crippling''. (a): Numerical inputs (binned). (b) and (c): categorical inputs.\relax }{figure.caption.79}{}}
\newlabel{fig:violins3@cref}{{[figure][29][3]3.29}{[1][69][]70}}
\@writefile{lot}{\contentsline {table}{\numberline {3.24}{\ignorespaces LIUM: Bootstrapped CIs for binned input variable ''FU.0430.26'' (bins' extrema displayed as column names). Residue corresponds to output variable ''RF Shear Panel Failure''.\relax }}{71}{table.caption.80}\protected@file@percent }
\newlabel{tab:lium1}{{3.24}{71}{LIUM: Bootstrapped CIs for binned input variable ''FU.0430.26'' (bins' extrema displayed as column names). Residue corresponds to output variable ''RF Shear Panel Failure''.\relax }{table.caption.80}{}}
\newlabel{tab:lium1@cref}{{[table][24][3]3.24}{[1][71][]71}}
\@writefile{lot}{\contentsline {table}{\numberline {3.25}{\ignorespaces LIUM: Bootstrapped CIs for categorical input variable ''dp'' (possible values that the variable can take are displayed as column names). Residue corresponds to ''RF Shear Panel Failure'' output variable.\relax }}{71}{table.caption.81}\protected@file@percent }
\newlabel{tab:lium2}{{3.25}{71}{LIUM: Bootstrapped CIs for categorical input variable ''dp'' (possible values that the variable can take are displayed as column names). Residue corresponds to ''RF Shear Panel Failure'' output variable.\relax }{table.caption.81}{}}
\newlabel{tab:lium2@cref}{{[table][25][3]3.25}{[1][71][]71}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Local Input Uncertainty Model (LIUM) evaluation}\\}{71}{table.caption.81}\protected@file@percent }
\newlabel{fig:liumcoveragenum}{{3.30(a)}{72}{Numerical inputs: ''FU.0410.14'' (left), ''FU.0410.15'' (right). White slices correspond to bins which have not fulfilled the minimum bin size requirements. For such bins, the GUM is used instead of LIUM.\relax }{figure.caption.82}{}}
\newlabel{fig:liumcoveragenum@cref}{{[subfigure][1][3,30]3.30(a)}{[1][72][]72}}
\newlabel{sub@fig:liumcoveragenum}{{(a)}{72}{Numerical inputs: ''FU.0410.14'' (left), ''FU.0410.15'' (right). White slices correspond to bins which have not fulfilled the minimum bin size requirements. For such bins, the GUM is used instead of LIUM.\relax }{figure.caption.82}{}}
\newlabel{sub@fig:liumcoveragenum@cref}{{[subfigure][1][3,30]3.30(a)}{[1][72][]72}}
\newlabel{fig:liumcoveragecat}{{3.30(b)}{72}{Categorical inputs: ''dp'' (left), ''Frame'' (right)\relax }{figure.caption.82}{}}
\newlabel{fig:liumcoveragecat@cref}{{[subfigure][2][3,30]3.30(b)}{[1][72][]72}}
\newlabel{sub@fig:liumcoveragecat}{{(b)}{72}{Categorical inputs: ''dp'' (left), ''Frame'' (right)\relax }{figure.caption.82}{}}
\newlabel{sub@fig:liumcoveragecat@cref}{{[subfigure][2][3,30]3.30(b)}{[1][72][]72}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.30}{\ignorespaces LIUM coverage on the evaluation set. Residue of the output variable ''RF Forced Crippling''. The grey area represents the uncertainty CI calculated by the LIUM for the corresponding bin.\relax }}{72}{figure.caption.82}\protected@file@percent }
\newlabel{fig:liumcoverage}{{3.30}{72}{LIUM coverage on the evaluation set. Residue of the output variable ''RF Forced Crippling''. The grey area represents the uncertainty CI calculated by the LIUM for the corresponding bin.\relax }{figure.caption.82}{}}
\newlabel{fig:liumcoverage@cref}{{[figure][30][3]3.30}{[1][72][]72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.4}Full uncertainty model (FUM)}{73}{subsection.3.7.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.31}{\ignorespaces Conceptual visualization of FUM as a conservative merge between GUM (whose bootstrap interval [P2.5,P97.5] is represented by the two straight horizontal lines), LOUM and LIUM (whose bootstrap intervals [P2.5,P97.5] are represented indistinctively by the red and blue curves).\relax }}{74}{figure.caption.83}\protected@file@percent }
\newlabel{fig:fumexplain}{{3.31}{74}{Conceptual visualization of FUM as a conservative merge between GUM (whose bootstrap interval [P2.5,P97.5] is represented by the two straight horizontal lines), LOUM and LIUM (whose bootstrap intervals [P2.5,P97.5] are represented indistinctively by the red and blue curves).\relax }{figure.caption.83}{}}
\newlabel{fig:fumexplain@cref}{{[figure][31][3]3.31}{[1][73][]74}}
\@setckpt{Chapters/Chapter_03/Chapter_03}{
\setcounter{page}{75}
\setcounter{equation}{1}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{6}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{7}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{31}
\setcounter{table}{25}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{theorem}{0}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{9}
\setcounter{algocfline}{4}
\setcounter{algocfproc}{4}
\setcounter{algocf}{4}
\setcounter{@stackindex}{0}
\setcounter{ROWcellindex@}{0}
\setcounter{r@tfl@t}{3}
\setcounter{tcbbreakpart}{0}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{lstnumber}{1}
\setcounter{FN@totalid}{10}
\setcounter{pp@a@FN@totalid}{10}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{60}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{47}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{42}
\setcounter{cbx@tempcntc}{0}
\setcounter{cbx@tempcntd}{-1}
\setcounter{Item}{7}
\setcounter{bookmark@seq@number}{30}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{prop}{0}
\setcounter{definition}{1}
\setcounter{mtc}{4}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
