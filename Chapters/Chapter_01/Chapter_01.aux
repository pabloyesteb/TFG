\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}The Validation Loop}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{The Validation Loop}{1}{chapter.1}\protected@file@percent }
\@writefile{lot}{\contentsline {xchapter}{The Validation Loop}{1}{chapter.1}\protected@file@percent }
\newlabel{chap:Chap_1}{{1}{1}{The Validation Loop}{chapter.1}{}}
\newlabel{chap:Chap_1@cref}{{[chapter][1][]1}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Case of study}{1}{subsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Surrogate model pipeline\relax }}{2}{figure.caption.9}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:diagrama_cajas}{{1.1}{2}{Surrogate model pipeline\relax }{figure.caption.9}{}}
\newlabel{fig:diagrama_cajas@cref}{{[figure][1][1]1.1}{[1][1][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Applicability}{2}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Supervised applicability classifyers}\\}{2}{subsection.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Unsupervised applicability classifyers}\\}{3}{subsection.1.1.2}\protected@file@percent }
\newlabel{def:interpolacion}{{1}{3}{}{definition.1}{}}
\newlabel{def:interpolacion@cref}{{[definition][1][]1}{[1][3][]3}}
\newlabel{dparadoxa}{{1.1.1}{3}{}{theorem.1.1.1}{}}
\newlabel{dparadoxa@cref}{{[theorem][1][1,1]1.1.1}{[1][3][]3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Smallest cube enclosing a set of 20 randomly generated points in a 3-dimensional euclidean space.\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:hipercuboex}{{1.2}{5}{Smallest cube enclosing a set of 20 randomly generated points in a 3-dimensional euclidean space.\relax }{figure.caption.11}{}}
\newlabel{fig:hipercuboex@cref}{{[figure][2][1]1.2}{[1][4][]5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Convex hull enclosing the set of \autoref  {fig:hipercuboex}. The convex hull's volume is always smaller than or equal to the volume of the hypercube.\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:policonex}{{1.3}{5}{Convex hull enclosing the set of \autoref {fig:hipercuboex}. The convex hull's volume is always smaller than or equal to the volume of the hypercube.\relax }{figure.caption.11}{}}
\newlabel{fig:policonex@cref}{{[figure][3][1]1.3}{[1][4][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Overview}{5}{subsection.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Validation pipeline\relax }}{6}{figure.caption.12}\protected@file@percent }
\newlabel{fig:pipeline}{{1.4}{6}{Validation pipeline\relax }{figure.caption.12}{}}
\newlabel{fig:pipeline@cref}{{[figure][4][1]1.4}{[1][4][]6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Train-test split}{7}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Preliminaries}{7}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Location of the train-test split assessment in the overall validation pipeline\relax }}{7}{figure.caption.13}\protected@file@percent }
\newlabel{fig:esquemattsplit}{{1.5}{7}{Location of the train-test split assessment in the overall validation pipeline\relax }{figure.caption.13}{}}
\newlabel{fig:esquemattsplit@cref}{{[figure][5][1]1.5}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Validation loop for the train-test split}{8}{subsection.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.1}Geometrical analysis}{8}{subsubsection.1.2.2.1}\protected@file@percent }
\pp@spagectr{FN@totalid}{1}{1}{9}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Train-test split geometrical analysis\relax }}{11}{algocf.1}\protected@file@percent }
\newlabel{algo:tt-split}{{1}{11}{Geometrical analysis}{algocf.1}{}}
\newlabel{algo:tt-split@cref}{{[algorithm][1][]1}{[1][8][]11}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Output of \autoref  {algo:tt-split}.\relax }}{12}{table.caption.15}\protected@file@percent }
\newlabel{tab:geo_out}{{1.1}{12}{Output of \autoref {algo:tt-split}.\relax }{table.caption.15}{}}
\newlabel{tab:geo_out@cref}{{[table][1][1]1.1}{[1][8][]12}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces Voxel reference table\relax }}{12}{table.caption.16}\protected@file@percent }
\newlabel{tab:voxref}{{1.2}{12}{Voxel reference table\relax }{table.caption.16}{}}
\newlabel{tab:voxref@cref}{{[table][2][1]1.2}{[1][8][]12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.2}Non-geometrical analysis}{13}{subsubsection.1.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.3}{\ignorespaces Points outside voxel hypercube\relax }}{14}{table.caption.17}\protected@file@percent }
\newlabel{tab:outhypercube}{{1.3}{14}{Points outside voxel hypercube\relax }{table.caption.17}{}}
\newlabel{tab:outhypercube@cref}{{[table][3][1]1.3}{[1][13][]14}}
\@writefile{lot}{\contentsline {table}{\numberline {1.4}{\ignorespaces \texttt  {reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.\relax }}{14}{table.caption.18}\protected@file@percent }
\newlabel{tab:reqsresults}{{1.4}{14}{\texttt {reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.\relax }{table.caption.18}{}}
\newlabel{tab:reqsresults@cref}{{[table][4][1]1.4}{[1][13][]14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.3}Train-test split. Conclusions}{15}{subsubsection.1.2.2.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.5}{\ignorespaces P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi ^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').\relax }}{16}{table.caption.19}\protected@file@percent }
\newlabel{tab:pvalin}{{1.5}{16}{P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi ^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').\relax }{table.caption.19}{}}
\newlabel{tab:pvalin@cref}{{[table][5][1]1.5}{[1][15][]16}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.\relax }}{17}{figure.caption.20}\protected@file@percent }
\newlabel{fig:inputsdhist}{{1.6}{17}{Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.\relax }{figure.caption.20}{}}
\newlabel{fig:inputsdhist@cref}{{[figure][6][1]1.6}{[1][15][]17}}
\@writefile{lot}{\contentsline {table}{\numberline {1.6}{\ignorespaces P-values of the output variables distributions\relax }}{17}{table.caption.22}\protected@file@percent }
\newlabel{tab:pvalout}{{1.6}{17}{P-values of the output variables distributions\relax }{table.caption.22}{}}
\newlabel{tab:pvalout@cref}{{[table][6][1]1.6}{[1][15][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Input categorical variables distributions double histograms\relax }}{18}{figure.caption.21}\protected@file@percent }
\newlabel{fig:inputscatdhist}{{1.7}{18}{Input categorical variables distributions double histograms\relax }{figure.caption.21}{}}
\newlabel{fig:inputscatdhist@cref}{{[figure][7][1]1.7}{[1][15][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Output variables distributions double histograms\relax }}{18}{figure.caption.23}\protected@file@percent }
\newlabel{fig:outputsdhist}{{1.8}{18}{Output variables distributions double histograms\relax }{figure.caption.23}{}}
\newlabel{fig:outputsdhist@cref}{{[figure][8][1]1.8}{[1][15][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Requirements of the geometrical analysis\relax }}{19}{figure.caption.24}\protected@file@percent }
\newlabel{fig:coloreqs_table}{{1.9}{19}{Requirements of the geometrical analysis\relax }{figure.caption.24}{}}
\newlabel{fig:coloreqs_table@cref}{{[figure][9][1]1.9}{[1][15][]19}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Global error quantification}{20}{section.1.3}\protected@file@percent }
\newlabel{eq:residue}{{1.2}{20}{Global error quantification}{equation.1.3.2}{}}
\newlabel{eq:residue@cref}{{[equation][2][1]1.2}{[1][20][]20}}
\pp@spagectr{FN@totalid}{2}{1}{20}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Scatter plot of ground true ($x$ axis) against predicted values ($y$ axis) of output variable ''RF Net Tension'', with the correspondent $R^2$ coefficient. In this case, $R^2=1,000$ indicates a perfect fit of predicted to ground true values. Mismatches due to underestimating failure risk are labelled in red, while those due to overestimating failure risk are labelled in blue. Similar graphs can be computed for every pair $\left \{y_j,\hat  {y}_j\right \}$ of features in the output variables $\mathbf  {Y}=\left \{y_1,y_2,\ldots  ,y_m\right \}$. Plots for the rest of the six output variables of MS-S18 show analogous results.\relax }}{21}{figure.caption.26}\protected@file@percent }
\newlabel{fig:truevspredscatter}{{1.10}{21}{Scatter plot of ground true ($x$ axis) against predicted values ($y$ axis) of output variable ''RF Net Tension'', with the correspondent $R^2$ coefficient. In this case, $R^2=1,000$ indicates a perfect fit of predicted to ground true values. Mismatches due to underestimating failure risk are labelled in red, while those due to overestimating failure risk are labelled in blue. Similar graphs can be computed for every pair $\left \{y_j,\hat {y}_j\right \}$ of features in the output variables $\mathbf {Y}=\left \{y_1,y_2,\ldots ,y_m\right \}$. Plots for the rest of the six output variables of MS-S18 show analogous results.\relax }{figure.caption.26}{}}
\newlabel{fig:truevspredscatter@cref}{{[figure][10][1]1.10}{[1][20][]21}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Distributed error quantification.}{22}{section.1.4}\protected@file@percent }
\newlabel{sec:disterr}{{1.4}{22}{Distributed error quantification}{section.1.4}{}}
\newlabel{sec:disterr@cref}{{[section][4][1]1.4}{[1][22][]22}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Location of \autoref  {sec:globalerr} in the validation pipeline.\relax }}{22}{figure.caption.27}\protected@file@percent }
\newlabel{fig:globalerrpipeline}{{1.11}{22}{Location of \autoref {sec:globalerr} in the validation pipeline.\relax }{figure.caption.27}{}}
\newlabel{fig:globalerrpipeline@cref}{{[figure][11][1]1.11}{[1][22][]22}}
\pp@spagectr{FN@totalid}{3}{1}{22}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Non gaussian error distribution}\\}{22}{figure.caption.27}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Outlier detection}\\}{23}{figure.caption.27}\protected@file@percent }
\newlabel{par:outliers}{{1.4}{23}{\GMVred {B.} \myul [GMVred]{Outlier detection}\label {par:outliers}\\}{figure.caption.27}{}}
\newlabel{par:outliers@cref}{{[section][4][1]1.4}{[1][23][]23}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Uncertainty measuring}\\}{23}{figure.caption.27}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Double histogram depicting ground true values and model's predictions for the six output variables of MS-18.\relax }}{24}{figure.caption.28}\protected@file@percent }
\newlabel{fig:yvsydoublehist}{{1.12}{24}{Double histogram depicting ground true values and model's predictions for the six output variables of MS-18.\relax }{figure.caption.28}{}}
\newlabel{fig:yvsydoublehist@cref}{{[figure][12][1]1.12}{[1][23][]24}}
\pp@spagectr{FN@totalid}{4}{1}{24}
\@writefile{lot}{\contentsline {table}{\numberline {1.7}{\ignorespaces p-value results for the 2-sample Kolmogorov-Smirnov test performed on distributions showed in \autoref  {fig:yvsydoublehist}. Hypothesis $H0$ is that ground true and predicted values both come from the same (unknown) distribution.\relax }}{25}{table.caption.29}\protected@file@percent }
\newlabel{tab:yvsyKS}{{1.7}{25}{p-value results for the 2-sample Kolmogorov-Smirnov test performed on distributions showed in \autoref {fig:yvsydoublehist}. Hypothesis $H0$ is that ground true and predicted values both come from the same (unknown) distribution.\relax }{table.caption.29}{}}
\newlabel{tab:yvsyKS@cref}{{[table][7][1]1.7}{[1][23][]25}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Empirical residue distribution sampled from the test set, for each of the six output variables of MS-S18. $x$-axis limits have been truncated to $\mu \pm 3 \sigma $, where the most part of the error lies. Histograms have been appropriately binned for a correct visualization.\relax }}{26}{figure.caption.30}\protected@file@percent }
\newlabel{fig:pdferror}{{1.13}{26}{Empirical residue distribution sampled from the test set, for each of the six output variables of MS-S18. $x$-axis limits have been truncated to $\mu \pm 3 \sigma $, where the most part of the error lies. Histograms have been appropriately binned for a correct visualization.\relax }{figure.caption.30}{}}
\newlabel{fig:pdferror@cref}{{[figure][13][1]1.13}{[1][23][]26}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Cumulative error distributions corresponding to the PDFs showed (as binned histograms) in \autoref  {fig:pdferror}.\relax }}{26}{figure.caption.31}\protected@file@percent }
\newlabel{fig:errorcumulative}{{1.14}{26}{Cumulative error distributions corresponding to the PDFs showed (as binned histograms) in \autoref {fig:pdferror}.\relax }{figure.caption.31}{}}
\newlabel{fig:errorcumulative@cref}{{[figure][14][1]1.14}{[1][23][]26}}
\@writefile{lot}{\contentsline {table}{\numberline {1.8}{\ignorespaces P-values of the K-S test comparing the empirical sample of $P(e)$ to the theoretical distributions indicated in each column. The null hypothesis $H0$ (the empirical distribution has been sampled from the one figuring in a given column) is rejected when $p-\text  {value}<0.05$.\relax }}{27}{table.caption.32}\protected@file@percent }
\newlabel{tab:KSerror}{{1.8}{27}{P-values of the K-S test comparing the empirical sample of $P(e)$ to the theoretical distributions indicated in each column. The null hypothesis $H0$ (the empirical distribution has been sampled from the one figuring in a given column) is rejected when $p-\text {value}<0.05$.\relax }{table.caption.32}{}}
\newlabel{tab:KSerror@cref}{{[table][8][1]1.8}{[1][25][]27}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Graphical comparison of the p-values resulting from the K-S test for the MS-18 data.\relax }}{28}{figure.caption.33}\protected@file@percent }
\newlabel{fig:errorpvalues}{{1.15}{28}{Graphical comparison of the p-values resulting from the K-S test for the MS-18 data.\relax }{figure.caption.33}{}}
\newlabel{fig:errorpvalues@cref}{{[figure][15][1]1.15}{[1][25][]28}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces (Binned) histograms depicting the distribution of the variable $z=\gamma +\qopname  \relax o{sinh}{\frac  {e-\xi }{\lambda }}$, where $e\sim JohnsonSU(\gamma ,\delta ,\xi ,\lambda )$ is the sampled residue. It can be shown that $z$ converges to a normal distribution\blx@tocontentsinit {0}\cite {jones2009sinh}.\relax }}{28}{figure.caption.34}\protected@file@percent }
\newlabel{fig:ztransform}{{1.16}{28}{(Binned) histograms depicting the distribution of the variable $z=\gamma +\sinh {\frac {e-\xi }{\lambda }}$, where $e\sim JohnsonSU(\gamma ,\delta ,\xi ,\lambda )$ is the sampled residue. It can be shown that $z$ converges to a normal distribution\cite {jones2009sinh}.\relax }{figure.caption.34}{}}
\newlabel{fig:ztransform@cref}{{[figure][16][1]1.16}{[1][25][]28}}
\@writefile{lot}{\contentsline {table}{\numberline {1.9}{\ignorespaces Outlier detection taking $e\sim JohnsonSU$ as $H0$. N.B. for this table the usual requirements for classifying a point as an outlier ($z\in \sigma \pm 3\mu $ for the z-score and significance $1-a\geq 95\%$ for the gESD) have been softened here for illustration purposes to $z\in \sigma \pm 1.2\mu $ and $a=0.45$ for both tests, respectively.\relax }}{29}{table.caption.35}\protected@file@percent }
\newlabel{tab:outliers}{{1.9}{29}{Outlier detection taking $e\sim JohnsonSU$ as $H0$. N.B. for this table the usual requirements for classifying a point as an outlier ($z\in \sigma \pm 3\mu $ for the z-score and significance $1-a\geq 95\%$ for the gESD) have been softened here for illustration purposes to $z\in \sigma \pm 1.2\mu $ and $a=0.45$ for both tests, respectively.\relax }{table.caption.35}{}}
\newlabel{tab:outliers@cref}{{[table][9][1]1.9}{[1][25][]29}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Non-parametric bootstrapping\relax }}{30}{algocf.2}\protected@file@percent }
\newlabel{algo:bootstrapping}{{2}{30}{\GMVred {C.} \myul [GMVred]{Uncertainty measuring}\\}{algocf.2}{}}
\newlabel{algo:bootstrapping@cref}{{[algorithm][2][]2}{[1][30][]30}}
\newlabel{RF1}{32}
\@writefile{lot}{\contentsline {table}{\numberline {1.10}{\ignorespaces Summary of bootstrapped error statistics. For the median, the Wilson-score\blx@tocontentsinit {0}\cite {wilson1927probable} is used for computing the confidence interval.\relax }}{32}{table.caption.37}\protected@file@percent }
\newlabel{tab:errorstats}{{1.10}{32}{Summary of bootstrapped error statistics. For the median, the Wilson-score\cite {wilson1927probable} is used for computing the confidence interval.\relax }{table.caption.37}{}}
\newlabel{tab:errorstats@cref}{{[table][10][1]1.10}{[1][30][]32}}
\newlabel{RF2}{33}
\@writefile{lot}{\contentsline {table}{\numberline {1.11}{\ignorespaces Bootstrapped percentiles (\ordinalnum {1}, \ordinalnum {5}, \ordinalnum {10}, \ordinalnum {90}, \ordinalnum {95} and \ordinalnum {99}) of the residue distribution, calculated with a 95\% confidence interval using Wilson-score.\relax }}{33}{table.caption.38}\protected@file@percent }
\newlabel{tab:basicuncertainty}{{1.11}{33}{Bootstrapped percentiles (\ordinalnum {1}, \ordinalnum {5}, \ordinalnum {10}, \ordinalnum {90}, \ordinalnum {95} and \ordinalnum {99}) of the residue distribution, calculated with a 95\% confidence interval using Wilson-score.\relax }{table.caption.38}{}}
\newlabel{tab:basicuncertainty@cref}{{[table][11][1]1.11}{[1][30][]33}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Distributed error quantification: conditioning the error distribution on the input space}{35}{section.1.5}\protected@file@percent }
\newlabel{sec:biasinput}{{1.5}{35}{Distributed error quantification: conditioning the error distribution on the input space}{section.1.5}{}}
\newlabel{sec:biasinput@cref}{{[section][5][1]1.5}{[1][35][]35}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces Box diagram showing the relative position of \autoref  {sec:biasinput} in the complete validation pipeline.\relax }}{35}{figure.caption.39}\protected@file@percent }
\newlabel{fig:biasinputbox}{{1.17}{35}{Box diagram showing the relative position of \autoref {sec:biasinput} in the complete validation pipeline.\relax }{figure.caption.39}{}}
\newlabel{fig:biasinputbox@cref}{{[figure][17][1]1.17}{[1][35][]35}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Visualization of error as a function of categorical (discrete) input variables}{36}{subsection.1.5.1}\protected@file@percent }
\newlabel{fig:boxwhisker1}{{1.18(a)}{37}{Error conditioned to the categorical variable ''Frame''\relax }{figure.caption.40}{}}
\newlabel{fig:boxwhisker1@cref}{{[subfigure][1][1,18]1.18(a)}{[1][36][]37}}
\newlabel{sub@fig:boxwhisker1}{{(a)}{37}{Error conditioned to the categorical variable ''Frame''\relax }{figure.caption.40}{}}
\newlabel{sub@fig:boxwhisker1@cref}{{[subfigure][1][1,18]1.18(a)}{[1][36][]37}}
\newlabel{fig:boxwhisker2}{{1.18(b)}{37}{Error conditioned to the categorical variable ''Stringer''\relax }{figure.caption.40}{}}
\newlabel{fig:boxwhisker2@cref}{{[subfigure][2][1,18]1.18(b)}{[1][36][]37}}
\newlabel{sub@fig:boxwhisker2}{{(b)}{37}{Error conditioned to the categorical variable ''Stringer''\relax }{figure.caption.40}{}}
\newlabel{sub@fig:boxwhisker2@cref}{{[subfigure][2][1,18]1.18(b)}{[1][36][]37}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.18}{\ignorespaces Box and whisker plots depicting the residue conditioned to two different categorical variables. \autoref  {fig:boxwhisker1}: ''Frame''. \autoref  {fig:boxwhisker2}: ''Stringer''. Clearly, outliers can be appreciated in both cases (''Fr69-Fr70'' in \autoref  {fig:boxwhisker1}, and various stringers in \autoref  {fig:boxwhisker2}).\relax }}{37}{figure.caption.40}\protected@file@percent }
\newlabel{fig:boxwhisker}{{1.18}{37}{Box and whisker plots depicting the residue conditioned to two different categorical variables. \autoref {fig:boxwhisker1}: ''Frame''. \autoref {fig:boxwhisker2}: ''Stringer''. Clearly, outliers can be appreciated in both cases (''Fr69-Fr70'' in \autoref {fig:boxwhisker1}, and various stringers in \autoref {fig:boxwhisker2}).\relax }{figure.caption.40}{}}
\newlabel{fig:boxwhisker@cref}{{[figure][18][1]1.18}{[1][36][]37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Bias detection and quantification (1D)}{38}{subsection.1.5.2}\protected@file@percent }
\newlabel{subsec:biasinput1d}{{1.5.2}{38}{Bias detection and quantification (1D)}{subsection.1.5.2}{}}
\newlabel{subsec:biasinput1d@cref}{{[subsection][2][1,5]1.5.2}{[1][38][]38}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Detection of error bias in single categories (ANOVA)}\\}{38}{subsection.1.5.2}\protected@file@percent }
\pp@spagectr{FN@totalid}{5}{1}{38}
\@writefile{lot}{\contentsline {table}{\numberline {1.12}{\ignorespaces P-values results from the one-way ANOVA test. The red labelled cells show that variable ''dp'' shows bias for the residual distribution of ''RF Net Tension'', as well as variable ''Frame'' for the residual distribution of ''RF Forced Crippling'' and variable''Stringer'' for the residual distributions of ''RF Net Tension'' and ''RF Pure Compression''. For the rest of the table, p-values greater than 0.05 indicate that $H0$ cannot be rejected with a statistical confidence of at least 95\%.\relax }}{39}{table.caption.41}\protected@file@percent }
\newlabel{tab:1anova}{{1.12}{39}{P-values results from the one-way ANOVA test. The red labelled cells show that variable ''dp'' shows bias for the residual distribution of ''RF Net Tension'', as well as variable ''Frame'' for the residual distribution of ''RF Forced Crippling'' and variable''Stringer'' for the residual distributions of ''RF Net Tension'' and ''RF Pure Compression''. For the rest of the table, p-values greater than 0.05 indicate that $H0$ cannot be rejected with a statistical confidence of at least 95\%.\relax }{table.caption.41}{}}
\newlabel{tab:1anova@cref}{{[table][12][1]1.12}{[1][38][]39}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Quantification of error bias in single categories test no. 1: based on error mean outlier}\\}{39}{table.caption.41}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.13}{\ignorespaces Z-score results for biased categorical variables. One table is generated for each pair biased categorical input variable-output variable.\relax }}{40}{table.caption.42}\protected@file@percent }
\newlabel{tab:zscore}{{1.13}{40}{Z-score results for biased categorical variables. One table is generated for each pair biased categorical input variable-output variable.\relax }{table.caption.42}{}}
\newlabel{tab:zscore@cref}{{[table][13][1]1.13}{[1][40][]40}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Quantification of error bias in single categories test no. 2: based on error variance outlier}\\}{40}{table.caption.42}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}D.} \myul [GMVred]{Quantification of error bias in single categories test no. 3: based on identification of linear trend}\\}{41}{table.caption.42}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}Bias detection and quantification (2D)}{42}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Bias detection (2D)}\\}{42}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Bias quantification (2D)}\\}{42}{subsection.1.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}Visualization of error as a function of numerical (continuous) input variables}{43}{subsection.1.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.5}Bias detection and quantification}{43}{subsection.1.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Detection of linear trends for individual numerical variables}\\}{43}{subsection.1.5.5}\protected@file@percent }
\newlabel{fig:imagen1}{{\caption@xref {fig:imagen1}{ on input line 710}}{44}{Visualization of error as a function of numerical (continuous) input variables}{figure.caption.43}{}}
\newlabel{fig:imagen1@cref}{{[subsection][4][1,5]1.5.4}{[1][43][]44}}
\newlabel{fig:imagen2}{{\caption@xref {fig:imagen2}{ on input line 716}}{44}{Visualization of error as a function of numerical (continuous) input variables}{figure.caption.43}{}}
\newlabel{fig:imagen2@cref}{{[subsection][4][1,5]1.5.4}{[1][43][]44}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.19}{\ignorespaces Scatter plots of residue against a particular numerical input variable. Left: Input var. FU.0420.26. A linear trend is appreciated, suggesting the model makes worse predictions as input load ''FU.0420.26'' is larger. Right: input var. FU.0420.25. No linear trend is appreciated, although severe heteroscedasticity can be observed. Note the vertical bar arrangement, showing particular input loads for which dispersion is unusually large. In view of the former results, the engineer may decide to investigate the underlying causes both for the linear trend in the left and for heteroscedasticity on the right. With the information, model and data boosting may be performed. More training data could be decided to be sampled in the range of $[20000,60000]$ of FU.0420.26, for instance, and some regularization technique could be tried for the loss function in order to penalise inputs triggering high variance observed in the right.\relax }}{44}{figure.caption.43}\protected@file@percent }
\newlabel{fig:binputscatter}{{1.19}{44}{Scatter plots of residue against a particular numerical input variable. Left: Input var. FU.0420.26. A linear trend is appreciated, suggesting the model makes worse predictions as input load ''FU.0420.26'' is larger. Right: input var. FU.0420.25. No linear trend is appreciated, although severe heteroscedasticity can be observed. Note the vertical bar arrangement, showing particular input loads for which dispersion is unusually large. In view of the former results, the engineer may decide to investigate the underlying causes both for the linear trend in the left and for heteroscedasticity on the right. With the information, model and data boosting may be performed. More training data could be decided to be sampled in the range of $[20000,60000]$ of FU.0420.26, for instance, and some regularization technique could be tried for the loss function in order to penalise inputs triggering high variance observed in the right.\relax }{figure.caption.43}{}}
\newlabel{fig:binputscatter@cref}{{[figure][19][1]1.19}{[1][43][]44}}
\@writefile{lot}{\contentsline {table}{\numberline {1.14}{\ignorespaces Bias detection and quantification on numerical input variables (the results for just five input variables are shown here -- in columns--): P-value (statistical significance of the hypothesis that the variable is biased), Pearson coefficient, and slope of the best linear fit are shown in the first three rows. The last row shows the message ''Biased'' in case the $p\text  {-value}>0.05$, ''NO'' otherwise. Data from this table corresponds to residue of the output variable ''RF Column Buckling''. Analogous tables exist for the rest of the output variables.\relax }}{44}{table.caption.44}\protected@file@percent }
\newlabel{tab:lintrend}{{1.14}{44}{Bias detection and quantification on numerical input variables (the results for just five input variables are shown here -- in columns--): P-value (statistical significance of the hypothesis that the variable is biased), Pearson coefficient, and slope of the best linear fit are shown in the first three rows. The last row shows the message ''Biased'' in case the $p\text {-value}>0.05$, ''NO'' otherwise. Data from this table corresponds to residue of the output variable ''RF Column Buckling''. Analogous tables exist for the rest of the output variables.\relax }{table.caption.44}{}}
\newlabel{tab:lintrend@cref}{{[table][14][1]1.14}{[1][44][]44}}
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Discretizing continuous variables}\\}{44}{table.caption.44}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.15}{\ignorespaces 1-way ANOVA test results (p-values) for binned numerical input variables. For the output variable ''RF Forced Crippling'', bias is found in the input variables ''FU.0420.25'' and ''FU.0430.25''. Similarly, for the output variable ''RF Net Tension'', bias is found in the input variable ''FU.0430.15''. \relax }}{45}{table.caption.45}\protected@file@percent }
\newlabel{tab:anovanum}{{1.15}{45}{1-way ANOVA test results (p-values) for binned numerical input variables. For the output variable ''RF Forced Crippling'', bias is found in the input variables ''FU.0420.25'' and ''FU.0430.25''. Similarly, for the output variable ''RF Net Tension'', bias is found in the input variable ''FU.0430.15''. \relax }{table.caption.45}{}}
\newlabel{tab:anovanum@cref}{{[table][15][1]1.15}{[1][45][]45}}
\@writefile{lot}{\contentsline {table}{\numberline {1.16}{\ignorespaces Bias quantification in binned FU.0430.15 input variable. Columns represents bins showing bias. The same quantification methods employed for categorical variables (z-score for mean and variance outlier detection) have been used.\relax }}{46}{table.caption.46}\protected@file@percent }
\newlabel{tab:anovabins}{{1.16}{46}{Bias quantification in binned FU.0430.15 input variable. Columns represents bins showing bias. The same quantification methods employed for categorical variables (z-score for mean and variance outlier detection) have been used.\relax }{table.caption.46}{}}
\newlabel{tab:anovabins@cref}{{[table][16][1]1.16}{[1][45][]46}}
\@writefile{lot}{\contentsline {table}{\numberline {1.17}{\ignorespaces Summary of binned input variables bias quantification after binning the numerical variables and performing one-way ANOVA and z-score tests to every bin.\relax }}{46}{table.caption.47}\protected@file@percent }
\newlabel{tab:zscorenum1}{{1.17}{46}{Summary of binned input variables bias quantification after binning the numerical variables and performing one-way ANOVA and z-score tests to every bin.\relax }{table.caption.47}{}}
\newlabel{tab:zscorenum1@cref}{{[table][17][1]1.17}{[1][45][]46}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Distributed error quantification: conditioning the error distribution on the output space}{48}{section.1.6}\protected@file@percent }
\newlabel{sec:biasoutput}{{1.6}{48}{Distributed error quantification: conditioning the error distribution on the output space}{section.1.6}{}}
\newlabel{sec:biasoutput@cref}{{[section][6][1]1.6}{[1][48][]48}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.20}{\ignorespaces Relative position of \autoref  {sec:biasoutput} in the complete validation pipeline.\relax }}{48}{figure.caption.48}\protected@file@percent }
\newlabel{fig:boutpipeline}{{1.20}{48}{Relative position of \autoref {sec:biasoutput} in the complete validation pipeline.\relax }{figure.caption.48}{}}
\newlabel{fig:boutpipeline@cref}{{[figure][20][1]1.20}{[1][48][]48}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.21}{\ignorespaces Goodness of fit of the error distribution (test set previously filtered) to some parametrised distributions. The test is performed individually for the output variables (Reserve Factors) displayed on top of each image. The goodness of fit is assessed with a 1-variable K-S test. The test set is filtered using the x axis, rejecting every point whose output $\hat  {y}$ is larger than $x$. If the p-value resulting from the K-S test in the filtered test set is greater than $0.05$, the vertical slice at position $x$ is labelled green (red if $p\text  {-value}<0.05$, grey if less than a threshold number of points --namely, 30-- are present in the filtered test set).\relax }}{50}{figure.caption.49}\protected@file@percent }
\newlabel{fig:localfits}{{1.21}{50}{Goodness of fit of the error distribution (test set previously filtered) to some parametrised distributions. The test is performed individually for the output variables (Reserve Factors) displayed on top of each image. The goodness of fit is assessed with a 1-variable K-S test. The test set is filtered using the x axis, rejecting every point whose output $\hat {y}$ is larger than $x$. If the p-value resulting from the K-S test in the filtered test set is greater than $0.05$, the vertical slice at position $x$ is labelled green (red if $p\text {-value}<0.05$, grey if less than a threshold number of points --namely, 30-- are present in the filtered test set).\relax }{figure.caption.49}{}}
\newlabel{fig:localfits@cref}{{[figure][21][1]1.21}{[1][49][]50}}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Uncertainty model estimation}{51}{section.1.7}\protected@file@percent }
\newlabel{sec:uncertainty}{{1.7}{51}{Uncertainty model estimation}{section.1.7}{}}
\newlabel{sec:uncertainty@cref}{{[section][7][1]1.7}{[1][51][]51}}
\@writefile{lot}{\contentsline {table}{\numberline {1.18}{\ignorespaces Output of \autoref  {algo:tt-split}: \texttt  {reqs\_results} table\relax }}{52}{table.caption.50}\protected@file@percent }
\newlabel{def:orden1}{{2}{52}{}{definition.2}{}}
\newlabel{def:orden1@cref}{{[definition][2][]2}{[1][52][]52}}
\@writefile{lot}{\contentsline {table}{\numberline {1.19}{\ignorespaces Voxel reference table. Lorem ipsum dolor sit amet, consectetuer adisciping elit.\relax }}{53}{table.caption.51}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Las movidas de Rodrigo}{54}{section.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Concept: System dynamics.}{54}{subsection.1.8.1}\protected@file@percent }
\newlabel{eqCh1:Problem_def}{{1.3}{54}{Concept: System dynamics}{equation.1.8.3}{}}
\newlabel{eqCh1:Problem_def@cref}{{[equation][3][1]1.3}{[1][54][]54}}
\newlabel{eqCh1:STM_1}{{1.4}{54}{Concept: System dynamics}{equation.1.8.4}{}}
\newlabel{eqCh1:STM_1@cref}{{[equation][4][1]1.4}{[1][54][]54}}
\newlabel{eqCh1:STM_2}{{1.5}{55}{Concept: System dynamics}{equation.1.8.5}{}}
\newlabel{eqCh1:STM_2@cref}{{[equation][5][1]1.5}{[1][54][]55}}
\newlabel{eqCh1:STM_decomp}{{1.6}{55}{Concept: System dynamics}{equation.1.8.6}{}}
\newlabel{eqCh1:STM_decomp@cref}{{[equation][6][1]1.6}{[1][55][]55}}
\newlabel{eqCh1:STM_prop}{{1.7}{55}{Concept: System dynamics}{equation.1.8.7}{}}
\newlabel{eqCh1:STM_prop@cref}{{[equation][7][1]1.7}{[1][55][]55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Applications of STMs in celestial mechanics.}{56}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}A.} \myul [GMVred]{Precise Orbit Determination.}\\}{56}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}B.} \myul [GMVred]{Guidance, Navigation and Control (GNC).} \\}{56}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}C.} \myul [GMVred]{Orbit design.} \\}{56}{subsection.1.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\leavevmode {\color  {GMVred}D.} \myul [GMVred]{Covariance matrix propagation.} \\}{57}{subsection.1.8.2}\protected@file@percent }
\newlabel{eqCh1:P_est}{{1.8}{58}{\GMVred {D.} \myul [GMVred]{Covariance matrix propagation.} \\}{equation.1.8.8}{}}
\newlabel{eqCh1:P_est@cref}{{[equation][8][1]1.8}{[1][57][]58}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.22}{\ignorespaces Covariance ellipsoid evolution along a radial hop.\relax }}{58}{figure.caption.58}\protected@file@percent }
\newlabel{figCh1:Covariance_segment}{{1.22}{58}{Covariance ellipsoid evolution along a radial hop.\relax }{figure.caption.58}{}}
\newlabel{figCh1:Covariance_segment@cref}{{[figure][22][1]1.22}{[1][58][]58}}
\@setckpt{Chapters/Chapter_01/Chapter_01}{
\setcounter{page}{60}
\setcounter{equation}{8}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{5}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{8}
\setcounter{subsection}{2}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{22}
\setcounter{table}{19}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{theorem}{0}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{8}
\setcounter{algocfline}{2}
\setcounter{algocfproc}{2}
\setcounter{algocf}{2}
\setcounter{@stackindex}{0}
\setcounter{ROWcellindex@}{0}
\setcounter{r@tfl@t}{2}
\setcounter{tcbbreakpart}{0}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{0}
\setcounter{lstnumber}{1}
\setcounter{FN@totalid}{5}
\setcounter{pp@a@FN@totalid}{5}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{49}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{blx@maxsegment@0}{0}
\setcounter{blx@sectionciteorder@0}{42}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{cbx@tempcnta}{0}
\setcounter{cbx@tempcntb}{34}
\setcounter{cbx@tempcntc}{0}
\setcounter{cbx@tempcntd}{-1}
\setcounter{Item}{4}
\setcounter{bookmark@seq@number}{25}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{prop}{0}
\setcounter{definition}{3}
\setcounter{mtc}{2}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
