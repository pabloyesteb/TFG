\chapter{The Validation Loop}
%
\label{chap:Chap_1}
%
%\indent This thesis is developed over a particular method of describing 
%
\section{Introduction}
\subsection{Case of study}
\indent For illustration of the proposed validation loop, a case of study has been used alongside the theoretical rationale of the loop to generate explanatory figures and tables and to give proof of the real operation of the loop.\\
%
\indent The case of study is an application of NN in aircraft stress engineering. For typical aircraft fuselage panel design, the dominant form of stiffened post buckling failure under shear loading is forced crippling\cite{bijlaard1955buckling}. This occurs when the shear buckles in the panel skin force the attached stiffener flanges to deform out-of-plane. There are other failure modes related to buckling, tension, and compression.\\
%
\indent The case of study used for illustration purposes consists of a NN model whose task is to predict Reserve Factors ($RF$) that quantify failure likelihood for regions of the aircraft subject to different loads happening in flight maneuvers. The possible failure modes are Forced Crippling, Column Buckling, In Plane, Net Tension, Pure Compression, and Shear Panel Failure.\\
%
\indent Input data consists of 26 features (loads applied to a specific region of the aircraft and different maneuver specs). Output data consists of 6 reserve factors that quantify the stress failure likelihood ($RF_1$, $RF_2$, $RF_3$, $RF_4$, $RF_5$, and $RF_6$), where $RF_i\in [0,5]$,where $0$ means extreme risk and $5$ means risk extremely low (in a logarithmic scale).\\
%
\indent The NN architecture and further features are irrelevant for this study and therefore the model treatment alongside this work remains the concept of a ''black box'' whose inputs are the 26 features aforementioned and whose output are the 6 reserve factors corresponding to 6 different failure modes.\\
%
\indent For typical aircraft fuselage panel design, the dominant form of stiffened post buckling failure under shear loading is forced crippling. This occurs when the shear buckles in the panel skin force the attached stiffener flanges to deform out-of-plane.\\
%
\begin{figure}
	\centering
	\begin{tikzpicture}
		% Caja 1
		\node[draw, minimum width=2cm, minimum height=3cm, font=\scriptsize] (box1) at (0,0) {
			\begin{tabular}{c}
				\textbf{INPUT $X$}\\
				Loads + Geometry +\\
				other specs\\
				(quantitative + qualitative)
			\end{tabular}
		};
		\node[below=0.1cm of box1] {$\mathbf{X}=(x_1,x_2,...,x_n)$};
		
		% Caja 2
		\node[draw, minimum width=2cm, minimum height=3cm, right=0.5cm of box1, font=\scriptsize] (box2) {
			\begin{tabular}{c}
				\textbf{SURROGATE MODEL}\\
				Stress learning model\\
				trained by splitting cases into\\
				train/test set and minimize loss\\
				function (Deep Neural Network)
			\end{tabular}
		};
		\node[below=0.1cm of box2] {$\cal{F}:\mathbf{X} \rightarrow \mathbf{Y}$};
		
		% Caja 3
		\node[draw, minimum width=2cm, minimum height=3cm, right=0.5cm of box2, font=\scriptsize] (box3) {
			\begin{tabular}{c}
				\textbf{PREDICTION (OUTPUT) Y}\\
				A set of Reserve Factors ($RF$)\\
				which characterize the likelihood\\
				of different failure modes.
			\end{tabular}
		};
		\node[below=0.1cm of box3] {$\mathbf{Y}=(y_1,y_2,...,y_m)$};
		
		% Flechas
		\draw[->, >=Stealth] (box1.east) -- (box2.west);
		\draw[->, >=Stealth] (box2.east) -- (box3.west);
	\end{tikzpicture}
	\caption{Surrogate model pipeline}
	\label{fig:diagrama_cajas}
\end{figure}


\subsection{Applicability}
\indent The applicability region can be intuitively defined as the set of the input and output values for which the model's prediction can be trusted. Applicability region is a refined idea of the \textit{Operational Design Domain} of a model.\\
\indent For a model $F$ to be applicable to a certain new point $x$:
\begin{itemize}
	\item $x$ needs to be inside the \textit{input} applicability region of $F$.
	\item The prediction $Y=F(x)$ needs to be inside the \textit{output} applicability region of $F$.
\end{itemize}

\indent Knowing whether a new point is either inside or outside applicability is a binary decision problem which can be addressed \textit{a priori} (filtering) or be learned \textit{a posteriori} (model boosting). In other words, the binary classification can be addressed from an unsupervised (geometric) learning approach, or a supervised learning approach. Supervised applicability classifiers are based on exogenous criteria. Examples of them include:
\begin{itemize}
	\item \textbf{Error-filtered convex hull.} Initially the whole set under testing is in applicability range. After filtering those test cases whose prediction error exceeds a tolerance, the applicability region is defined as the convex hull of the remaining subset. The convex hull can be simply defined as the smallest convex set containing the data\cite{Preparata1985}.
	\item \textbf{Error-labelled classifiers.} Initially a whole subset of the dataset (namely, the test set) is in applicability range. After labelling those test cases whose prediction error exceeds a tolerance as outside applicability, different binary classifiers are trained on the full dataset.\\
\end{itemize}

On the other hand, geometrical applicability classifiers are based on the premise of NN interpolation capabilities. It has been widely discussed (see \eg \cite{pmlr-v80-barrett18a,DBLP:journals/corr/abs-1711-00350,DBLP:journals/corr/abs-1904-01557}) that NN's performance relies on their interpolation capabilities, and that no extrapolation capabilities outside their applicability region should be assumed.\\
%
\indent Subsequently, from a geometrical approach to the applicability classification problem, we shall define the input applicability region as the geometrical region in the input space where the model is known to work in interpolating regime.\\
%
\indent There are plenty of definitions for the interpolating region of a given dataset. Some authors define it as the smallest hypercube enclosing the data\cite{ebert2014interpolation} although this may seriously challenge interpolation due to isolated points falling into the interpolation region under this definition. Many authors (see v. gr. \cite{loh2007extrapolation,4505337}) define the interpolation region as the \textit{convex hull} of the training data, \ie:

\begin{definition}\cite{balestriero2021learning}\label{def:interpolacion}
	Standard interpolation occurs for a sample $\mathbf{x}$ whenever this sample belongs to the convex hull of a set of samples $\mathbf{X}\triangleq \left\{\mathbf{x}_1,...,\mathbf{x}_N\right\}$.
\end{definition}

In the above definition, $\mathbf{X}$ is the training set which has been used for training the model.\\
%
\indent Recently, \cite{balestriero2021learning} have pointed out that, due to the so-called curse of dimensionality, extrapolation outside the training convex hull always ends up taking place if the input dimension is sufficiently large. The curse of dimensionality\cite[pp. 17-18]{Marsland2015Machine} can be illustrated by the fact that the unitary $n$-sphere's volume asymptotically diminishes to $0$ as $n$ increases. In the end, the effect is that, as the number of dimensions increase, more data is needed in order for the model to work in interpolating regime, as is showed by the following theorem:\\

\begin{theorem}\cite{barany1988shape}\label{dparadoxa}
	Given a $d$-dimensional dataset $\mathbf X \triangleq {\mathbf{x}_1,...,\mathbf{x}_N}$ with i.i.d. samples uniformly drawn from a hyperball, the probability that a new sample $\mathbf{x}$ is in interpolation regime (recall \autoref{def:interpolacion}) has the following asymptotic behaviour:\\
	
	\begin{equation}
		\lim_{d \to \infty}p(\mathbf{x}\in Hull(\mathbf{X}))=
		\begin{cases}
			1 \iff N>d^{-1}2^{\frac{d}{2}}\\
			0 \iff N<d^{-1}2^{\frac{d}{2}}
		\end{cases}	
	\end{equation}
\end{theorem}

\indent The main answer to the argument of \cite{balestriero2021learning} is that interpolation does not occur in the ambient space, but in a latent, low-dimensional space of the input data\cite{bonnasse2022interpolation}. This leads to a new definition of interpolation alternative to \autoref{def:interpolacion}.\\
%
\indent What's more, the authors in \cite{bonnasse2022interpolation} not only show that interpolation indeed occurs (at least in a latent representation of the ambient space), but that more important conditions to the model's performance are that testing and training data follow the same cumulative distribution (or the same tail distribution whenever the former cannot be fulfilled) and that testing points be not isolated in the dataset.\\
%
Examples of unsupervised applicability classifiers include:
\begin{itemize}
	\item \textbf{Operational design domains.} Based on engineer/scientist expertise, only certain combinations and range of features make physical sense.
	\item \textbf{Input space range classifier.} The applicability region is defined as the boundary of the hypercube whose edges are the ranges $[min, max]$ of each input variable in the training set. In practice, this amounts to checking if each numerical feature $X_i$ of the test point lies inside the range spanned by the training subset.
	\item \textbf{Input space convex hull classifier.} The applicability region is defined as the boundary of the convex hull of the training set.
	\item \textbf{Input space isolated region detector.} Even if a point is inside the convex hull of the training set, it can be very far away from other points, thus interpolation can be challenged. Isolated region detectors address this by checking the statistical vicinity of train points and comparing it to the distance of a given test point to the closest training point.
\end{itemize}

\begin{figure}[!htb]
	\begin{minipage}[t]{0.4\linewidth}
		\raggedright
		\includegraphics[width=\linewidth]{Figures/hipercubo.png}
		\caption{Smallest cube enclosing a set of 20 randomly generated points in a 3-dimensional euclidean space.}
		\label{fig:hipercuboex}
	\end{minipage}\hfill
	\begin{minipage}[t]{0.4\linewidth}
		\raggedleft
		\includegraphics[width=\linewidth]{Figures/policon.png}
		\caption{Convex hull enclosing the set of \autoref{fig:hipercuboex}. The convex hull's volume is always smaller than or equal to the volume of the hypercube.}
		\label{fig:policonex}
	\end{minipage}
\end{figure}
%
\subsection{Overview}
(Sin acentos) Recorrido sumario por las distintas partes del analisis estadistico (plantillas) centrandose en su funcion en vez de su funcionamiento tecnico. Explicacion de la arquitectura general de la validacion.\\ 
\section{Train-test split}
\subsection{Preliminaries}
\begin{figure}[!b]
	\centering
	\includegraphics[width=0.8\textwidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/tt_split_overview.png}
	\caption{Location of the train-test split assessment in the overall validation pipeline}
	\label{fig:esquemattsplit}
\end{figure}
\indent In supervised learning applications, the dataset is typically divided into the training and the testing sets. Keeping different sets for each task is fundamental in order to prevent model bias. Typical figures for the train-test split ratio are 80\%-20\%. When the model being trained is very large, a third dataset (the validation set) may be needed for comparing different hyperparameter configurations, in which case the split is typically done at 60\%-20\%-20\% for the train, test, and vaidation sets, resectively\cite[pp. 20-21]{Marsland2015Machine}.\\
%
\indent Training and evaluating the NN on the same dataset would result in the phenomenon called overfitting\cite[pp. 19-20]{Marsland2015Machine}, which basically consists of the NN fitting the noise in the training data and thus losing generalization capabilities.\\
%
\indent With the dataset split into the train, evaluation, and test sets, the standard training and validation loop is as follows: the model is trained to ''fit'' the data in the training set. After a certain amount of training, its performance is measured in the evaluation set. The test set is used to compare the performance of different hyperparameter configurations. Note that the NN is always evaluated with data not previously ''seen'' during training, and as such cannot develop any bias for the training set (although bias for the validation or test sets may exist).\\
%
\indent In the model validation loop, the first question that should be asked, even before training the model, is whether the dataset split is appropriate for training.\\
%
\indent For our case of applicability (MSP18, explicar en otra seccion), we suppose we have a dataset which has been split into a training set
$${\cal S}_{\text{train}}=\{({\bf X^{tr}},{\bf Y^{tr}})_i\}_{i=1}^{N_{training}}$$
and a test set
$${\cal S}_{\text{test}}=\{({\bf X^{te}},{\bf Y^{te}})_i\}_{i=1}^{N_{test}},$$
where ${\bf X}=(X_1,X_2,\dots,X_m)$ is the vector of input variables (also called feature vector), $m$ is the dimensionality of the input parameter space, and ${\bf Y}=(Y_1,Y_2,\dots,Y_q)$ is the vector of output variables, with dimensionality $q$. Individual variables $X_k$ can be numerical or categorical. For instance, for stress problems such as MSP-S18, we have a combination of numerical  (\eg external loads) and categorical (eg discrete geometrical variables such as ''Frame'' or ''Stringer'', and purely categorical such as ''dp''). Individual variables $Y_k$ describe the prediction and these are typically numerical (for stress problems such as MSP-S18, $q=6$ and these are so-called reserve factors, quantifying the failure likelihood of different failure modes).\\
%
\indent The aim of this section is to propose a set of tests to evaluate to which extent splitting fulfils the necessary conditions for the subsequent surrogate model ${\bf {Y}}={F}({\bf X})$ to be appropriately trained on ${\cal S}_{\text{train}}$ and tested on ${\cal S}_{\text{test}}$. This basically means the latter be in the applicability region of a model trained on the former, in order for the training-validation loop of the model to be coherent.\\
%
\subsection{Validation loop for the train-test split}
\subsubsection{Geometrical analysis}
\indent To address the applicability classification problem, points in the test set extremely far away from the training set (effectively outside applicability) need to be detected. If found, that would mean the train-test split is incorrect.\\
%
\indent There is a wide range of criteria for classifying a point inside or outside applicability. The proposed validation loop makes such analysis following a hierarchical flow. For each point in the test set a decision is made based on where that test set point lies with respect to the training set.\\
%
\indent Because categorical variables are usually related to different physical conditions, the first step is to condition the analysis of each test point only with respect to the training subset of points whose categorical variables have exactly the same values than the test point under analysis. This conditioning on categorical variables defines, for each test point, a \textit{voxel}, \ie a region in the input space defined by the precise values of each categorical variable. At this point the first requirement comes into play: the number of training samples inside such voxel needs to be large enough (\eg larger than zero).\\
%
\indent Then, inside the voxel the ranges of each feature $X_i$ of the training subset are computed, and then the maximum ranges are checked and defined. Their cartesian product defines the voxel's hypercuboid volume associated to the numerical features. It is checked whether the test point is inside or outside the hypercube. In practice, this amounts to checking if each numerical feature $X_i$ of the test point lies inside the range spanned by the training subset. If all numerical features fall inside these ranges, the test set falls inside the training subset hypercuboid, otherwise, it falls outside. The points lying outside such hypercuboid are outside applicability and are flagged. The ''hypercube requirement'' is that such percentage of points outside applicability is zero, or very close to it.\\
%
\indent If the test point under analysis is found to be outside the hypercuboid, the analysis finishes and the loop moves to the next point. Otherwise, the second step is to check whether this point not only lies inside hypercuboid, but further, whether it also lies inside the convex hull spanned by the training subset in a PCA99\footnote{A truncated PCA\cite{hotelling1933analysis} projection in which the selected components explain at least 99\% of the whole variance of the data.} projection. This hull has a smaller volume than the hypercuboid. If the test point under analysis is found to be outside the convex hull in the PCA99 projection, the analysis finishes and the loop moves to the next point.\\
% 
\indent Otherwise, then the third step is to check whether this point (not only lies inside hypercuboid and $\text{CH}_\text{PCA99}$, but also) lies inside the convex hull spanned by the training subset in ambient space. The volume of this hull is typically smaller than the one of the PCA99 projection by virtue of the curse of dimensionality, and if the test point lies inside this hull, interpolating properties of the surrogate model will suggest that the model is not require to generalize outside the region where it cannot generalize.\\
%
The step of the PCA projection is motivated by the curse of dimensionality, which makes every test point be in extrapolating regime with respect to the training data when the convex hull of the raw, unprocessed training data is used in a high-dimensional input space, as pointed out by \cite{balestriero2021learning}. The work of \cite{bonnasse2022interpolation} effectively shows how in such cases, a low-dimensional space is more useful for applicability classification.\\
%
\indent Each step provides different level of evidence of whether the point under analysis was adequately located, where the best is that it lies inside the convex hull of the corresponding voxel in ambient space, and the worst is that it lies outside the hypercuboid.\\
%
\indent An additional check is to analyse whether p-hacking is happening, \ie whether the test set point is ''too close'' to an actual training point (or indeed equal to a training point), what would falsely induce low test error of the model. For this, we measure the distance of the test point to the closest point of the training subset. This information is later used to assess different aspects of potential p-hacking and its impact on the decision of train-test split correctness.\\
%
\indent The former procedure for classifying the applicability of test points is summarised in \autoref{algo:tt-split}.\\
\begin{algorithm}
	\caption{Train-test split geometrical analysis}
	\label{algo:tt-split}
	\KwData{${\cal S}_{\text{train}},{\cal S}_{\text{test}}$, voxel\_size\_req}
	\KwResult{inside\_hypercube, inside\_PCA99, inside\_ambient, avg\_train\_dist, min\_test\_dist}
	
	Initialize empty lists: $\text{test\_voxels, train\_voxels}\leftarrow[]$\;
	
	Initialize boolean arrays: $\text{inside\_hypercube}, \text{inside\_PCA99}, \text{inside\_ambient} \leftarrow [\text{False}, \ldots, \text{False}]_{1\times \text{len}({\cal S}_{\text{test}})}$\;
	
	Initialize arrays for distances: $\text{avg\_train\_dist}, \text{min\_test\_dist} \leftarrow [\text{NaN}, \ldots, \text{NaN}]_{1 \times \text{len}({\cal S}_{\text{test}})}$\;
	
	\ForEach{$\mathbf{X}=(\mathbf{X_{\text{numerical}},X_{\text{categorical}}})$ in ${\cal S}_{\text{test}}$}{
		Compute test\_voxel by imposing $\mathbf{X_{\text{categorical}}}$\;
		Append test\_voxel to $\text{test\_voxels}$\;
	}
	
	\ForEach{$\mathbf{X}=(\mathbf{X_{\text{numerical}},X_{\text{categorical}}})$ in ${\cal S}_{\text{train}}$}{
		Compute train\_voxel by imposing $\mathbf{X_{\text{categorical}}}$\;
		Append train\_voxel to $\text{train\_voxels}$\;
	}
	
	$i\leftarrow 0$\;
	
	\ForEach{test\_voxel in $\text{test\_voxels}$}{
		Get train\_voxel by imposing $\mathbf{X_{\text{categorical}}}$\;
		Compute main nearest neighbour distance inside train\_voxel: $\overline{d}_{\text{train}}(\text{train\_voxel},\text{train\_voxel})$\;
		$\text{avg\_train\_dist}[i]\leftarrow \overline{d}_{\text{train}}$\;
		\If{$\text{size(train\_voxel)} \geq \text{voxel\_size\_req}$}{			
			\ForEach{$\mathbf{X}$ in test\_voxel}{
				Compute minimum nearest neighbour distance: $d_{\text{test}}(\mathbf{X},\text{train\_voxel})$\;
				$\text{min\_test\_dist}[i]\leftarrow d_{\text{test}}$\;
				
				\uIf{$\mathbf{X}$ not in hypercube}{
					\textbf{break}\;
				}
				\Else{
					$\text{inside\_hypercube}[i]\leftarrow \text{True}$\;
					
					\uIf{$\mathbf{X}$ not in CH\_PCA99}{
						\textbf{break}\;
					}
					\Else{
						$\text{inside\_PCA99}[i]\leftarrow \text{True}$\;
						
						\uIf{$\mathbf{X}$ in ambient\_hull}{
							$\text{inside\_ambient}[i]\leftarrow \text{True}$\;
						}
					}
				}
				$i\leftarrow i+1$\;
			}
		}
	}
\end{algorithm}
%After completing the geometrical analysis for every point, the following specific parameters and requirements are to be checked and stored in a subsequent table:
%\begin{itemize}
%	\item Whether there are enough training samples inside each training subset is compared with \texttt{voxel\_size\_req}.
%	\item The percentage of test points inside the ranges of the training samples is to be compared with \texttt{hypercube\_req}.
%	\item The number of points inside the hypercube but outside \texttt{CH\_PCA99} is to be compared with \texttt{CHMP\_PCA99\_negative\_req}.
%	\item The number of points inside the hypercube and \texttt{CH\_PCA99} but outside \texttt{CH\_ambient} is to be compared to the requirement \texttt{CHMP\_ambient\_negative\_req}.
%	\item The total number of points inside \texttt{CH\_ambient} is to be compared to \texttt{CHMP\_ambient\_positive\_req}.
%	\item All these requirements are stored in the \texttt{reqs\_results\_table}.
%\end{itemize}
%%
%\begin{table}[h]
%	\centering
%	\begin{tabular}{|l|l|}
%		\hline
%		\rowcolor[HTML]{EFEFEF} 
%		\textbf{Parameter/Requirement} & \textbf{Comparison Requirement} \\ \hline
%		Hypercube Percentage (\texttt{hypercube\_req}) & To be determined \\ \hline
%		Points Outside \texttt{CH\_PCA99} (\texttt{CHMP\_PCA99\_negative\_req}) & To be determined \\ \hline
%		Points Outside \texttt{CH\_ambient} (\texttt{CHMP\_ambient\_negative\_req}) & To be determined \\ \hline
%		Points Inside \texttt{CH\_ambient} (\texttt{CHMP\_ambient\_positive\_req}) & To be determined \\ \hline
%	\end{tabular}
%	\caption{\texttt{reqs\_results\_table}}
%	\label{tab:reqs_results_table}
%\end{table}
%
\indent Output of \autoref{algo:tt-split} is depicted in \autoref{tab:geo_out}. This information has to be processed to complete \autoref{tab:reqsresults}. The first column identifies the test point inside the test set. The next three columns show information about the corresponding voxel: existance, identification and size. Columns 5 to 7 show information related to pointwise distances inside the voxel. The last three columns show the relative position of the test point inside the voxel (inside the hypercube/convex hull in PCA99/convex hull in ambient space). In this algorithm, if the test point is found to be outside the hypercube ($\text{CH}_{\text{PCA99}}$), then its position with respect to $\text{CH}_{\text{PCA99}}$ and $\text{CH}_{\text{ambient}}$ ($\text{CH}_{\text{ambient}}$) is not computed in the sake of computational efficiency.\\
%
\begin{table}[htbp]
	\centering
	\captionof{table}{Output of \autoref{algo:tt-split}.}
	\label{tab:geo_out}
	\begin{minipage}{1\textwidth}
		\centering
		\includegraphics[width=\linewidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/geo.png}
	\end{minipage}
\end{table}
%
\indent To better understand how the voxels are computed, a reference of their categorical variables is given in \autoref{tab:voxref}. Points inside each voxel all have the same categorical values, which effectively act as a unique identifyer for the voxel. We see each voxel represents a different stringer section between two concrete frames, plus the categorical variable ''np'' which can take the values either $0$ or $0.9$.\\
%
\begin{table}[!htb]
	\centering
	\captionof{table}{Voxel reference table}
	\label{tab:voxref}
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox.png}
\end{table}
%
\indent Data in the column ''inside vox. hypercube'' of \autoref{tab:geo_out} has been rearranged for the sake of interpretability in \autoref{tab:outhypercube}. This table shows the points which lie outside the training voxel hypercube for every voxel where such points exist. Similar tables could be arranged with the number of points belonging to the hypercube but not to the convex hull in a PCA99 projection, or with those points belonging to the convex hull in a PCA99 projection but not in ambient space.\\
%
\indent This information is used to check the following parameters and requirements, which are stored in \autoref{tab:reqsresults}:
%
\begin{itemize}
	\item Whether there are enough training samples inside each training subset is compared with \texttt{voxel\_size\_req}.
	\item The percentage of test points inside the ranges of the training samples is compared with \texttt{hypercube\_req}.
	\item The number of points inside the hypercube but outside \texttt{CH\_PCA99} is compared with \texttt{CHMP\_PCA99\_negative\_req}.
	\item The number of points inside the hypercube and \texttt{CH\_PCA99} but outside \texttt{CH\_ambient} is compared to the requirement \texttt{CHMP\_ambient\_negative\_req}.
	\item The total number of points inside \texttt{CH\_ambient} is compared to \texttt{CHMP\_ambient\_abs\_req}.
	\item All these requirements are stored in \autoref{tab:reqsresults}.
\end{itemize}
%
\begin{table}[!htb]
	\centering
	\captionof{table}{Points outside voxel hypercube}
	\label{tab:outhypercube}
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/outside_hypercube_c.png}
\end{table}
% 
\begin{table}[!htb]
	\centering
	\captionof{table}{\texttt{reqs\_results\_table}. The first and the last requirements compare absolute figures of points at some isolation level with the overall number of points. Whereas the second and third requirements compare the difference in number of points between two consecutive levels with the total number of points.}
	\label{tab:reqsresults}
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/reqs_table.png}
\end{table}
%
\indent Having analised the isolation level of test points, it is necessary to check wheter p-hacking is taking place. That is, whether test points are unrealistically close to train points, thus making the model evaluation flawed. This is measured using the Mann-Whitney U test\cite{rosner1999use}. In this test, the initial hypothesis H0 is that both distributions are the same. H1 is that the distribution underlying test-training distances is stochastically less than distribution underlying training-training distances, which would involve risk of p-hacking. H0 is rejected only with a 95\% confidence. For instance, for the dataset of MSP-18, the resulting p-value is $p=0.9793$, thus the null hypothesis is not rejected and the dataset can be assumed to be free of p-hacking.\\
%
\subsubsection{Non-geometrical analysis}
\indent To help (the engineer in charge) make a decission about the dataset split, another approach is developed, complementary to the geometrical analysis carried out so far. This approach consists of focusing on the statistical distributions of the train and the test datasets. A proper train-test split is characterised by similar statistical distributions of both sets (test and training)\cite{bonnasse2022interpolation}. When this cannot be achieved, a softer requirement is that each of the feature variables $X_i$ need to have reasonably similar marginal distributions in the training and the test set.\\
%
\indent The following analysis checks whether, for each individual input feature, the distribution of the training and test set is reasonably similar. This is also checked for the output variables (the ground true ones, thus this is independent from the surrogate model). Finally, the splitting can be done locally, \ie region by region, by binning each numerical variable. The implementation of this analysis tackles each input variable $X_i$ independently and for each input variable, it compares the training and the test set such that:\\
\begin{itemize}
	\item If the variable $X_i$ is `categorical`: both (train and test) categorical frequency distributions are plotted (\autoref{fig:inputscatdhist}), a 2-sample $\chi^2$ test\cite[p. 431]{velez1994calculo} is performed, and the p-value of such test is introduced in \autoref{tab:pvalin}.
	\item If the variable $X_i$ is numerical: both (train and test) numerical frequency distributions are plotted (\autoref{fig:inputsdhist}), a 2-sample Kolmogorov-Smirnov test\cite[p. 454]{velez1994calculo} is carried out, and the p-value of such test is introduced in the same table.
\end{itemize}
%
\indent The null hypothesis for both tests is that both train and test distributions are the same. H0 is only rejected with a 95\% confidence.\\
%
\begin{table}[!htb]
	\centering
	\captionof{table}{P-values of the input variables. The test performed is a 2-sample Kolmogorov-Smirnov or a 2-sample $\chi^2$ test, depending on the data being numerical (first 19 rows) or categorical (''dp'', ''Frame'' and ''Stringer'').}
	\label{tab:pvalin}
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/pvalues_input.png}
\end{table}
%
\begin{figure}[!htb]
	\centering
	\includegraphics[width=\textwidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/inputs_dhist.png}
	\caption{Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.}
	\label{fig:inputsdhist}
\end{figure}
%
\begin{figure}[!htb]
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.8\textwidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/inputs_cat_dhist.png}
	\end{subfigure}
	
%	\vspace{1cm} % Espacio vertical entre las subfiguras
	
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.8\textwidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/inputs_str_dhist.png}
	\end{subfigure}
	\caption{Input categorical variables distributions double histograms}
	\label{fig:inputscatdhist}
\end{figure}
%
\indent As stated earlier, applicability is not only a matter of the \textit{input} space, but also of the \textit{output} space. The 2-sample Kolmogorov-Smirnov test has been performed again on each of the six output variables. The p-values and their statistical distributions are depicted in \autoref{tab:pvalout} and \autoref{fig:outputsdhist}, respectively.\\
%
\begin{table}[!htb]
	\centering
	\captionof{table}{P-values of the output variables distributions}
	\label{tab:pvalout}
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/pvalues_outputs.png}
\end{table}
%
\begin{figure}[!htb]
	\centering
	\includegraphics[width=\textwidth]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/outputs_num_dhist.png}
	\caption{Output variables distributions double histograms}
	\label{fig:outputsdhist}
\end{figure}
%
\subsubsection{Train-test split. Conclusions}
\indent The proposed validation loop for the train-test split focuses, on the one hand, on the applicability classification problem, which makes use of a geometrical analysis which classifies test points at different levels of isolation. A series of requirements are defined based on the proportions of such isolated points. Plus, p-hacking is checked. The output of this analysis is showed in \autoref{fig:coloreqs_table}.\\
%
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/colorequirements.png}
	\caption{Requirements of the geometrical analysis}
	\label{fig:coloreqs_table}
\end{figure}
\indent On the other hand, the distributions of both input and output variables in the training set are checked to be reasonably similar to that of the test set. The main outputs are the p-values shown at \autoref{tab:pvalin} and \autoref{tab:pvalout}.\\
%
\indent Of course, any given dataset may meet some of the requirements, but not all (as is the case with the MSP-18 dataset). The engineer in charge should evaluate the ensemble output and decide whether it is necessary to redo the split completely or partially, depending on data availability.




\clearpage
\begin{table}[htbp]
%	\centering
	\newlength{\voxrefw}
	\settowidth{\voxrefw}{\includegraphics{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox.png}}
	\edef\tabvoxrefw{\fpeval{\voxrefw*\tabscale}}
%	Hola \the\tabvoxrefw
	\begin{minipage}{\dimexpr\tabvoxrefw pt\relax}
		\centering
		\caption{Output of \autoref{algo:tt-split}: \texttt{reqs\_results} table}
		\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox.png}
	\end{minipage}
\end{table}

\begin{table}[htbp]
	\centering
	\mytable{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox.png}{Voxel reference table. Lorem ipsum dolor sit amet, consectetuer adisciping elit.}
\end{table}


%\begin{minipage}[t]{0.4\linewidth}
%	\raggedright
%	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox2.png}
%\end{minipage}\hfill
%\begin{minipage}[t]{0.4\linewidth}
%	\raggedleft
%	\includegraphics[scale=\tabscale]{/home/pablo/Documentos/TFGP/Thesis/Figures/tt-split/refTableVox.png}
%\end{minipage}


\indent The first step is check whether the train and test datasets follow the same empirical distributions. If test data is found to not follow the same distribution as the train data, the evaluation of the model would be biased or the test data would be outside input applicability. Take, for instance, the extreme case in which the statistical distribution for some input numerical variable follows a uniform distribution $x_{train} \sim U(a_1,a_2)$ whereas the same input variable in the test dataset follows another distribution $x_{test} \sim U(b_1,b_2)$ where $b_1 \leq a_2$. Clearly, $x_{test}$ is outside the hypercube spanned by $x_{train}$ and is outside the applicability region as a consequence.

\begin{definition}\label{def:orden1}
	Let $\mathbf{X}$ represent some dataset, which has been split in $\mathbf{X}^{TRAIN}$ and $\mathbf{X}^{TEST}$. $\mathbf{X}$ is said to be order 1 [O(1)] well-split if and only if $\mathbf{X}^{TEST} \subseteq Hull[\mathbf{X}^{TRAIN}]$.\\
	
	Where we denote the convex hull of $\mathbf{X}^{TRAIN}$ by $Hull[\mathbf{X}^{TRAIN}]$.
\end{definition}

\begin{definition}
	Let $\mathbf{X}$ represent the dataset defined in \autoref{def:orden1}. $\mathbf{X}$ is said to be order 2 well-split if and only if 
\end{definition}
%



\clearpage
\section{Las movidas de Rodrigo}
%
\indent Orbit propagation is a very wide and varied field. It comprises many different approaches and methods to obtain more or less accurate results, with a higher or lower computational cost. Some examples are the numerical integration of the equations of motion in cartesian coordinates, the numerical integration of the variational equations (\ie equations of motion expressed in OEs) and the development of closed-form solutions by simplifying the problem. Within this last group, State Transition Matrices arise.\\
%
\indent The State Transition Matrix is a linearization procedure of a nonlinear dynamical system. It is used to approximate the dynamics of said system over short periods of time, allowing for a lower computational cost while maintaining an acceptable accuracy. This concept is not restricted to orbital mechanics, although it is one of the main fields in which it is used \cite{Montenbruck}. \\
%
\indent This section intends to provide some background in (a) its mathematical formulation and (b) its applications in orbit theory.
%
	\subsection{Concept: System dynamics.}
	%
	\indent Consider the uncontrolled, nonlinear dynamic system that is characterized through the state vector $\underline{y} = \left[ y_1, y_2, \ldots, y_n \right]$. The Initial Value Problem (IVP) for this system may be expressed as:
	%
	\begin{equation}
	[P] \equiv \left\{ \begin{array}{lll}
	\text{Eq.}	 	& \dfrac{d \underline{y}}{dt} = \bm F(\underline{y}, t) \\
	\text{ICs.} 	& \underline{y}(t_0) = \underline{y}_0
	\end{array}\right.
	\label{eqCh1:Problem_def}
	\end{equation}
	%
	\noindent where $\bm F(\underline{y}, t)$ represents the nonlinear dynamics of the system. This problem is unsolvable in general, mainly due to its nonlinearity. In the context of orbit propagation, the state vector $\underline{y}$ might be the position and velocity (be it relative or absolute) of the celestial body, and the dynamics function $\bm F$ contains the considered force model. In order to arrive at a closed-form, solvable problem, it is assumed that the solution $\underline{y}(t)$ can be expressed as:
	%
	\begin{equation}
	\underline{y}(t) = \Phi (t, t_0) \underline{y}(t_0)
	\label{eqCh1:STM_1}
	\end{equation}
	%
	\noindent where $\Phi (t, t_0)$ is the State Transition Matrix (STM) of the system. This matrix allows the state vector at a certain epoch $t$ to be calculated as the product of the matrix times the initial condition. This expression is obviously very favorable, but the question now is how does one compute it. Its actual definition can be easily derived from \eqref{eqCh1:STM_1} as:
	%
	\begin{equation}
	\Phi (t, t_0) \equiv \dfrac{\partial \underline{y}}{\partial \underline{y}_0}
	\label{eqCh1:STM_2}
	\end{equation}
	%
	\indent Yet again, how to compute it is not clear at all. There are three main options, depending on the situation:
	%
	\begin{itemize}
	\item[\GMVred{A.}] If the nonlinear solution as a function of the initial condition is known, then the expression \eqref{eqCh1:STM_2} is directly applied. This is an uncommon case, although simplified examples exist in the orbit propagation field. For example, the Keplerian motion equations expressed in Keplerian orbital elements (OEs) can be solved this way, due to the trivial remaining equations. Another example is the Clohessy-Wiltshire solution, from which the STM can be directly obtained. This process is detailed later on in section \ref{secCh2:CW_STM}.
	%
	\item[\GMVred{B.}] The nonlinear solution is unknown in the original state space, but can be calculated in a different space through a transformation. Mathematically, this can be written as:
	%
	\begin{equation}
	\Phi_{y} (t, t_0) = \dfrac{\partial \underline{y}}{\partial \underline{y}_0} = \dfrac{\partial \underline{y}}{\partial \underline{u}} \dfrac{\partial \underline{u}}{\partial \underline{u}_0} \dfrac{\partial
	\underline{u}_0}{\partial \underline{y}_0} \equiv W(t) \Phi_u(t, t_0) \left( W(t_0) \right)^{-1}
	\label{eqCh1:STM_decomp}
	\end{equation}
	%
	\noindent where $W(t)$ is the transformation matrix, where it is assumed that the transformation $\underline{y} = h(\underline{u})$ is known. An example of this kind of approach is the transformation of the Cartesian equations of motion into the Keplerian OEs, whose solution is known, as mentioned in \GMVred{A.}. This is a very commonly used method in relative orbit propagation, as in \cite{Yamanaka_Ankersen, GA_STM}.
	%
	\item[\GMVred{C.}] If none of the above can be performed, then the STM can be integrated itself, to be then used to calculate the state vector. This starts by differentiating \eqref{eqCh1:Problem_def} with respect to the initial condition $\underline{y}_0$, leading to:
	\[
	\begin{array}{ll}
	\bullet & \dfrac{\partial}{{\partial \underline{y}(t_0)}} \dfrac{d\underline{y}(t)}{dt} = \dfrac{d}{dt}\dfrac{\partial \underline{y}(t)} {{\partial \underline{y}(t_0)}} = \dfrac{d}{dt} \bm \Phi (t, t_0) \\[1.2em]
	\bullet & \dfrac{\partial \bm F(t, \underline{y})}{{\partial \underline{y}(t_0)}}  = \dfrac{\partial \bm F(t, \underline{y})}{{\partial \underline{y}(t)}} \dfrac{\partial \underline{y}}{{\partial \underline{y}(t_0)}} = \bm A \bm \Phi(t, t_0)
	\end{array}
	\]
	%
	\begin{equation}
	\Rightarrow [P] \equiv \left\{ \begin{array}{lll}
	\text{Eq.} 	& \dfrac{d}{dt} \Phi (t, t_0) = \bm A \Phi(t, t_0)\\
	\text{IC} 	& \Phi(t_0, t_0) = \eye_{nxn}
	\end{array}\right.
	\label{eqCh1:STM_prop}
	\end{equation}
	%
	\indent This last method is a bit unrewarding, as it forces one to integrate an IVP. However, the problem in terms of $\Phi(t, t_0)$ (eq. \eqref{eqCh1:STM_prop}) might be simpler or more efficient than the original (eq. \eqref{eqCh1:Problem_def}), although it is rare. An example of this approach is shown later in section \ref{secApp2:STM_prop}.
	%
	\end{itemize}
	%
	\subsection{Applications of STMs in celestial mechanics.}
	%
	\indent State Transition Matrices can be useful in a wide range of spacecraft dynamics applications. Some of the most important are \cite{STM_Apps}:
	%
	\paragraph{\GMVred{A.} \myul[GMVred]{Precise Orbit Determination.}\\}
	%
	\indent Precise Orbit Determination (POD) is a method through which the orbit of a flying spacecraft can be determined with a high accuracy \cite{POD}. This estimation is performed using general orbit determination algorithms, such as Kalman filtering or a batch least squares. It requires both high-precision geodetic receivers and high-precision dynamics models, where STMs comes to play. POD usually requires all typically important perturbations, such as non-spherical gravity, drag, tidal forces \ldots 
	%
	\paragraph{\GMVred{B.} \myul[GMVred]{Guidance, Navigation and Control (GNC).} \\}
	%
	\indent GNC deals with the design the systems to control the spacecraft. It involves the determination of the desired trajectory (guidance), the instantaneous determination of the spacecraft's position (navigation) and the manipulation of the controllers to execute guidance commands (control). STMs become very useful specially in situations in which the linearization error is small, such as in rendez-vous, station-keeping or formation flying operations. They prove to be useful in all three branches:
	%
	\begin{itemize}
	\item Guidance: STMs are a lightweight yet precise tool to generate reference trajectories.
	%
	\item Navigation: Signal filtering makes extensive use of STMs for the propagation of the estimated state. This is certainly one of the most relevant applications.
	%
	\item Control: Algorithms like robust online optimal control involve state propagation, using the STM.
	\end{itemize}
	%
%	\indent Unfavorable scenarios (\eg elliptic or perturbed orbit) may lead to greater linearization errors, unless an enhanced model is developed. This will be one recurring topic around the thesis.
%	%
	\paragraph{\GMVred{C.} \myul[GMVred]{Orbit design.} \\}
	%
	\indent Alternatively, rather than propagating already defined orbits, it may be useful to solve the inverse problem: that is, find the orbit that satisfies a set of conditions (\eg optimality). This is specially relevant for the Circular Restricted Three Body Problem (CR3BP), or its particular case of Halo orbits (periodic 3D orbit near one of the Lagrange libration points). STMs are quite useful to determine an initial solution for said Halo orbits, and can also be used to evaluate the effect of a deviation in initial conditions or other parameters. 
	%
	\paragraph{\GMVred{D.} \myul[GMVred]{Covariance matrix propagation.} \\}
	%
	\indent Some degree of uncertainty will always be assumed in the estimation of a spacecraft's position and velocity. This matter becomes really important in the context of collision avoidance, where ideally, said uncertainty would be exactly calculated. However, these values are usually not something inherently worrying. What is worrying indeed is that this uncertainty may propagate in a divergent fashion, leading to unbounded trajectories with its inherent collision risk.\\
	%
	\indent Here is where the covariance matrix comes to light. Conceptually, it can be seen as an entity which indicates how certain are each of the components of the state vector. That is represented by their variances and covariances. Mathematically, it is defined as:
	%
	\[
	P(t) 	= E\left[ \left(\underline{\hat{x}} - \underline{x}\right) \left(\underline{\hat{x}} - \underline{x}\right)^T \right]
	\]
	%
	\indent If one knew the covariance at a certain epoch $t_j$, it is possible to map it to a different epoch $t_k$ (latter or earlier) through the STM, that is:
	%
	\[
	\begin{array} {c} P(t_k) 	=  E\left[ \left(\underline{\hat{x}_k} - \underline{x_k}\right) \left(\underline{\hat{x}_k} - \underline{x}_k\right)^T \right] = E\left[\Phi(t_k, t_j) \left(\underline{\hat{x}_j} - \underline{x}_j\right) \left(\underline{\hat{x}_j} - \underline{x_j}\right)^T \Phi^T(t_k, t_j)\right] \\[1.3em]
	\Rightarrow P(t_k)=  \Phi(t_k, t_j) P(t_j) \Phi^T(t_k, t_j) \end{array}
	\]
	%
	\indent Now, once the mathematical formalism has been stated, it is time to apply it to the situation at hand. Spacecraft state uncertainty has essentially two sources: estimation error (associated to navigation) and execution error (associated to control/manoeuvres). \\
	%
	\indent In a fairly relaxed approach (\ie assuming the state variables be decoupled), the covariance matrix associated to the estimation error has the following shape:\\
	%
	\begin{equation}
	P_{est} = \left[ \begin{array}{cccccc}
	\delta x^2 	& 0 			& 0 			& 0 			& 0 			& 0 \\
	0 			& \delta y^2	& 0 			& 0 			& 0 			& 0 \\	
	0 			& 0 			& \delta z^2 	& 0 			& 0 			& 0 \\
	0			& 0 			& 0 			& \delta v_x^2 	& 0 			& 0 \\
	0			& 0 			& 0 			& 0				& \delta v_y^2 	& 0 \\
	0			& 0 			& 0 			& 0				& 0 			& \delta v_z^2 \\
	\end{array} \right]
	\label{eqCh1:P_est}
	\end{equation}
	%
	\noindent where $\delta \psi$ indicates the standard deviation of the variable $\psi$. An useful way to visualize the covariance is the probability ellipsoid, defined by:
	%
	\[
	\left[\begin{array}{ccc}
	\tilde{x} & \tilde{y} & \tilde{z}
	\end{array} \right] 
	P_{xyz}^{-1} 
	\left[ \begin{array}{c}
	\tilde{x} \\ \tilde{y} \\ \tilde{z} \\
	\end{array} \right] = l^2
	\]
	%
	\noindent where $\tilde{x}, \tilde{y}, \tilde{z}$ are the coordinates of a point of the ellipsoid (referred to its center), $P_{xyz}$ is the partition of the covariance matrix related to the position and $l$ is the sigma coefficient. That is, for $l = 2$, the equation represents the ellipsoid in which the spacecraft will be found with a $2\sigma$ probability. An example of the evolution of this ellipsoid can be seen for a small radial hop in figure \ref{figCh1:Covariance_segment}. 
	%
	\begin{figure}[!htb]
	\centering\includegraphics[width = 0.90\linewidth]{Chapters/Chapter_01/Covariance_segment}
	\caption{Covariance ellipsoid evolution along a radial hop.}
	\label{figCh1:Covariance_segment}
	\end{figure}
	%
	\FloatBarrier
	%
	\indent Most of these concepts lie out of the thesis' scope. However, it is important to know that the STMs developed or quoted throughout this thesis can be used in many different fields of celestial mechanics.
	%