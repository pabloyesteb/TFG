\chapter{General concepts on supervised learning for industrial applications}\label{chap:1}
In the dynamic landscape of industrial applications, the integration of supervised learning techniques has emerged as a pivotal force in addressing complex challenges, particularly within the aerospace industry. This chapter delves into the foundational concepts of industrial-oriented supervised learning, focusing on its profound implications for solving regression problems inherent in various aerospace endeavors. From optimizing fuel consumption\cite{hong2018data} to enhancing structural integrity\cite{pfingstl2023warped}, numerous industrial dilemmas can be effectively framed as regression tasks, where supervised learning algorithms offer unparalleled potential for both solvability and computational efficiency. Within the realm of industry-oriented supervised learning, understanding the mathematical background of these methodologies lays the groundwork for harnessing their transformative impact on real-world industrial challenges, particularly within aerospace domains.\\
%
\section{Mathematical description of ANNs}\label{sec:ANNs}
\indent Mathematically, the problems we refer to in this chapter consist of finding the explicit shape of a function
\begin{align}\label{eq:F}
	& \mathcal{F}_{t}:S_X\rightarrow S_{Y_{t}} \\
	& \mathcal{F}_t(\mathbf{x})=\mathbf{y}_t
\end{align}
with $S_X\subset\mathbb{R}^n$ and $S_Y\subset\mathbb{R}^m$; \ie the function $\mathcal{F}_t$ takes as input a vector $\mathbf{x}=\{x_1,x_2,\ldots,x_n\}$, and outputs a vector $\mathbf{y}_t=\{y_{t1},y_{t2},\ldots,y_{tm}\}$. The input vector could represent, for instance, a collection of loads applied to some part of the fuselage structure of an aeroplane, whereas the output vector may represent the probability of failure of that structure under the loads contained in $\mathbf{x}$. The problem at hand would therefore be finding the function $\mathcal{F}_t$ which maps load configurations to failure probabilities. By categorizing the task of finding such function $\mathcal{F}$ as a ''regression problem'', we mean usually $n>>m$. Note that finding the explicit shape of $\mathcal{F}_t$ might be a difficult task when $\mathcal{F}_t$ is a strongly non-linear function, especially if $n>>1$.\\
%
\indent Although regression problems can be tackled by several means, in this work we will focus on artificial neural networks or ANNs\cite{Marsland2015Machine}\footnote{When using an ANN to solve a regression problem, we shall refer to it (the ANN) as a surrogate model as well}. From this approach, the starting point is a parametrized function $\mathcal{F}$ with which we shall approximate $\mathcal{F}_t$ (which is taken as the ground true --unknown-- function that conveys the physics of the regression problem\footnote{Indeed, $\mathcal{F}_t$ is just a conceptual instrument we use to associate pairs of input-output values $(\mathbf{x}_i,\mathbf{y}_i)$.}), so that we have:

\begin{align}
	& {\mathcal{F}} : S_X \rightarrow S_Y \\
	& {\mathcal{F}}(\mathbf{x}; W) = \mathbf{{y}} \label{eq:Fhat}
\end{align}

Where $W$ is the set of parameters defining the explicit shape of $\mathcal{{F}}$. In this equation, the absence of subscript ''t'' accounts for the difference between our parametrized function and the real function we are trying to find, the one from \cref{eq:F}. N.B. the domain set $S_X$ is the same for both $\mathcal{F}_t$ and $\mathcal{F}$, which is not the case for the codomain.\\
%
\indent When speaking about regression problems, the input vector $\mathbf{x}$ is usually called the ''feature vector'', while the output vector $\mathbf{y}_t$ is usually called --in a descriptive way-- the ''prediction vector''. Similarly, $n$ is called the ''feature'' or the ''input'' dimension, and $m$ is called the ''output'' or the ''prediction'' dimension.\\
%
\indent We shall denote $\mathcal{{F}}$'s dependency on $W$ with a subscript: $\mathcal{{F}}_W$. Mathematically, the explicit shape of $\mathcal{{F}}_W$ can adopt a wide variety of expressions. Perhaps the most common architecture is the so-called Multi Layer Perceptron (MLP)\cite{Marsland2015Machine}, which basically consists of a series of iterative affine transformations, the first of which is applied to the elements of $\mathbf{x}$ (defined by the parameters $W$) and non-linear functions (the rectified linear unit function or ReLU, the sigmoid function and the hyperbolic tangent being the most widely used) applied to each iteration's result.\\
%
\indent The approach now is to define a distance $\mathcal{L}=\|\mathcal{F}_t-\mathcal{{F}}\|$ and treat the regression problem as the task of minimizing $\mathcal{L}$:
\begin{equation}\label{eq:Fargmin}
	\mathcal{{F}}^*=argmin(\mathcal{L})
\end{equation}\\
%
\indent From a practical point of view, the information available for defining $\mathcal{L}$ consists of a (large\footnote{By large, we mean $\left|S^\text{Full}\right|>>n$ (cfr. \cref{eq:full}).}) set of duplets $(\mathbf{x},\mathbf{y}_t)$\footnote{N.B. the lack of hat here, meaning data has been sampled from the domain and codomain of $\mathcal{F}$, $S_X$ and $S_Y$, respectively.} representing empirical samples from the feature and the prediction space coming from experimental data, simulations, or any other source. Such set is called $S^\text{Full}$:
\begin{equation}\label{eq:full}
	S^\text{Full}=\{\mathbf{x}_i,\mathbf{y}_{ti}\}_{i=1}^{N_{\text{Full}}}
\end{equation}
The procedure is to split Full into a training and a test set, so that
\begin{align}
	& S^\text{Train} \cup S^\text{Test} = S^\text{Full} \\
	& S^\text{Train} \cap S^\text{Test} = \emptyset \\
	& |S^\text{Train}| > |S^\text{Test}|
\end{align}\\
%
$\mathcal{L}$ (which is called the ''loss function'') can now be defined as
\begin{align}
	& \mathcal{L}=\mathcal{L}(W) \\
	& \mathcal{L}(W)=E(W)+\lambda R(W) \label{eq:loss}
\end{align}
where
\begin{equation}\label{eq:error}
	E(W) = \|S^\text{Train}_{Y_t} - S^\text{Train}_Y\|
\end{equation}
and
\begin{equation}\label{eq:regularization}
	R(W) = \|W\|
\end{equation}
for any defined norm $\|\cdot\|$. In \cref{eq:loss}, $\lambda$ is just an arbitrary scaling factor. For the explicit dependence of $E$ on $W$, recall \cref{eq:Fhat}\footnote{N.B. $S^\text{Test}_{\mathbf{{Y}}}$ is not available beforehand; it is generated by applying $\mathcal{{F}}_W$ to $S^\text{Test}_{\mathbf{X}}$.}.\\
%
\indent $\mathcal{L}$ is called the ''loss function''. We can see from \cref{eq:loss} that it combines the effect of two terms: the error term (\cref{eq:error}) accounts for the mismatch between actual data in $\mathcal{F}$'s codomain and our parametrized function's predictions, whereas the regularization term (\cref{eq:regularization}) imposes a restriction on the set $W$ (which is done mainly for numerical stability reasons). The exact definition of $E(W)$ and $R(W)$ is an arbitrary choice. Common used error functions are:
\begin{itemize}
	\item The Mean Square Error (MSE):
	\begin{equation}\label{eq:mse}
		E(W) = \frac{1}{N_{\text{Train}}} \sum_{i=1}^{N_{\text{Train}}} (\mathbf{y}_{ti} - \mathbf{\hat{y}}_i)^2
	\end{equation}
	\item The Mean Absolute Error (MAE):
	\begin{equation}\label{eq:mae}
		E(W) = \frac{1}{N_{\text{Train}}} \sum_{i=1}^{N_{\text{Train}}} \left|\mathbf{y}_i - \mathbf{\hat{y}}_{ti}\right|
	\end{equation}
\end{itemize}

For the regularization term, a common choice is the $L_2$ norm.\\
%
\indent Let us rewrite now the optimization problem defined in \cref{eq:Fargmin} the following way:
\begin{equation}
	W^* = argmin\{L(W))\}
\end{equation}

The algorithm commonly used to find $W^*$ is gradient descent:
\begin{equation}\label{eq:train}
	W(k+1)=W(k)-\eta\nabla_W\mathcal{L}(W)
\end{equation}

Where, again, $\eta$ is an arbitrarily defined scaling factor which receives the name of ''learning rate''.\\
%
\indent A plethora of different algorithms have been tried for ANN training, but the majority of them shares the basic concept with gradient descent. Amongst common techniques, descending learning rates and stochastic gradient descent are perhaps the most widely used. Descending learning rate just means $\lambda$ decreases as successive loops of \cref{eq:train} are completed. Stochastic gradient descent (Cfr. \cite{Marsland2015Machine} for further details) applies the loss function, \cref{eq:loss} is applied to a batch randomly sampled from $S^\text{Train}$ instead of the whole set.
%
\section{Overfitting. Bias-variance trade-off}\label{sec:overfitting}
\indent An important phenomenon to care about during training of ANNs is \textbf{overfitting}\footnote{For more extense treaty on this topic, cfr. \cite{Marsland2015Machine}}. When aiming to solve any regression problem with ANNs, one must decide on the architecture (by architecture we mean the explicit definition of $\mathcal{{F}}_W$). One example of possible network architectures are the aforementioned Multi Layer Perceptrons. An important characteristic of the network is the size of the set $W$. Popular wisdom in machine learning says the more complex, non-linear the function $\mathcal{F}_t$ is, the larger the parameter set $W$ needs to be in order to properly capture all the features in $\mathcal{F}_t$. One can build an analogy between a regression problem with ANNs and a polynomial interpolation problem. If $\mathcal{F}_t$ is supposed to be a polynomial\footnote{Usually there are absolutely no guarantees that $\mathcal{\hat{F}}_W$ is a polynomial. Here we are just assuming it for illustration purposes.}, then the objective of minimizing the loss function as defined in \cref{eq:mse} is equivalent to the polynomial interpolation problem of fitting the points $\{(\mathbf{x}_i,\mathbf{y}_{ti})\}_{i=1}^{N_{\text{Train}}}$ in $S^\text{Train}$. In this case $W$ would just represent the set of coefficients $\{c_0,c_1,\ldots,c_{N_W}\}$ that defines the polynomial $\mathcal{{F}}_W$. The minimum degree of the polynomial that solves this interpolation problem is clearly $N_{\text{Train}}\equiv\left|S^{\text{Train}}\right|$. Now, if we set $N_W<N_{\text{Train}}$, obviously we would not be able to fit all points in the train set and the minimum of the loss function as defined in \cref{eq:loss} would be presumably high. When this occurs, it is said that the model $\mathcal{{F}}_W$ has high bias. Due to the lack of sufficient trainable parameters in $W$, the model is not capable of learning all the intricacies and patterns in the training set. Our model is just not complex enough for the regression task we aimed to solve.\\
%
\indent On the other hand, setting $N_W>>N_{\text{Train}}$ can lead to the so-called overfitting. In industrial applied regression problems, data in $S^\text{Full}$ comes from experiments or numerical simulations, as has been mentioned before. This kind of data irremediably involves some noise. The noise might be coming from sensors, numerical instabilities in the simulations, signal noise, etc. Now take for instance the target function $\mathcal{F}_t$ is a polynomial of degree $N_1<<N_{\text{Train}}$. This means our training set is redundant as we have sampled $N_\text{Train}$ points from a polynomial of degree $N_1$. If data was noise free, our interpolation problem would be determined by just $N_1$ points in the test set and coefficients $\{c_{N_1+1},c_{N_1+2},\ldots,c_{N_W}\}$ would be identically zero. But presence of noise deviates points in $S^\text{Train}$ from the actual polynomial $\mathcal{F}_t$, and thus makes the interpolation problem non redundant, \ie the coefficients $\{c_{N_1+1},c_{N_1+2},\ldots,c_{N_W}\}$ would be different from zero and our surrogate model $\mathcal{{F}}_W$ will have a higher degree than the actual $\mathcal{F}_t$. Fitting the noise in $S^\text{Train}$ is what is called overfitting. Clearly this is undesirable from all points of view, namely:
\begin{itemize}
	\item Computational resources are invested in fitting irrelevant noise.
	\item By fitting the noise in the training set, the model loses generalization capability, \ie although the loss $\mathcal{L}$ in the training set might be very low due to the model correctly fitting every point in that set, performance in the test set drops due to the noise patterns the model has learnt in the training set not being present at the test set. This will cause a mismatch between the training and the test loss (low and high, respectively). When this occurs, we refer to it as the model having high variance.
\end{itemize}

It is clear from all the above that during the training phase it is paramount to achieve an equilibrium between bias and variance, \ie between configuring a model complex enough to capture all the patterns and correlations in the data and avoiding overfitting.\\
%
\indent There exists several regularization techniques to avoid overfitting, mainly early stopping and random neuron deactivation (dropout)\cite{Marsland2015Machine}.\\
%
\indent Bias-variance trade-off will be a present idea throughout the validation pipeline. One of the goals of the validation, especially of \autoref{sec:ttsplit} is to prevent overfitting and to provide mechanisms to detect it.

\section{Applicability}
Another important concept which will be later used in \autoref{chap:3} is the applicability region of a surrogate model.\\
\indent The applicability region can be intuitively defined as the set of the input and output values for which the model's prediction can be trusted. Applicability region is a refined idea of the \textit{Operational Design Domain} of a model.\\
\indent For a model $\mathcal{F}$ to be applicable to a certain new point $x$:
\begin{itemize}
	\item $\mathbf{x}$ needs to be inside the \textit{input} applicability region of $\mathcal{F}$.
	\item The prediction $\mathbf{y}=\mathcal{F}(\mathbf{x})$ needs to be inside the \textit{output} applicability region of $\mathcal{F}$.\\
\end{itemize}
%
\indent Knowing whether a new point is either inside or outside applicability is a binary decision problem which can be addressed \textit{a priori} (filtering) or be learned \textit{a posteriori} (model boosting). In other words, the binary classification can be addressed from an unsupervised (geometric) learning approach, or a supervised learning approach:
\paragraph{\GMVred{A.} \myul[GMVred]{Supervised applicability classifyers}\\}
Supervised applicability classifiers are based on exogenous criteria. Examples of them include:
\begin{itemize}
	\item \textbf{Operational design domains.} Based on engineer/scientist expertise, only certain combinations and range of features make physical sense. These combinations are used to define a (geometrical) applicability region.
	\item \textbf{Error-filtered convex hull.} Initially the whole set under testing is in applicability range. After filtering those test cases whose prediction error exceeds a tolerance, the applicability region is defined as the convex hull of the remaining subset. The convex hull can be simply defined as the smallest convex set containing the data\cite{Preparata1985} (vid. \cref{fig:policonex}).
	\item \textbf{Error-labelled classifiers.} Initially a whole subset of the dataset (namely, the test set) is in applicability range. After labelling those test cases whose prediction error exceeds a tolerance as outside applicability, different binary classifiers are trained on the full dataset.\\
\end{itemize}

\paragraph{\GMVred{B.} \myul[GMVred]{Unsupervised applicability classifyers}\\}
On the other hand, geometrical applicability classifiers are based on the premise of NN interpolation capabilities. It has been widely discussed (see \eg \cite{pmlr-v80-barrett18a,DBLP:journals/corr/abs-1711-00350,DBLP:journals/corr/abs-1904-01557}) that NN's performance relies on their interpolation capabilities, and that no extrapolation capabilities outside their applicability region should be assumed.\\
%
\indent Subsequently, from a geometrical approach to the applicability classification problem, we shall define the input applicability region as the geometrical region in the input space where the model is known to work in interpolating regime.\\
%
\indent There are plenty of definitions for the interpolating region of a given dataset. Some authors define it as the smallest hypercube enclosing the data\cite{ebert2014interpolation} (vid. \cref{fig:hipercuboex}) although this may seriously challenge interpolation due to isolated points falling into the interpolation region under this definition. Many authors (see v. gr. \cite{loh2007extrapolation,4505337}) define the interpolation region as the \textit{convex hull} of the training data, \ie:

\begin{definition}\cite{balestriero2021learning}\label{def:interpolacion}
	Standard interpolation occurs for a sample $\mathbf{x}$ whenever this sample belongs to the convex hull of a set of samples $S^\text{Train}_X=\left\{\mathbf{x}_1,x_2,\ldots,\mathbf{x}_N\right\}$.
\end{definition}

\indent Recently, the authors from \cite{balestriero2021learning} have pointed out that, due to the so-called curse of dimensionality, extrapolation outside the training convex hull always ends up taking place if the input dimension is sufficiently large. The curse of dimensionality\cite[pp. 17-18]{Marsland2015Machine} can be illustrated by the fact that the unitary $n$-sphere's volume asymptotically diminishes to $0$ as $n$ increases. In the end, the effect is that, as the number of dimensions increase, more data is needed in order for the model to work in interpolating regime, as is showed by \autoref{dparadoxa}.\\

\begin{theorem}\cite{barany1988shape}\label{dparadoxa}
	Given a $d$-dimensional dataset $S_X=\left\{\mathbf{x}_1,...,\mathbf{x}_N\right\}$ with i.i.d. samples uniformly drawn from a hyperball, the probability that a new sample $\mathbf{x}$ is in interpolation regime (recall \cref{def:interpolacion}) has the following asymptotic behaviour:\\
	
	\begin{equation}
		\lim_{d \to \infty}p(\mathbf{x}\in Hull(\mathbf{X}))=
		\begin{cases}
			1 \iff N>d^{-1}2^{\frac{d}{2}}\\
			0 \iff N<d^{-1}2^{\frac{d}{2}}
		\end{cases}	
	\end{equation}
\end{theorem}

\indent The main answer to the argument of \cite{balestriero2021learning} is that interpolation does not occur in the ambient space, but in a latent, low-dimensional space of the input data\cite{bonnasse2022interpolation}. This leads to a new definition of interpolation alternative to \cref{def:interpolacion}.\\
%
\indent Interestingly, the authors in \cite{bonnasse2022interpolation} go beyond demonstrating that interpolation occurs (at least in a latent representation of the ambient space). They unveil two more crucial conditions for optimal model performance:
%
\begin{itemize}
	\item The training and testing data should share the same cumulative distribution. In situations where this is impossible, matching the tail distribution becomes essential.
	\item The testing points should not be isolated within the dataset. This means they should have similar characteristics to other data points and not represent extreme outliers that testing and training data follow the same cumulative distribution (or the same tail distribution whenever the former cannot be fulfilled) and that testing points be not isolated in the dataset.\\
\end{itemize}
%
Examples of unsupervised applicability classifiers include:
\begin{itemize}
	\item \textbf{Input space range classifier.} The applicability region is defined as the boundary of the hypercube whose edges are the ranges $[min, max]$ of each input variable in the training set. In practice, this amounts to checking if each numerical feature $X_i$ of the test point lies inside the range spanned by the training subset.
	\item \textbf{Input space convex hull classifier.} The applicability region is defined as the boundary of the convex hull of the training set.
	\item \textbf{Input space isolated region detector.} Even if a point is inside the convex hull of the training set, it can be very far away from other points, thus interpolation can be challenged. Isolated region detectors address this by checking the statistical vicinity of train points and comparing it to the distance of a given test point to the closest training point.\\
\end{itemize}

\begin{figure}[!htb]
	\begin{minipage}[t]{0.4\linewidth}
		\raggedright
		\includegraphics[width=\linewidth]{Figures/hipercubo.png}
		\caption{Smallest cube enclosing a set of 20 randomly generated points in a 3-dimensional euclidean space.}
		\label{fig:hipercuboex}
	\end{minipage}\hfill
	\begin{minipage}[t]{0.4\linewidth}
		\raggedleft
		\includegraphics[width=\linewidth]{Figures/policon.png}
		\caption{Convex hull enclosing the set of \cref{fig:hipercuboex}. The convex hull's volume is always smaller than or equal to the volume of the hypercube.}
		\label{fig:policonex}
	\end{minipage}
\end{figure}