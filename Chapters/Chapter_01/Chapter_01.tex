\chapter{The Validation Loop}
%
\label{chap:Chap_1}
%
%\indent This thesis is developed over a particular method of describing 
%
\section{Introduccion}
%
\indent Spacecraft relative dynamics is a vast, very relevant and ever-increasing branch of celestial mechanics. It tries to analyse, rather than the motion around a central body, that of a secondary body (or set of bodies) around a primary, assuming that neither of them generate a gravitational effect on each other. This discipline hence focuses on analysing how a certain force field -- which may include different influences -- differentially affects two or more different spacecrafts in a mostly common orbit.\\
%
\section{Train-test split}
\subsection{Preliminaries}
\indent In supervised learning applications, the dataset is typically divided into the training, the validation, and the test sets. Each set is used for different tasks, namely: training, model validation and hyperparameter tuning. Keeping different sets for each task is fundamental in order to prevent bias of the model for certain data or data features. Typical figures for the train-validation-test split are 60\%-20\%-20\%\cite[pp. 20-21]{Marsland2015Machine}.\\
%
\indent Training and evaluating the NN on the same dataset would result in the phenomenon called overfitting\cite[pp. 19-20]{Marsland2015Machine}, which basically consists of the NN fitting the noise in the training data and thus losing inference ability.\\
%
\indent With the dataset split into the train, evaluation, and test sets, the training and validation loop is as follows: the model is trained to ''fit'' the data in the training set. After a certain amount of training, its performance is measured on the evaluation set. The test set is used to compare the performance of different hyperparameter configurations. Note that the NN is always evaluated with data not previously ''seen'' during training, and as such cannot develop any bias for the training set (although bias for the validation or test sets may exist).\\
%
\indent In the model validation loop, the first question that should be asked, even before training the model, is whether the dataset split is appropriate for training.
%
\indent For the case of applicability of this section, we suppose we have a dataset which has been split into a training set

$${\cal S}_{\text{train}}=\{({\bf X^{tr}},{\bf Y^{tr}})_i\}_{i=1}^{N_{training}}$$

and a test set

$${\cal S}_{\text{test}}=\{({\bf X^{te}},{\bf Y^{te}})_i\}_{i=1}^{N_{test}},$$

where ${\bf X}=(X_1,X_2,\dots,X_m)$ is the vector of input variables (also called feature vector), $m$ is the dimensionality of the input parameter space, and ${\bf Y}=(Y_1,Y_2,\dots,Y_q)$ is the vector of output variables, with dimensionality $q$. Individual variables $X_k$ can be numerical or categorical. For instance, for stress problems such as MSP-S18, we have a combination of numerical  (eg external loads) and categorical (eg discrete geometrical variables such as ''Frame'' or ''Stringer'', and purely categorical such as ''dp''). Individual variables $Y_k$ describe the prediction and these are typically numerical (for stress problems such as MSP-S18, $q=6$ and these are so-called reserve factors, quantifying the failure likelihood of different failure modes).

The aim of this section is to propose a set of tests to evaluate to which extent splitting fulfils the necessary conditions for the subsequent surrogate model ${\bf \hat{Y}}=F({\bf X})$ to be appropriately trained on ${\cal S}_{\text{train}}$ and tested on ${\cal S}_{\text{test}}$.\\
%
 
\subsection{The train-test split problem in supervised learning}
\indent The idea that the model evaluation consists of evaluating the NN's fitness to a dataset statistically as close as possible to the training one should be kept in mind. This can be expressed by the equation \eqref{eqC1:TT1}:

\begin{equation} \label{eqC1:TT1}
	P_{training}(x)=P_{test}(x)
\end{equation}
where $x=(x_1, x_2, x_3,...,x_m)$ is the vector of input variables.\\
%
\indent The above condition can be applied also to the validation dataset. Therefore, for the rest of this section only the train-test split will be referred, nevertheless everything herein said for the train-test split is fully applicable to the train-validation split.\\
%
\indent In fact, the condition given by \eqref{eqC1:TT1} indeed assures statistical equivalence between the two sets, nonetheless is impossible to fulfil given that ${\cal S}_{train} \cap {\cal S}_{test} = \emptyset$. Instead, we will see that the goodness of the train-test split is closely related to the idea of interpolation. We now of NN that they perform better at interpolating than at extrapolating tasks. This is a matter of discussion highly debated in the literature (see v. gr.\cite{pmlr-v80-barrett18a,DBLP:journals/corr/abs-1711-00350,DBLP:journals/corr/abs-1904-01557}).\\

%
\indent There are plenty of definitions for the interpolation region of a given dataset. Some authors define it as the smallest hypercube enclosing the data\cite{ebert2014interpolation} although this might lead to points well far-away from the training set being considered to fall inside the interpolation region. Many authors (see v. gr. \cite{loh2007extrapolation,4505337}) define the interpolation region as the \textit{convex hull} of the training data, \ie:

\begin{definition}\label{def:interpolacion}
	Interpolation occurs for a sample $\mathbf{x}$ whenever this sample belongs to the convex hull of a set of samples $\mathbf{X}\triangleq \left\{\mathbf{x}_1,...,\mathbf{x}_N\right\}$.
\end{definition}

\indent The convex hull can be simply defined as the smallest convex set containing the data\cite{Preparata1985}. Definition \ref{def:interpolacion} will be taken as a first approach for the train-test split validation.\\
%

%




\section{Las movidas de Rodrigo}
%
\indent Orbit propagation is a very wide and varied field. It comprises many different approaches and methods to obtain more or less accurate results, with a higher or lower computational cost. Some examples are the numerical integration of the equations of motion in cartesian coordinates, the numerical integration of the variational equations (\ie equations of motion expressed in OEs) and the development of closed-form solutions by simplifying the problem. Within this last group, State Transition Matrices arise.\\
%
\indent The State Transition Matrix is a linearization procedure of a nonlinear dynamical system. It is used to approximate the dynamics of said system over short periods of time, allowing for a lower computational cost while maintaining an acceptable accuracy. This concept is not restricted to orbital mechanics, although it is one of the main fields in which it is used \cite{Montenbruck}. \\
%
\indent This section intends to provide some background in (a) its mathematical formulation and (b) its applications in orbit theory.
%
	\subsection{Concept: System dynamics.}
	%
	\indent Consider the uncontrolled, nonlinear dynamic system that is characterized through the state vector $\underline{y} = \left[ y_1, y_2, \ldots, y_n \right]$. The Initial Value Problem (IVP) for this system may be expressed as:
	%
	\begin{equation}
	[P] \equiv \left\{ \begin{array}{lll}
	\text{Eq.}	 	& \dfrac{d \underline{y}}{dt} = \bm F(\underline{y}, t) \\
	\text{ICs.} 	& \underline{y}(t_0) = \underline{y}_0
	\end{array}\right.
	\label{eqCh1:Problem_def}
	\end{equation}
	%
	\noindent where $\bm F(\underline{y}, t)$ represents the nonlinear dynamics of the system. This problem is unsolvable in general, mainly due to its nonlinearity. In the context of orbit propagation, the state vector $\underline{y}$ might be the position and velocity (be it relative or absolute) of the celestial body, and the dynamics function $\bm F$ contains the considered force model. In order to arrive at a closed-form, solvable problem, it is assumed that the solution $\underline{y}(t)$ can be expressed as:
	%
	\begin{equation}
	\underline{y}(t) = \Phi (t, t_0) \underline{y}(t_0)
	\label{eqCh1:STM_1}
	\end{equation}
	%
	\noindent where $\Phi (t, t_0)$ is the State Transition Matrix (STM) of the system. This matrix allows the state vector at a certain epoch $t$ to be calculated as the product of the matrix times the initial condition. This expression is obviously very favorable, but the question now is how does one compute it. Its actual definition can be easily derived from \eqref{eqCh1:STM_1} as:
	%
	\begin{equation}
	\Phi (t, t_0) \equiv \dfrac{\partial \underline{y}}{\partial \underline{y}_0}
	\label{eqCh1:STM_2}
	\end{equation}
	%
	\indent Yet again, how to compute it is not clear at all. There are three main options, depending on the situation:
	%
	\begin{itemize}
	\item[\GMVred{A.}] If the nonlinear solution as a function of the initial condition is known, then the expression \eqref{eqCh1:STM_2} is directly applied. This is an uncommon case, although simplified examples exist in the orbit propagation field. For example, the Keplerian motion equations expressed in Keplerian orbital elements (OEs) can be solved this way, due to the trivial remaining equations. Another example is the Clohessy-Wiltshire solution, from which the STM can be directly obtained. This process is detailed later on in section \ref{secCh2:CW_STM}.
	%
	\item[\GMVred{B.}] The nonlinear solution is unknown in the original state space, but can be calculated in a different space through a transformation. Mathematically, this can be written as:
	%
	\begin{equation}
	\Phi_{y} (t, t_0) = \dfrac{\partial \underline{y}}{\partial \underline{y}_0} = \dfrac{\partial \underline{y}}{\partial \underline{u}} \dfrac{\partial \underline{u}}{\partial \underline{u}_0} \dfrac{\partial
	\underline{u}_0}{\partial \underline{y}_0} \equiv W(t) \Phi_u(t, t_0) \left( W(t_0) \right)^{-1}
	\label{eqCh1:STM_decomp}
	\end{equation}
	%
	\noindent where $W(t)$ is the transformation matrix, where it is assumed that the transformation $\underline{y} = h(\underline{u})$ is known. An example of this kind of approach is the transformation of the Cartesian equations of motion into the Keplerian OEs, whose solution is known, as mentioned in \GMVred{A.}. This is a very commonly used method in relative orbit propagation, as in \cite{Yamanaka_Ankersen, GA_STM}.
	%
	\item[\GMVred{C.}] If none of the above can be performed, then the STM can be integrated itself, to be then used to calculate the state vector. This starts by differentiating \eqref{eqCh1:Problem_def} with respect to the initial condition $\underline{y}_0$, leading to:
	\[
	\begin{array}{ll}
	\bullet & \dfrac{\partial}{{\partial \underline{y}(t_0)}} \dfrac{d\underline{y}(t)}{dt} = \dfrac{d}{dt}\dfrac{\partial \underline{y}(t)} {{\partial \underline{y}(t_0)}} = \dfrac{d}{dt} \bm \Phi (t, t_0) \\[1.2em]
	\bullet & \dfrac{\partial \bm F(t, \underline{y})}{{\partial \underline{y}(t_0)}}  = \dfrac{\partial \bm F(t, \underline{y})}{{\partial \underline{y}(t)}} \dfrac{\partial \underline{y}}{{\partial \underline{y}(t_0)}} = \bm A \bm \Phi(t, t_0)
	\end{array}
	\]
	%
	\begin{equation}
	\Rightarrow [P] \equiv \left\{ \begin{array}{lll}
	\text{Eq.} 	& \dfrac{d}{dt} \Phi (t, t_0) = \bm A \Phi(t, t_0)\\
	\text{IC} 	& \Phi(t_0, t_0) = \eye_{nxn}
	\end{array}\right.
	\label{eqCh1:STM_prop}
	\end{equation}
	%
	\indent This last method is a bit unrewarding, as it forces one to integrate an IVP. However, the problem in terms of $\Phi(t, t_0)$ (eq. \eqref{eqCh1:STM_prop}) might be simpler or more efficient than the original (eq. \eqref{eqCh1:Problem_def}), although it is rare. An example of this approach is shown later in section \ref{secApp2:STM_prop}.
	%
	\end{itemize}
	%
	\subsection{Applications of STMs in celestial mechanics.}
	%
	\indent State Transition Matrices can be useful in a wide range of spacecraft dynamics applications. Some of the most important are \cite{STM_Apps}:
	%
	\paragraph{\GMVred{A.} \myul[GMVred]{Precise Orbit Determination.}\\}
	%
	\indent Precise Orbit Determination (POD) is a method through which the orbit of a flying spacecraft can be determined with a high accuracy \cite{POD}. This estimation is performed using general orbit determination algorithms, such as Kalman filtering or a batch least squares. It requires both high-precision geodetic receivers and high-precision dynamics models, where STMs comes to play. POD usually requires all typically important perturbations, such as non-spherical gravity, drag, tidal forces \ldots 
	%
	\paragraph{\GMVred{B.} \myul[GMVred]{Guidance, Navigation and Control (GNC).} \\}
	%
	\indent GNC deals with the design the systems to control the spacecraft. It involves the determination of the desired trajectory (guidance), the instantaneous determination of the spacecraft's position (navigation) and the manipulation of the controllers to execute guidance commands (control). STMs become very useful specially in situations in which the linearization error is small, such as in rendez-vous, station-keeping or formation flying operations. They prove to be useful in all three branches:
	%
	\begin{itemize}
	\item Guidance: STMs are a lightweight yet precise tool to generate reference trajectories.
	%
	\item Navigation: Signal filtering makes extensive use of STMs for the propagation of the estimated state. This is certainly one of the most relevant applications.
	%
	\item Control: Algorithms like robust online optimal control involve state propagation, using the STM.
	\end{itemize}
	%
%	\indent Unfavorable scenarios (\eg elliptic or perturbed orbit) may lead to greater linearization errors, unless an enhanced model is developed. This will be one recurring topic around the thesis.
%	%
	\paragraph{\GMVred{C.} \myul[GMVred]{Orbit design.} \\}
	%
	\indent Alternatively, rather than propagating already defined orbits, it may be useful to solve the inverse problem: that is, find the orbit that satisfies a set of conditions (\eg optimality). This is specially relevant for the Circular Restricted Three Body Problem (CR3BP), or its particular case of Halo orbits (periodic 3D orbit near one of the Lagrange libration points). STMs are quite useful to determine an initial solution for said Halo orbits, and can also be used to evaluate the effect of a deviation in initial conditions or other parameters. 
	%
	\paragraph{\GMVred{D.} \myul[GMVred]{Covariance matrix propagation.} \\}
	%
	\indent Some degree of uncertainty will always be assumed in the estimation of a spacecraft's position and velocity. This matter becomes really important in the context of collision avoidance, where ideally, said uncertainty would be exactly calculated. However, these values are usually not something inherently worrying. What is worrying indeed is that this uncertainty may propagate in a divergent fashion, leading to unbounded trajectories with its inherent collision risk.\\
	%
	\indent Here is where the covariance matrix comes to light. Conceptually, it can be seen as an entity which indicates how certain are each of the components of the state vector. That is represented by their variances and covariances. Mathematically, it is defined as:
	%
	\[
	P(t) 	= E\left[ \left(\underline{\hat{x}} - \underline{x}\right) \left(\underline{\hat{x}} - \underline{x}\right)^T \right]
	\]
	%
	\indent If one knew the covariance at a certain epoch $t_j$, it is possible to map it to a different epoch $t_k$ (latter or earlier) through the STM, that is:
	%
	\[
	\begin{array} {c} P(t_k) 	=  E\left[ \left(\underline{\hat{x}_k} - \underline{x_k}\right) \left(\underline{\hat{x}_k} - \underline{x}_k\right)^T \right] = E\left[\Phi(t_k, t_j) \left(\underline{\hat{x}_j} - \underline{x}_j\right) \left(\underline{\hat{x}_j} - \underline{x_j}\right)^T \Phi^T(t_k, t_j)\right] \\[1.3em]
	\Rightarrow P(t_k)=  \Phi(t_k, t_j) P(t_j) \Phi^T(t_k, t_j) \end{array}
	\]
	%
	\indent Now, once the mathematical formalism has been stated, it is time to apply it to the situation at hand. Spacecraft state uncertainty has essentially two sources: estimation error (associated to navigation) and execution error (associated to control/manoeuvres). \\
	%
	\indent In a fairly relaxed approach (\ie assuming the state variables be decoupled), the covariance matrix associated to the estimation error has the following shape:\\
	%
	\begin{equation}
	P_{est} = \left[ \begin{array}{cccccc}
	\delta x^2 	& 0 			& 0 			& 0 			& 0 			& 0 \\
	0 			& \delta y^2	& 0 			& 0 			& 0 			& 0 \\	
	0 			& 0 			& \delta z^2 	& 0 			& 0 			& 0 \\
	0			& 0 			& 0 			& \delta v_x^2 	& 0 			& 0 \\
	0			& 0 			& 0 			& 0				& \delta v_y^2 	& 0 \\
	0			& 0 			& 0 			& 0				& 0 			& \delta v_z^2 \\
	\end{array} \right]
	\label{eqCh1:P_est}
	\end{equation}
	%
	\noindent where $\delta \psi$ indicates the standard deviation of the variable $\psi$. An useful way to visualize the covariance is the probability ellipsoid, defined by:
	%
	\[
	\left[\begin{array}{ccc}
	\tilde{x} & \tilde{y} & \tilde{z}
	\end{array} \right] 
	P_{xyz}^{-1} 
	\left[ \begin{array}{c}
	\tilde{x} \\ \tilde{y} \\ \tilde{z} \\
	\end{array} \right] = l^2
	\]
	%
	\noindent where $\tilde{x}, \tilde{y}, \tilde{z}$ are the coordinates of a point of the ellipsoid (referred to its center), $P_{xyz}$ is the partition of the covariance matrix related to the position and $l$ is the sigma coefficient. That is, for $l = 2$, the equation represents the ellipsoid in which the spacecraft will be found with a $2\sigma$ probability. An example of the evolution of this ellipsoid can be seen for a small radial hop in figure \ref{figCh1:Covariance_segment}. 
	%
	\begin{figure}[!htb]
	\centering\includegraphics[width = 0.90\linewidth]{Chapters/Chapter_01/Covariance_segment}
	\caption{Covariance ellipsoid evolution along a radial hop.}
	\label{figCh1:Covariance_segment}
	\end{figure}
	%
	\FloatBarrier
	%
	\indent Most of these concepts lie out of the thesis' scope. However, it is important to know that the STMs developed or quoted throughout this thesis can be used in many different fields of celestial mechanics.
	%