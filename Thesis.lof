\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {xchapter}{Resumen.}{iii}{chapter*.2}%
\addvspace {10\p@ }
\contentsline {xchapter}{Abstract.}{v}{chapter*.3}%
\addvspace {10\p@ }
\contentsline {xchapter}{Introduction.}{xix}{chapter*.8}%
\contentsline {figure}{\numberline {2}{\ignorespaces Research fields in which Machine Learning represents an outbreak in technological development. \blx@tocontentsinit {0}\cite {le2023improving}\relax }}{xx}{figure.caption.9}%
\addvspace {10\p@ }
\contentsline {xchapter}{General concepts on supervised learning for industrial applications}{1}{chapter.1}%
\contentsline {figure}{\numberline {1.1}{\ignorespaces Smallest cube enclosing a set of 20 randomly generated points in a 3-dimensional euclidean space.\relax }}{9}{figure.caption.23}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Convex hull enclosing the set of \cref {fig:hipercuboex}. The convex hull's volume is always smaller than or equal to the volume of the hypercube.\relax }}{9}{figure.caption.23}%
\addvspace {10\p@ }
\contentsline {xchapter}{The industrial problem}{11}{chapter.2}%
\contentsline {figure}{\numberline {2.1}{\ignorespaces Surrogate model pipeline\relax }}{12}{figure.caption.24}%
\addvspace {10\p@ }
\contentsline {xchapter}{The validation pipeline}{13}{chapter.3}%
\contentsline {figure}{\numberline {3.1}{\ignorespaces Validation pipeline\relax }}{13}{figure.caption.25}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Location of the train-test split assessment in the overall validation pipeline\relax }}{14}{figure.caption.26}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Input [numeric] variables distributions double histogram. Only the first four input variables have been plotted.\relax }}{24}{figure.caption.33}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Input categorical variables distributions double histograms\relax }}{24}{figure.caption.34}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Output variables distributions double histograms\relax }}{25}{figure.caption.36}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Requirements of the geometrical analysis\relax }}{25}{figure.caption.37}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Scatter plot of ground true ($x$ axis) against predicted values ($y$ axis) of output variable ''RF Net Tension'', with the correspondent $R^2$ coefficient. In this case, $R^2=1,000$ indicates a perfect fit of predicted to ground true values. Mismatches due to underestimating failure risk are labelled in red, while those due to overestimating failure risk are labelled in blue. Similar graphs can be computed for every pair $\left \{y_j,\hat {y}_j\right \}$ of features in the output variables $\mathbf {Y}=\left \{y_1,y_2,\ldots ,y_m\right \}$. Plots for the rest of the six output variables of MS-S18 show analogous results.\relax }}{27}{figure.caption.39}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Location of \autoref {sec:globalerr} in the validation pipeline.\relax }}{28}{figure.caption.40}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Double histogram depicting ground true values and model's predictions for the six output variables of MS-18.\relax }}{30}{figure.caption.41}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces Empirical residue distribution sampled from the test set, for each of the six output variables of MS-S18. $x$-axis limits have been truncated to $\mu \pm 3 \sigma $, where the most part of the error lies. Histograms have been appropriately binned for a correct visualization.\relax }}{32}{figure.caption.43}%
\contentsline {figure}{\numberline {3.11}{\ignorespaces Cumulative error distributions corresponding to the PDFs showed (as binned histograms) in \autoref {fig:pdferror}.\relax }}{32}{figure.caption.44}%
\contentsline {figure}{\numberline {3.12}{\ignorespaces Graphical comparison of the p-values resulting from the K-S test for the MS-18 data.\relax }}{34}{figure.caption.46}%
\contentsline {figure}{\numberline {3.13}{\ignorespaces (Binned) histograms depicting the distribution of the variable $z=\gamma +\qopname \relax o{sinh}{\frac {e-\xi }{\lambda }}$, where $e\sim JohnsonSU(\gamma ,\delta ,\xi ,\lambda )$ is the sampled residue. It can be shown that $z$ converges to a normal distribution\blx@tocontentsinit {0}\cite {jones2009sinh}.\relax }}{34}{figure.caption.47}%
\contentsline {figure}{\numberline {3.14}{\ignorespaces Box diagram showing the relative position of \autoref {sec:biasinput} in the complete validation pipeline.\relax }}{40}{figure.caption.52}%
\contentsline {figure}{\numberline {3.15}{\ignorespaces Box and whisker plots depicting the residue conditioned to two different categorical variables. \autoref {fig:boxwhisker1}: ''Frame''. \autoref {fig:boxwhisker2}: ''Stringer''. Clearly, outliers can be appreciated in both cases (''Fr69-Fr70'' in \autoref {fig:boxwhisker1}, and various stringers in \autoref {fig:boxwhisker2}).\relax }}{42}{figure.caption.53}%
\contentsline {figure}{\numberline {3.16}{\ignorespaces Quantification of linear trend for input categorical variables ''Stringer'' (left) and ''Frame'' (right). Variables have been numerically encoded following a logical order ({\it e.g.}\ in the right image, six integers in the $x$ axis represent the six possible values of variable Frame). The residue of output variable ''RF Net Tension'' has been plotted against the categorical variable ($y$ axis). In this case, no linear trend is appreciated in neither of the two input variables (no bias present).\relax }}{47}{figure.caption.56}%
\contentsline {figure}{\numberline {3.17}{\ignorespaces Scatter plots of residue against a particular numerical input variable. Left: Input var. FU.0420.26. A linear trend is appreciated, suggesting the model makes worse predictions as input load ''FU.0420.26'' is larger. Right: input var. FU.0420.25. No linear trend is appreciated, although severe heteroscedasticity can be observed. Note the vertical bar arrangement, showing particular input loads for which dispersion is unusually large. In view of the former results, the engineer may decide to investigate the underlying causes both for the linear trend in the left and for heteroscedasticity on the right. With the information, model and data boosting may be performed. More training data could be decided to be sampled in the range of $[20000,60000]$ of FU.0420.26, for instance, and some regularization technique could be tried for the loss function in order to penalise inputs triggering high variance observed in the right.\relax }}{49}{figure.caption.58}%
\contentsline {figure}{\numberline {3.18}{\ignorespaces Relative position of \autoref {sec:biasoutput} in the complete validation pipeline.\relax }}{54}{figure.caption.63}%
\contentsline {figure}{\numberline {3.19}{\ignorespaces Goodness of fit of the error distribution (test set previously filtered) to some parametrised distributions. The test is performed individually for the output variables (Reserve Factors) displayed on top of each image. The goodness of fit is assessed with a 1-variable K-S test. The test set is filtered using the x axis, rejecting every point whose output $\hat {y}$ is larger than $x$. If the p-value resulting from the K-S test in the filtered test set is greater than $0.05$, the vertical slice at position $x$ is labelled green (red if $p\text {-value}<0.05$, grey if less than a threshold number of points --namely, 30-- are present in the filtered test set).\relax }}{56}{figure.caption.64}%
\contentsline {figure}{\numberline {3.20}{\ignorespaces Line plot of the $p$-value from the true-predicted distributions under a 2 sample K-S test. Distribution similarity is rejected if $p\text {-value}<0.05$.\relax }}{58}{figure.caption.66}%
\contentsline {figure}{\numberline {3.21}{\ignorespaces Violin plots showing the absolute value residue for every bin.\relax }}{59}{figure.caption.67}%
\contentsline {figure}{\numberline {3.22}{\ignorespaces Sliced-bar with p-values from the binned error under a K-S test to assess the goodness of fit to several parametrised distributions.\relax }}{60}{figure.caption.68}%
\contentsline {figure}{\numberline {3.23}{\ignorespaces Global Uncertainty Model: error coverage. The coverage is higher than 95\% for both output variables --for convenience just two output variables are depicted-- what means the calibration criteria is successfully met.\relax }}{65}{figure.caption.73}%
\contentsline {figure}{\numberline {3.24}{\ignorespaces Local Uncertainty Model based on $P(E|\mathbf {Y})$: Scatter plot of the residue as a function of the predicted output $\hat {y}$, for output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }}{66}{figure.caption.74}%
\contentsline {figure}{\numberline {3.25}{\ignorespaces Local Uncertainty Model based on $P(E|\mathbf {Y})$: Violin plots of the residue, for binned output variables ''RF Pure Compression'' and ''RF Shear Panel Failure''.\relax }}{66}{figure.caption.75}%
\contentsline {figure}{\numberline {3.26}{\ignorespaces LOUM coverage in the validation set. For both output variables coverage is above the minimum 95\% threshold.\relax }}{68}{figure.caption.78}%
\contentsline {figure}{\numberline {3.27}{\ignorespaces LIUM: Scatter plot of the residue of ''RF Forced Crippling'' as a function of the input $x$ (left: $x$ is ''FU.0410.16''. Right: $x$ is ''FU.0410.24'').\relax }}{69}{figure.caption.79}%
\contentsline {figure}{\numberline {3.28}{\ignorespaces Violin plots showing the residue of output variable ''RF Forced Crippling''. (a): Numerical inputs (binned). (b) and (c): categorical inputs.\relax }}{70}{figure.caption.80}%
\contentsline {figure}{\numberline {3.29}{\ignorespaces LIUM coverage on the evaluation set. Residue of the output variable ''RF Forced Crippling''. The grey area represents the uncertainty CI calculated by the LIUM for the corresponding bin.\relax }}{73}{figure.caption.83}%
\contentsline {figure}{\numberline {3.30}{\ignorespaces Conceptual visualization of FUM as a conservative merge between GUM (whose bootstrap interval [P2.5,P97.5] is represented by the two straight horizontal lines), LOUM and LIUM (whose bootstrap intervals [P2.5,P97.5] are represented indistinctively by the red and blue curves).\relax }}{74}{figure.caption.84}%
\addvspace {10\p@ }
\contentsline {xchapter}{Conclusions and research outlook.}{75}{chapter.4}%
